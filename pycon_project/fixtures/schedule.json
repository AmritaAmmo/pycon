[
    {
        "pk": 1, 
        "model": "schedule.slot", 
        "fields": {
            "start": "2011-03-09 14:00:00", 
            "end": "2011-03-09 17:00:00", 
            "title": null
        }
    }, 
    {
        "pk": 2, 
        "model": "schedule.slot", 
        "fields": {
            "start": "2011-03-09 19:00:00", 
            "end": "2011-03-09 22:00:00", 
            "title": null
        }
    }, 
    {
        "pk": 3, 
        "model": "schedule.slot", 
        "fields": {
            "start": "2011-03-10 14:00:00", 
            "end": "2011-03-10 17:00:00", 
            "title": null
        }
    }, 
    {
        "pk": 4, 
        "model": "schedule.slot", 
        "fields": {
            "start": "2011-03-10 19:00:00", 
            "end": "2011-03-10 22:00:00", 
            "title": null
        }
    }, 
    {
        "pk": 1, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Celery is an open source task queueing system based on distributed message passing, especially using the AMQP protocol.\r\n\r\nThis talk will focus on the need for task distribution, the tools celery provides to meet those needs, and an in-depth discussion of how we've used celery at ShootQ to improve the efficiency and reliability of our background processes.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The talk (including time for questions) will last approximately 30 minutes and will focus on the following topics:\r\n\r\n* The need for distributed tasks in real world systems, especially in a web application environment.  This portion of the talk will describe examples where the traditional request-response model of the web can be improved with background processing.\r\n* A brief overview of traditional distributed message passing models and the AMPQ protocol.\r\n* An overview of Celery and the variety of tools it provides for task distribution, scheduling, and execution.  This portion of the talk will also review production-oriented components of Celery, such as monitoring, error detection/reporting, and error recovery.\r\n* Real world discussion of several problems we solved at ShootQ using Celery including before-and-after looks at our implementations.\r\n* Common pitfalls and gotchas we encountered while working with Celery.", 
            "title": "Distributed Tasks with Celery", 
            "plenary": false, 
            "abstract_html": "<p>The talk (including time for questions) will last approximately 30 minutes and will focus on the following topics:\r</p>\n<ul>\n<li>The need for distributed tasks in real world systems, especially in a web application environment.  This portion of the talk will describe examples where the traditional request-response model of the web can be improved with background processing.\r</li>\n<li>A brief overview of traditional distributed message passing models and the AMPQ protocol.\r</li>\n<li>An overview of Celery and the variety of tools it provides for task distribution, scheduling, and execution.  This portion of the talk will also review production-oriented components of Celery, such as monitoring, error detection/reporting, and error recovery.\r</li>\n<li>Real world discussion of several problems we solved at ShootQ using Celery including before-and-after looks at our implementations.\r</li>\n<li>Common pitfalls and gotchas we encountered while working with Celery.</li>\n</ul>\n", 
            "speaker": 2, 
            "submitted": "2010-09-21 15:56:28", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 7, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Have an inside look at what it takes to work on CPython, from getting setup with the source and navigating the bug tracker, to the best practices for having your work accepted. We'll find, categorize, and fix an issue in Python to get you started.\r\n\r\nThis talk is ideal for those who are new to open source projects or are interested in the Python development process.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "People from all backgrounds, users of all platforms, and developers of all levels are necessary in the development of Python. From writing code to documentation, it takes all kinds of people to make an impact. If you've used Python, we need you, and what better place to get involved than at PyCon?\r\n\r\n2010 saw a rise in the number of contributors to CPython, and the PSF stepped in to support the efforts of those wanting to get involved. Are you up for the challenge? This talk dives right into what it takes to get involved, covering the who, what, where, when, and why of Python development, going through the whole process live.\r\n\r\nAfter the conference is over, stick around with the CPython crew and hack away!", 
            "title": "The Development of Python and You", 
            "plenary": false, 
            "abstract_html": "<p>People from all backgrounds, users of all platforms, and developers of all levels are necessary in the development of Python. From writing code to documentation, it takes all kinds of people to make an impact. If you've used Python, we need you, and what better place to get involved than at PyCon?\r</p>\n<p>2010 saw a rise in the number of contributors to CPython, and the PSF stepped in to support the efforts of those wanting to get involved. Are you up for the challenge? This talk dives right into what it takes to get involved, covering the who, what, where, when, and why of Python development, going through the whole process live.\r</p>\n<p>After the conference is over, stick around with the CPython crew and hack away!</p>\n", 
            "speaker": 7, 
            "submitted": "2010-09-26 18:47:05", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 10, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Serializing data structures (in Python-speak \"pickling\") to save to disk/socket is an important tool for the programmer:  We will discuss how the pickling protocols (0,1,2, and 3) work as well as real-world issues (gotchas, backwards-compatibility, etc).  We will concentrate on the basics of this stack-based protocol: what it looks like, how to encode/decode, speeds of different implementations. ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The Pickling Protocols are a fundamental tool for saving state.  \r\n\r\nWe will discuss the differences between text serialization and Python pickling (as well as marshalling, and simple bit-blitting).\r\n\r\nWe will spend a little time discussing history: why there is a cPickle and pickle module in 2.x and only pickle in 3.x., and why there are 4 different protocols: 0,1,2 and 3.\r\n\r\nWe will then dive right in and look at how the stack-based protocol works.  We will concentrate on the basics (the stack-based machine), as all the protocols adhere to this basic model, but tend to discuss the more recent protocols and their differences.  We will also discuss how the memoization scheme works.\r\n\r\nWe will show some simple examples and then build to more complex examples. \r\n\r\nWe will also discuss the relative speeds: the different protocols (text, 0,1,2,3) and the different implementations (Python, Boost, PicklingTools, IronPython?, PyPy? Unladen Swallow?).\r\n\r\nWe will end with some real-world advice and some gotchas to watch out for (32-bit vs. 64-bit, different versions of Python serialize differently, etc.).\r\n", 
            "title": "Everything You Wanted To Know About Pickling, But Were Afraid To Ask!", 
            "plenary": false, 
            "abstract_html": "<p>The Pickling Protocols are a fundamental tool for saving state.  \r</p>\n<p>We will discuss the differences between text serialization and Python pickling (as well as marshalling, and simple bit-blitting).\r</p>\n<p>We will spend a little time discussing history: why there is a cPickle and pickle module in 2.x and only pickle in 3.x., and why there are 4 different protocols: 0,1,2 and 3.\r</p>\n<p>We will then dive right in and look at how the stack-based protocol works.  We will concentrate on the basics (the stack-based machine), as all the protocols adhere to this basic model, but tend to discuss the more recent protocols and their differences.  We will also discuss how the memoization scheme works.\r</p>\n<p>We will show some simple examples and then build to more complex examples. \r</p>\n<p>We will also discuss the relative speeds: the different protocols (text, 0,1,2,3) and the different implementations (Python, Boost, PicklingTools, IronPython?, PyPy? Unladen Swallow?).\r</p>\n<p>We will end with some real-world advice and some gotchas to watch out for (32-bit vs. 64-bit, different versions of Python serialize differently, etc.).\r</p>\n", 
            "speaker": 28, 
            "submitted": "2010-09-30 13:13:39", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 12, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Did you know you can create and evolve programs that find solutions to problems? This talk walks through how to use Genetic Algorithms and Genetic Programming as tools to discover solutions to hard problems, when to use GA/GP, setting up the GA/GP environment, and interpreting the results. Using pyevolve, we'll walk through a real-world implementation creating a GP that predicts the weather.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Genetic Algorithms (GA) and Genetic Programming (GP) are methods used to search for and optimize solutions in large solution spaces.  GA/GP use concepts borrowed from natural evolution, such as mutation, cross-over, selection, population, and fitness to generate solutions to problems.  If done well, these solutions will become better as the GA/GP runs.\r\n\r\nGA/GP has been used in problem domains as diverse as scheduling, database index optimization, circuit board layout, mirror and lens design, game strategies, and robotic walking and swimming.  They can also be a lot of fun, and have been used to evolve aesthetically pleasing artwork, melodies, and approximating pictures or paintings using polygons.\r\n\r\nGA/GP is fun to play with because often-times an unexpected solution will be created that will give new insight or knowledge.  It might also present a novel solution to a problem, one that a human may never generate.  Solutions may also be inscrutable, and determining why a solution works is interesting in itself.", 
            "title": "Genetic Programming in Python", 
            "plenary": false, 
            "abstract_html": "<p>Genetic Algorithms (GA) and Genetic Programming (GP) are methods used to search for and optimize solutions in large solution spaces.  GA/GP use concepts borrowed from natural evolution, such as mutation, cross-over, selection, population, and fitness to generate solutions to problems.  If done well, these solutions will become better as the GA/GP runs.\r</p>\n<p>GA/GP has been used in problem domains as diverse as scheduling, database index optimization, circuit board layout, mirror and lens design, game strategies, and robotic walking and swimming.  They can also be a lot of fun, and have been used to evolve aesthetically pleasing artwork, melodies, and approximating pictures or paintings using polygons.\r</p>\n<p>GA/GP is fun to play with because often-times an unexpected solution will be created that will give new insight or knowledge.  It might also present a novel solution to a problem, one that a human may never generate.  Solutions may also be inscrutable, and determining why a solution works is interesting in itself.</p>\n", 
            "speaker": 30, 
            "submitted": "2010-10-05 08:56:01", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 127, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Educators discuss Python as both a subject and a tool in primary and secondary (K12) education. Topics addressed include the distinction between teaching Python and teaching with Python, the benefits of Python in K12 and ways to demonstrate the value of Python to administrators. Panel includes private and public K12 educators and university faculty involved in instruction in the K12 setting.", 
            "additional_speakers": [
                108, 
                156, 
                186, 
                248
            ], 
            "session_type": 2, 
            "track": null, 
            "abstract": "Zac Miller will act as panel moderator.  \r\n\r\nPanel will open with a brief introduction of the origins of the panel and self introductions of panel members before addressing the following topics:\r\n\r\n*The distinction between teaching Python and teaching with Python.\r\n**Teaching Python\r\n**Teaching Math with Python\r\n*How does Teaching with Python complement Teaching Python?\r\n**Do tensions between the two exist?\r\n*What keeps Python out of schools? What can be done to encourage more schools to teach tools like Python?\r\n*What is the biggest benefit teaching Python brings to your school and students? What is the biggest benefit in general, beyond your school?\r\n*Can teaching Python help spark creativity in those students who have trouble exercising it?\r\n**When teaching Python a creativity divide becomes readily apparent among students.  Students with a high level of curiosity and creativity constantly try new things on their own, while other students are focused solely on completing the assignments for grades. How can an instructor handle this?\r\n**What tangible steps can an instructor take to encourage creativity?\r\n*What does the future look like for Python in K12 education, both at our own schools and in general?\r\n*Audience Questions\r\n\r\nPanel Biographies:\r\n\r\nVern Ceder, Director of Technology, Canterbury School, Ft Wayne, Indiana.  The Canterbury School has been teaching at least a little Python to every single 8th and 9th grader in the school since 2001, as well as offering electives in Python, Java, C, etc. Vern also teaches Python through Northwestern's Gifted Learning Links program (http://www.ctd.northwestern.edu/gll/) and is the author of The Quick Python Book, 2nd ed (http://www.manning.com/ceder)\r\n\r\nMaria Litvin.  Maria teaches Math and Computer Science at Phillips Academy in Andover, MA, including \"Introduction to Discrete Mathematics and Programming in Python.\"  She also taught Python to Boston-area high school teachers and to middle schoolers in Google's CAPE program.  She's co-author of several Computer Science textbooks, most recently Mathematics for the Digital Age and Programming in Python (www.skylit.com/mathandpython.html).\r\n\r\nJeffrey Elkner, teaches computer programming and information technology at the Governor's Career and Technical Academy in Arlington, Virginia.  He has been teaching with Python since 1999, and is co-author of a free on-line textbook: How to Think Like a Computer Scientist: Learning with Python.  He also maintains the Open Book Project (http://openbookproject.net), which contains several Python resources.  Jeff has attended each PyCon held thus far, often bringing students along with him.\r\n\r\nBrian Brumley teaches Python (and lots of other stuff) to grades 6-8 at Porter-Gaud school in Charleston, SC.  Brian is a regular presenter at state and regional conferences on technology and programming in schools.\r\n\r\nZac Miller is adjunct instructor in the STEM school at Gainesville State College and a faculty member at the Da Vinci Academy at South Hall Middle School in Gainesville, Georgia.  Zac is currently teaching Python programming and Python programming for Geographic Information Systems to K12 and college-level students. \r\n\r\n\r\n\r\n\r\n", 
            "title": "Panel: Python in Schools: Teaching It and Teaching With It.", 
            "plenary": false, 
            "abstract_html": "<p>Zac Miller will act as panel moderator.  \r</p>\n<p>Panel will open with a brief introduction of the origins of the panel and self introductions of panel members before addressing the following topics:\r</p>\n<ul>\n<li>The distinction between teaching Python and teaching with Python.\r<ul>\n<li>Teaching Python\r</li>\n<li>Teaching Math with Python\r</li>\n</ul>\n</li>\n<li>How does Teaching with Python complement Teaching Python?\r<ul>\n<li>Do tensions between the two exist?\r</li>\n</ul>\n</li>\n<li>What keeps Python out of schools? What can be done to encourage more schools to teach tools like Python?\r</li>\n<li>What is the biggest benefit teaching Python brings to your school and students? What is the biggest benefit in general, beyond your school?\r</li>\n<li>Can teaching Python help spark creativity in those students who have trouble exercising it?\r<ul>\n<li>When teaching Python a creativity divide becomes readily apparent among students.  Students with a high level of curiosity and creativity constantly try new things on their own, while other students are focused solely on completing the assignments for grades. How can an instructor handle this?\r</li>\n<li>What tangible steps can an instructor take to encourage creativity?\r</li>\n</ul>\n</li>\n<li>What does the future look like for Python in K12 education, both at our own schools and in general?\r</li>\n<li>Audience Questions\r</li>\n</ul>\n<p>Panel Biographies:\r</p>\n<p>Vern Ceder, Director of Technology, Canterbury School, Ft Wayne, Indiana.  The Canterbury School has been teaching at least a little Python to every single 8th and 9th grader in the school since 2001, as well as offering electives in Python, Java, C, etc. Vern also teaches Python through Northwestern's Gifted Learning Links program (<a href=\"http://www.ctd.northwestern.edu/gll/\">http://www.ctd.northwestern.edu/gll/</a>) and is the author of The Quick Python Book, 2nd ed (<a href=\"http://www.manning.com/ceder\">http://www.manning.com/ceder</a>)\r</p>\n<p>Maria Litvin.  Maria teaches Math and Computer Science at Phillips Academy in Andover, MA, including \"Introduction to Discrete Mathematics and Programming in Python.\"  She also taught Python to Boston-area high school teachers and to middle schoolers in Google's CAPE program.  She's co-author of several Computer Science textbooks, most recently Mathematics for the Digital Age and Programming in Python (www.skylit.com/mathandpython.html).\r</p>\n<p>Jeffrey Elkner, teaches computer programming and information technology at the Governor's Career and Technical Academy in Arlington, Virginia.  He has been teaching with Python since 1999, and is co-author of a free on-line textbook: How to Think Like a Computer Scientist: Learning with Python.  He also maintains the Open Book Project (<a href=\"http://openbookproject.net)\">http://openbookproject.net)</a>, which contains several Python resources.  Jeff has attended each PyCon held thus far, often bringing students along with him.\r</p>\n<p>Brian Brumley teaches Python (and lots of other stuff) to grades 6-8 at Porter-Gaud school in Charleston, SC.  Brian is a regular presenter at state and regional conferences on technology and programming in schools.\r</p>\n<p>Zac Miller is adjunct instructor in the STEM school at Gainesville State College and a faculty member at the Da Vinci Academy at South Hall Middle School in Gainesville, Georgia.  Zac is currently teaching Python programming and Python programming for Geographic Information Systems to K12 and college-level students. \r</p>\n", 
            "speaker": 43, 
            "submitted": "2010-10-31 13:04:06", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 246, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Selenium is a popular web application testing tool for acceptance testing dynamic web applications. Selenium 2.0 has a different architecture that makes it leaner, meaner, and more pythonic -- for testing desktop *and* mobile web (iPhone/Android) apps. This talk will go into detail on how Selenium 2 works. If you like testing and Python, you'll enjoy what's cooking in Selenium 2.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Selenium was originally created by Jason Huggins and his team at ThoughtWorks in 2004 as a tool for cross-browser acceptance testing of dynamic web apps -- apps that use JavaScript heavily on the client. Over the years, the Selenium tool family has expanded to include a Firefox record and playback tool (Selenium IDE), a Remote Control server that allows API access from any major programming language, and a Grid server that allows tests to run in parallel across many machines.\r\n\r\nDespite it's widespread industry adoption, the Selenium project is far from done. Selenium's goal is to drive any browser the same way an end user would (e.g. opening pages, clicking buttons, entering text, etc.) with any programming language on any OS platform. It's an ambitious goal, and with a steady stream of new browsers (Chrome), new platforms (Android, iPhone), and new HTML5 technologies (video, canvas, offline storage) to support, just keeping up is an arduous task.\r\n\r\nAstute observers will note, though, the bulk of Selenium's automation engine is implemented in JavaScript, which is confined by the browser's security sandbox in which it executes JavaScript code. That security sandbox ultimately is at odds with Selenium's goal to drive the browser just as a user would. A user has no problem interacting with security alerts for untrusted certificates, or file upload dialog boxes, but Selenium can't deal with these kinds of things easily without extra effort.\r\n\r\nEnter WebDriver. There's a lot in common between the Selenium and WebDriver projects. They're both tools for automated testing of web applications, and both aspire to offer browser test automation from any language on any platform. However, they do their thing in radically different ways. Selenium uses the strategy that JavaScript is the one common tool available for automating all browsers, even though its capabilities can be highly constrained. Meanwhile, WebDriver leverages the strategy that acknowledges different automation strategies work best for different browsers. COM works best for IE on Windows, Apple Events for Safari on OS X. And Firefox, well, the best way to natively automate Firefox is to turn it into a telnet server. (But that's a whole other PyCon talk entirely!) WebDriver aims to natively drive each browser the best way possible for maximum capability, then hiding those differences between lower level C and C++ APIs, and finally exposing the functionality through the appropriate C/C++ mechanism for each target language, such as using ctypes for Python. With WebDriver's technical approach, anything a user can do is now possible in test automation code.\r\n\r\nThis talk will go into detail explaining how Selenium and WebDriver (aka Selenium 2) work, comparing the strengths and weaknesses of each tool's approach to browser automation. The talk will then explain what Selenium 2.0 looks like and how to use it. \r\n\r\nTalk outline:\r\n\r\n* Description of problem space\r\n** More browsers\r\n** More frequent browser releases\r\n** HTML 5 - video, canvas, offline storage\r\n** The web in more places - Mobile, Chrome OS\r\n\r\n* Description of Selenium\r\n\r\n* Strengths of Selenium\r\n\r\n* Description of challenges for Selenium 1\r\n** Javascript security sandbox\r\n** Same origin policy / cross-site scripting\r\n** OS-level popups\r\n** Speed / stability\r\n** Java as the cross-language integration point (aka Not Very Pythonic, eh?)\r\n \r\n* Description of Selenium 2 (aka WebDriver)\r\n\r\n* Strengths of Selenium 2\r\n\r\n* How Selenium 2 is more pythonic\r\n** (Lots and lots of example code goes here.)\r\n** Spoiler Alert: No Java server required!\r\n\r\n* How to test Android apps\r\n* How to test iPhone apps\r\n\r\n* Selenium development roadmap\r\n", 
            "title": "Testing the Mobile (and Desktop) Web with Selenium 2.0 -  Better, Faster, and more Pythonicly", 
            "plenary": false, 
            "abstract_html": "<p>Selenium was originally created by Jason Huggins and his team at ThoughtWorks in 2004 as a tool for cross-browser acceptance testing of dynamic web apps -- apps that use JavaScript heavily on the client. Over the years, the Selenium tool family has expanded to include a Firefox record and playback tool (Selenium IDE), a Remote Control server that allows API access from any major programming language, and a Grid server that allows tests to run in parallel across many machines.\r</p>\n<p>Despite it's widespread industry adoption, the Selenium project is far from done. Selenium's goal is to drive any browser the same way an end user would (e.g. opening pages, clicking buttons, entering text, etc.) with any programming language on any OS platform. It's an ambitious goal, and with a steady stream of new browsers (Chrome), new platforms (Android, iPhone), and new HTML5 technologies (video, canvas, offline storage) to support, just keeping up is an arduous task.\r</p>\n<p>Astute observers will note, though, the bulk of Selenium's automation engine is implemented in JavaScript, which is confined by the browser's security sandbox in which it executes JavaScript code. That security sandbox ultimately is at odds with Selenium's goal to drive the browser just as a user would. A user has no problem interacting with security alerts for untrusted certificates, or file upload dialog boxes, but Selenium can't deal with these kinds of things easily without extra effort.\r</p>\n<p>Enter WebDriver. There's a lot in common between the Selenium and WebDriver projects. They're both tools for automated testing of web applications, and both aspire to offer browser test automation from any language on any platform. However, they do their thing in radically different ways. Selenium uses the strategy that JavaScript is the one common tool available for automating all browsers, even though its capabilities can be highly constrained. Meanwhile, WebDriver leverages the strategy that acknowledges different automation strategies work best for different browsers. COM works best for IE on Windows, Apple Events for Safari on OS X. And Firefox, well, the best way to natively automate Firefox is to turn it into a telnet server. (But that's a whole other PyCon talk entirely!) WebDriver aims to natively drive each browser the best way possible for maximum capability, then hiding those differences between lower level C and C++ APIs, and finally exposing the functionality through the appropriate C/C++ mechanism for each target language, such as using ctypes for Python. With WebDriver's technical approach, anything a user can do is now possible in test automation code.\r</p>\n<p>This talk will go into detail explaining how Selenium and WebDriver (aka Selenium 2) work, comparing the strengths and weaknesses of each tool's approach to browser automation. The talk will then explain what Selenium 2.0 looks like and how to use it. \r</p>\n<p>Talk outline:\r</p>\n<ul>\n<li>Description of problem space\r<ul>\n<li>More browsers\r</li>\n<li>More frequent browser releases\r</li>\n<li>HTML 5 - video, canvas, offline storage\r</li>\n<li>The web in more places - Mobile, Chrome OS\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Description of Selenium\r</li>\n</ul>\n<ul>\n<li>Strengths of Selenium\r</li>\n</ul>\n<ul>\n<li>Description of challenges for Selenium 1\r<ul>\n<li>Javascript security sandbox\r</li>\n<li>Same origin policy / cross-site scripting\r</li>\n<li>OS-level popups\r</li>\n<li>Speed / stability\r</li>\n<li>Java as the cross-language integration point (aka Not Very Pythonic, eh?)\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Description of Selenium 2 (aka WebDriver)\r</li>\n</ul>\n<ul>\n<li>Strengths of Selenium 2\r</li>\n</ul>\n<ul>\n<li>How Selenium 2 is more pythonic\r<ul>\n<li>(Lots and lots of example code goes here.)\r</li>\n<li>Spoiler Alert: No Java server required!\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>How to test Android apps\r</li>\n<li>How to test iPhone apps\r</li>\n</ul>\n<ul>\n<li>Selenium development roadmap\r</li>\n</ul>\n", 
            "speaker": 215, 
            "submitted": "2010-11-02 06:44:45", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 17, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "This course is intended to introduce the attendee to various Python network manipulation libraries such as scapy, dpkt and impacket. Attendees will learn how to perform various tasks in Python that aid them in reading, building, writing, manipulating, generating and replaying custom network data.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "While the term \"packet\" is generally used in context of IP, the term \"packet crafting\" is most often used to describe the manipulation of network data at multiple layers of the network stack. Packet crafting is a powerful skill the enables users to perform a wide variety of tasks including network auditing, application testing, system fingerprinting and protocol fuzzing.\r\n", 
            "title": "Packet Crafting with Python", 
            "plenary": false, 
            "abstract_html": "<p>While the term \"packet\" is generally used in context of IP, the term \"packet crafting\" is most often used to describe the manipulation of network data at multiple layers of the network stack. Packet crafting is a powerful skill the enables users to perform a wide variety of tasks including network auditing, application testing, system fingerprinting and protocol fuzzing.\r</p>\n", 
            "speaker": 41, 
            "submitted": "2010-10-11 22:50:44", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 14, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python is lucky enough to have a healthy ecosystem of virtual machines (VMs) exist. CPython, Jython, IronPython, and PyPy are all used extensively by people in real-world situations. This panel brings together a representative from each of the major VMs to discuss where they are now, going in the future, and to answer questions from the community.", 
            "additional_speakers": [
                24, 
                37, 
                39, 
                38
            ], 
            "session_type": 2, 
            "track": null, 
            "abstract": "All four major Python VMs will be represented:\r\n\r\n* [[http://www.python.org|CPython]] : Brett Cannon\r\n* [[http://www.jython.org|Jython]] : Frank Wierzbicki\r\n* [[http://ironpython.net/|IronPython]] : Dino Viehland\r\n* [[http://pypy.org/|PyPy]] : Maciej Fijalkowski\r\n\r\nModeration will be handled by Jacob Kaplan-Moss of [[http://www.djangoproject.com|Django]].", 
            "title": "Panel: Python VMs", 
            "plenary": false, 
            "abstract_html": "<p>All four major Python VMs will be represented:\r</p>\n<ul>\n<li><a href=\"http://www.python.org\">CPython</a> : Brett Cannon\r</li>\n<li><a href=\"http://www.jython.org\">Jython</a> : Frank Wierzbicki\r</li>\n<li><a href=\"http://ironpython.net/\">IronPython</a> : Dino Viehland\r</li>\n<li><a href=\"http://pypy.org/\">PyPy</a> : Maciej Fijalkowski\r</li>\n</ul>\n<p>Moderation will be handled by Jacob Kaplan-Moss of <a href=\"http://www.djangoproject.com\">Django</a>.</p>\n", 
            "speaker": 36, 
            "submitted": "2010-10-08 16:23:44", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 15, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python's dynamic nature, large standard library, and concern for beauty over performance make it an elegant and uniquely easy to use language, but they also cause some unique problems. In this talk we'll explore how features ranging from dictionaries to duck typing can become security risks, demonstrate those attacks on real Python projects, and examine how you can protect yourself and your code.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Over the last decade, an increasing body of evidence has accumulated indicating that even when a system is hardened enough to provide strong guarantees about its high-level behavior, implementation details and especially performance properties can still provide attackers with an easy way in. For Python, this is especially problematic: its generally high-level view and the emphasis placed on flexibility often mean that it can be difficult to stop attackers from gaining a foothold, while its comparatively low execution speed increases the efficacy of wide variety of implementation and timing attacks.\r\n\r\nTo help Pythonistas understand and cope with these problems, we've divided this talk into two parts: in the first, we demonstrate the attacks against a series of widely-deployed Python projects with the goal of both improving awareness about the issue and demonstrating common weaknesses to be avoided. The second demonstrates effective countermeasures and alternative constructions with the goal of improving defenders' odds of spotting and correcting these flaws in their own code.", 
            "title": "Through the Side Channel: Timing and Implementation Attacks in Python", 
            "plenary": false, 
            "abstract_html": "<p>Over the last decade, an increasing body of evidence has accumulated indicating that even when a system is hardened enough to provide strong guarantees about its high-level behavior, implementation details and especially performance properties can still provide attackers with an easy way in. For Python, this is especially problematic: its generally high-level view and the emphasis placed on flexibility often mean that it can be difficult to stop attackers from gaining a foothold, while its comparatively low execution speed increases the efficacy of wide variety of implementation and timing attacks.\r</p>\n<p>To help Pythonistas understand and cope with these problems, we've divided this talk into two parts: in the first, we demonstrate the attacks against a series of widely-deployed Python projects with the goal of both improving awareness about the issue and demonstrating common weaknesses to be avoided. The second demonstrates effective countermeasures and alternative constructions with the goal of improving defenders' odds of spotting and correcting these flaws in their own code.</p>\n", 
            "speaker": 8, 
            "submitted": "2010-10-09 04:11:51", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 21, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "A look at the strategies for porting to Python 3, and a quick look of the most common problems.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk is split into three parts. The first will look at the different options in how to handle Python 3 porting. Do you need to support Python 2, or just port once? Should your code run unmodified or via 2to3, etc. It will in depth take up the benefits and problems with each strategy to let you choose, and also give quick examples of how to port with each strategy.\r\n\r\nThe second part looks at how you should prepare before porting, and things you can do right now to improve your code and make porting easier, even though you don't plan to port yet.\r\n\r\nThe third part will take up the most common problems in porting, and how you can solve them.\r\n\r\n=== Choosing a strategy\r\n* Only support Python 3\r\n* Separate branches\r\n* Continuous conversion with 2to3\r\n* Single code base; no conversion\r\n=== Preparing for the port\r\n* Get rid of warnings\r\n* Use {{{//}}} instead of /\r\n* Integers don't float\r\n* Iterator methods\r\n* Sorting (*)\r\n* Put an in in it (*)\r\n* Prepare for bytes\r\n* Write tests\r\n=== Common Problems\r\n* Comparisons\r\n* Unorderable types\r\n* Bytes vs Strings vs Unicode (+)\r\n* Doctests (*)\r\n* If you don't use 2to3: (*)\r\n** Stdlib reorg (*)\r\n** try/except (*)\r\n** print vs print() (*)\r\n* C-code (*)\r\n\r\nThe sections with (*) will be skipped if this gets a short slot. The (+) section will be cut down.", 
            "title": "Porting to Python 3", 
            "plenary": false, 
            "abstract_html": "<p>This talk is split into three parts. The first will look at the different options in how to handle Python 3 porting. Do you need to support Python 2, or just port once? Should your code run unmodified or via 2to3, etc. It will in depth take up the benefits and problems with each strategy to let you choose, and also give quick examples of how to port with each strategy.\r</p>\n<p>The second part looks at how you should prepare before porting, and things you can do right now to improve your code and make porting easier, even though you don't plan to port yet.\r</p>\n<p>The third part will take up the most common problems in porting, and how you can solve them.\r</p>\n<h3>Choosing a strategy</h3>\n<ul>\n<li>Only support Python 3\r</li>\n<li>Separate branches\r</li>\n<li>Continuous conversion with 2to3\r</li>\n<li>Single code base; no conversion\r</li>\n</ul>\n<h3>Preparing for the port</h3>\n<ul>\n<li>Get rid of warnings\r</li>\n<li>Use <tt>//</tt> instead of /\r</li>\n<li>Integers don't float\r</li>\n<li>Iterator methods\r</li>\n<li>Sorting (*)\r</li>\n<li>Put an in in it (*)\r</li>\n<li>Prepare for bytes\r</li>\n<li>Write tests\r</li>\n</ul>\n<h3>Common Problems</h3>\n<ul>\n<li>Comparisons\r</li>\n<li>Unorderable types\r</li>\n<li>Bytes vs Strings vs Unicode (+)\r</li>\n<li>Doctests (*)\r</li>\n<li>If you don't use 2to3: (*)\r<ul>\n<li>Stdlib reorg (*)\r</li>\n<li>try/except (*)\r</li>\n<li>print vs print() (*)\r</li>\n</ul>\n</li>\n<li>C-code (*)\r</li>\n</ul>\n<p>The sections with (*) will be skipped if this gets a short slot. The (+) section will be cut down.</p>\n", 
            "speaker": 46, 
            "submitted": "2010-10-13 03:31:52", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 25, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk will give a deep dive into how CPython uses memory. I'll be demonstrating a new tool I've written that analyses CPython's memory usage, and offer hints and tips on how you can reduce the memory footprint of your Python programs.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Is your Python program using too much memory?  This talk will give a deep dive into how CPython uses memory - starting from objects in your Python code, down through the various implementations layers, eventually reaching actual hardware.\r\n\r\nIn particular, I'll be demonstrating a new tool I've written that can [[https://fedorahosted.org/gdb-heap/|track CPython's memory usage]] down to the level of individual bytes, and offer hints and tips on how you can reduce the memory footprint of your Python programs.", 
            "title": "\"Dude, Where's My RAM?\" - A deep dive into how Python uses memory", 
            "plenary": false, 
            "abstract_html": "<p>Is your Python program using too much memory?  This talk will give a deep dive into how CPython uses memory - starting from objects in your Python code, down through the various implementations layers, eventually reaching actual hardware.\r</p>\n<p>In particular, I'll be demonstrating a new tool I've written that can <a href=\"https://fedorahosted.org/gdb-heap/\">track CPython's memory usage</a> down to the level of individual bytes, and offer hints and tips on how you can reduce the memory footprint of your Python programs.</p>\n", 
            "speaker": 52, 
            "submitted": "2010-10-15 14:54:48", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 27, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Got a difficult C/C++ program to debug?  The power of Python is now available from within the GNU debugger.  I'll show how you can use simple fragments of Python to quickly track down fiddly bugs in C/C++ code.  We'll also see how to use Python to extend gdb with new commands and new ways of visualizing the internal state of a program.  ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The GNU debugger, gdb, is the standard debugger when dealing with bugs in machine-code programs on Linux systems.  As of gdb7 it supports a Python interface, allowing experienced Python programmers to extend the reach of the debugger.  Difficult debugging tasks can be dramatically simplified by adding a little python.\r\n\r\nI'm the author of two substantial bodies of gdb python code: pretty-printers for Python itself, and for the GNU libc implementation of \"malloc/free\".", 
            "title": "Using Python to debug C and C++ code (using gdb)", 
            "plenary": false, 
            "abstract_html": "<p>The GNU debugger, gdb, is the standard debugger when dealing with bugs in machine-code programs on Linux systems.  As of gdb7 it supports a Python interface, allowing experienced Python programmers to extend the reach of the debugger.  Difficult debugging tasks can be dramatically simplified by adding a little python.\r</p>\n<p>I'm the author of two substantial bodies of gdb python code: pretty-printers for Python itself, and for the GNU libc implementation of \"malloc/free\".</p>\n", 
            "speaker": 52, 
            "submitted": "2010-10-15 18:01:46", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 33, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "WSGI has been around for quite a few years now, and has progressed somewhat into a movement in the web development world.  The purpose of this panel is to get the experts developing the spec together in a public domain to talk about the past, present, and future of WSGI.\r\n", 
            "additional_speakers": [], 
            "session_type": 2, 
            "track": null, 
            "abstract": "I will introduce myself, explain what my credentials are as speaker, and what the purpose of the panel is  I will then introduce each one of the speakers, and explain a bit about why they have been invited as a panelist.  I will then start in on my \"Starter Questions\" and after the first few are answered, I will open the questions up to #wsgipanel on Twitter, selecting from my starter questions and what comes through on the feed.\r\n", 
            "title": "WSGI: Working together to solve the web's problems ", 
            "plenary": false, 
            "abstract_html": "<p>I will introduce myself, explain what my credentials are as speaker, and what the purpose of the panel is  I will then introduce each one of the speakers, and explain a bit about why they have been invited as a panelist.  I will then start in on my \"Starter Questions\" and after the first few are answered, I will open the questions up to #wsgipanel on Twitter, selecting from my starter questions and what comes through on the feed.\r</p>\n", 
            "speaker": 51, 
            "submitted": "2010-10-19 16:06:20", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 32, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "Distributing and Documenting code is a place where a lot of projects are held up because these things are often perceived as difficult to someone that just has a few python scripts lying around that they want to share.  The aim of this tutorial is to train folks on how to package their software and provide an easier\r\nway to provide documentation.\r\n", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "The first part of this tutorial will focus on packaging, and how to create a repeatable install process.  This is important because most python packages rely on other packages, and getting the dependencies to work is often a challenge with our current python packaging toolset.  I will show attendees how to set up a private index whereby the user will have complete control over the packages that are installed.  I will explain a little about how setup.py works in a package, and what we can do to ensure packages install as expected.\r\n\r\nThe second part of the tutorial will help the user get started with documentation.  This is a skill I have shown a number of pythonistas in the past, and the result was documentation for Jython, ConfigObj, and others. I will show users how Sphinx can provide both a narrative and api-style documentation for their codebase,  and how that documentation becomes a living, tested document through the usage of doctests.\r\n\r\nFor this tutorial, people are welcome to bring their own code that they'd like to document and/or distribute. I am happy to work on the fly with an existing codebase, and will have a few volunteers lined up to help me with this.\r\n\r\n=== Intro Talk ===\r\n\r\nA 15 minute talk about packaging, distribution, and the problems usingtools like Paster, PIP, Virtualenv, and Basketweaver solve. Also, I will introduce Sphinx, and describe the way the class will work.\r\n\r\n=== Part I ===\r\n\r\n* Installation of virtualenv, pastescript, pip, and basketweaver (5 minutes)\r\n\r\n* Creation of a \"development\" virtualenv. (5 minutes)\r\n\r\n* Participant volunteers to explain their codebase. (5 minutes)\r\n\r\n* Splitting into groups, and sharing codebases. (15 minutes)\r\n\r\n* Using PasteScript to create a package, install that package, and create a distributable egg. (15 minutes)\r\n\r\n* Modifying your egg to depend on other python packages. (5 minutes)* Creating a personal pypi using basketweaver. (10 minutes)\r\n\r\n* Creation of a \"deployment\" virtualenv. (5 minutes)\r\n\r\n* Loading your deployment virtualenv with your new package. (10 minutes)\r\n\r\n* (optional) uploading your package to the official pypi\r\n\r\n* (optional) discussion on namespacing\r\n\r\n=== Part II ===\r\n\r\n* Installation of Sphinx (5 minutes)\r\n\r\n* Quickstart of sphinx package, HTML generation ( 10 minutes)\r\n\r\n* Review of ReST formatting ( 10 minutes)\r\n\r\n* Generating docs from your package's docstrings (10 minutes)\r\n\r\n* Autodoc Discussion. (10 minutes)\r\n\r\n* Adding and testing example source code. (30 minutes)\r\n\r\n* Theming and adding Feedback mechanisms. (15 minutes)\r\n\r\n* (optional) Adding your package documentation to packages.python.org\r\n\r\n=== Requirements ===\r\n\r\nLaptop with Python 2.5 or 2.6 installed.\r\n", 
            "title": "Packaging, Documenting, and Distributing your Python Codebase", 
            "plenary": false, 
            "abstract_html": "<p>The first part of this tutorial will focus on packaging, and how to create a repeatable install process.  This is important because most python packages rely on other packages, and getting the dependencies to work is often a challenge with our current python packaging toolset.  I will show attendees how to set up a private index whereby the user will have complete control over the packages that are installed.  I will explain a little about how setup.py works in a package, and what we can do to ensure packages install as expected.\r</p>\n<p>The second part of the tutorial will help the user get started with documentation.  This is a skill I have shown a number of pythonistas in the past, and the result was documentation for Jython, ConfigObj, and others. I will show users how Sphinx can provide both a narrative and api-style documentation for their codebase,  and how that documentation becomes a living, tested document through the usage of doctests.\r</p>\n<p>For this tutorial, people are welcome to bring their own code that they'd like to document and/or distribute. I am happy to work on the fly with an existing codebase, and will have a few volunteers lined up to help me with this.\r</p>\n<h3>Intro Talk</h3>\n<p>A 15 minute talk about packaging, distribution, and the problems usingtools like Paster, PIP, Virtualenv, and Basketweaver solve. Also, I will introduce Sphinx, and describe the way the class will work.\r</p>\n<h3>Part I</h3>\n<ul>\n<li>Installation of virtualenv, pastescript, pip, and basketweaver (5 minutes)\r</li>\n</ul>\n<ul>\n<li>Creation of a \"development\" virtualenv. (5 minutes)\r</li>\n</ul>\n<ul>\n<li>Participant volunteers to explain their codebase. (5 minutes)\r</li>\n</ul>\n<ul>\n<li>Splitting into groups, and sharing codebases. (15 minutes)\r</li>\n</ul>\n<ul>\n<li>Using PasteScript to create a package, install that package, and create a distributable egg. (15 minutes)\r</li>\n</ul>\n<ul>\n<li>Modifying your egg to depend on other python packages. (5 minutes)* Creating a personal pypi using basketweaver. (10 minutes)\r</li>\n</ul>\n<ul>\n<li>Creation of a \"deployment\" virtualenv. (5 minutes)\r</li>\n</ul>\n<ul>\n<li>Loading your deployment virtualenv with your new package. (10 minutes)\r</li>\n</ul>\n<ul>\n<li>(optional) uploading your package to the official pypi\r</li>\n</ul>\n<ul>\n<li>(optional) discussion on namespacing\r</li>\n</ul>\n<h3>Part II</h3>\n<ul>\n<li>Installation of Sphinx (5 minutes)\r</li>\n</ul>\n<ul>\n<li>Quickstart of sphinx package, HTML generation ( 10 minutes)\r</li>\n</ul>\n<ul>\n<li>Review of ReST formatting ( 10 minutes)\r</li>\n</ul>\n<ul>\n<li>Generating docs from your package's docstrings (10 minutes)\r</li>\n</ul>\n<ul>\n<li>Autodoc Discussion. (10 minutes)\r</li>\n</ul>\n<ul>\n<li>Adding and testing example source code. (30 minutes)\r</li>\n</ul>\n<ul>\n<li>Theming and adding Feedback mechanisms. (15 minutes)\r</li>\n</ul>\n<ul>\n<li>(optional) Adding your package documentation to packages.python.org\r</li>\n</ul>\n<h3>Requirements</h3>\n<p>Laptop with Python 2.5 or 2.6 installed.\r</p>\n", 
            "speaker": 51, 
            "submitted": "2010-10-19 10:44:55", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 34, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "mock is a Python testing library. It has the goal of making mocking in tests brain dead simple! mock provides the Mock class and the patch decorator for safely patching out the objects you are mocking in your tests. \r\n\r\nThis talk will cover standard mocking patterns. We'll also look at some of the newer features in the latest release, including support for mocking magic methods.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "mock provides a core Mock class that removes the need to create a host of trivial stubs throughout your test suite. After performing an action, you can make assertions about which methods / attributes were used and arguments they were called with. You can also specify return values and set specific attributes in the normal way.\r\n\r\n* http://www.voidspace.org.uk/python/mock/\r\n* http://pypi.python.org/pypi/mock/\r\n\r\nThe mock module also provides a patch() decorator that handles safely patching out the things you are mocking during your test.\r\n\r\nWe'll cover standard mocking patterns, and how mock makes them easy. We'll also be looking at some of the newer features in the latest release, including the magic method support that can be used (for example) for mocking out objects used as context managers.\r\n\r\nmock is designed for \"unit test style\" testing, but is used with Python testing libraries like nose and py.test.\r\n\r\nThere will be some emphasis on how *not* to use mocking in testing, and why 'over mocking' is bad (and makes for brittle tests).", 
            "title": "Testing with mock", 
            "plenary": false, 
            "abstract_html": "<p>mock provides a core Mock class that removes the need to create a host of trivial stubs throughout your test suite. After performing an action, you can make assertions about which methods / attributes were used and arguments they were called with. You can also specify return values and set specific attributes in the normal way.\r</p>\n<ul>\n<li><a href=\"http://www.voidspace.org.uk/python/mock/\">http://www.voidspace.org.uk/python/mock/</a>\r</li>\n<li><a href=\"http://pypi.python.org/pypi/mock/\">http://pypi.python.org/pypi/mock/</a>\r</li>\n</ul>\n<p>The mock module also provides a patch() decorator that handles safely patching out the things you are mocking during your test.\r</p>\n<p>We'll cover standard mocking patterns, and how mock makes them easy. We'll also be looking at some of the newer features in the latest release, including the magic method support that can be used (for example) for mocking out objects used as context managers.\r</p>\n<p>mock is designed for \"unit test style\" testing, but is used with Python testing libraries like nose and py.test.\r</p>\n<p>There will be some emphasis on how *not* to use mocking in testing, and why 'over mocking' is bad (and makes for brittle tests).</p>\n", 
            "speaker": 61, 
            "submitted": "2010-10-19 18:54:43", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 35, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Tornado is an open source version of the scalable, non-blocking web server and tools that power FriendFeed. It is not only a web server but it is a light-weight, use only what you need, web development framework.  In this talk we will review the current state of the Tornado project, review the features Tornado provides and give examples of how to implement asynchronous web applications in Tornado.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Tornado is an open source version of the scalable, non-blocking web server and tools that power FriendFeed. It is not only a web server but it is a light-weight, use only what you need, web development framework.  In this talk we will review the current state of the Tornado project, review the features Tornado provides and give examples of how to implement asynchronous web applications in Tornado.\r\n\r\nTopics covered will include:\r\n\r\n * Core Tornado concepts\r\n * Building an asynchronous web application\r\n * Using the Tornado template engine\r\n * Database Interaction\r\n * Secure cookies and Sessions\r\n * Utilizing built-in OAuth Clients for Authentication\r\n * Websockets\r\n * State of asynchronous drivers available to Tornado\r\n * A light introduction to Tornado internals", 
            "title": "An Introduction to Tornado", 
            "plenary": false, 
            "abstract_html": "<p>Tornado is an open source version of the scalable, non-blocking web server and tools that power FriendFeed. It is not only a web server but it is a light-weight, use only what you need, web development framework.  In this talk we will review the current state of the Tornado project, review the features Tornado provides and give examples of how to implement asynchronous web applications in Tornado.\r</p>\n<p>Topics covered will include:\r</p>\n<ul>\n<li>Core Tornado concepts\r</li>\n<li>Building an asynchronous web application\r</li>\n<li>Using the Tornado template engine\r</li>\n<li>Database Interaction\r</li>\n<li>Secure cookies and Sessions\r</li>\n<li>Utilizing built-in OAuth Clients for Authentication\r</li>\n<li>Websockets\r</li>\n<li>State of asynchronous drivers available to Tornado\r</li>\n<li>A light introduction to Tornado internals</li>\n</ul>\n", 
            "speaker": 63, 
            "submitted": "2010-10-20 11:33:47", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 37, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk will cover App Engine's new Pipeline API, which connects together complex, time-consuming work (including MapReduces and human actions) in a distributed system. The API transforms Python into an asynchronous language for describing data dependencies in a novel way. We will discuss how the API works, how it achieves parallelism, and how to reuse its design and code outside of App Engine.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Notably, the Pipeline API is being used by App Engine to connect the pieces of our MapReduce system. The API's key use-case is executing many MapReduces and offline processes in parallel to form a single data pipeline. This enables developers to very easily \"join\" data from disparate sources, which is one of the most difficult things to achieve in a distributed processing system. I'll show some specific examples of when you would want to \"fan-in\" and how to achieve that with the Pipeline API.", 
            "title": "Creating Complex Data Pipelines in the Cloud: The App Engine Pipeline API", 
            "plenary": false, 
            "abstract_html": "<p>Notably, the Pipeline API is being used by App Engine to connect the pieces of our MapReduce system. The API's key use-case is executing many MapReduces and offline processes in parallel to form a single data pipeline. This enables developers to very easily \"join\" data from disparate sources, which is one of the most difficult things to achieve in a distributed processing system. I'll show some specific examples of when you would want to \"fan-in\" and how to achieve that with the Pipeline API.</p>\n", 
            "speaker": 69, 
            "submitted": "2010-10-21 14:18:01", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 39, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "How do you manage a custom fork of Python for an unsupported OS running on custom hardware? That was the question at Vocollect, where we use Python on our wearable, voice-controlled computers. In this talk, I'll discuss how we did it, describe the problems and roadblocks we found, and show how we're managing our use of Python through 3.2 and beyond.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Vocollect produces voice-based wearable embedded devices for industry. We also provide a development environment that third-party developers can use to create applications to run on our devices, which are based on a customized version of Windows CE. Several years ago we decided to replace our 15-year-old graphical scripting environment with a better-supported scripting language.  In the end, we chose Python.\r\n\r\nWe originally started by modifying the open-source \"PythonCE\" project, but after significant effort, we realized that the result wasn't something that we'd be able to support long-term.\r\n\r\nHaving learned from that effort, we threw out the code, started with a clean trunk, and set down some internal guidelines for developing our own fork. As a result, we now have a cleaner, more maintainable port of Python customized for our platform, which we'll be able to keep in sync for years in the future.\r\n\r\nI'll talk about the specific challenges that made our first effort unsupportable, the guidelines we're using to prevent them from occurring again, and how recent developments like the Python 3 transition and the move to Mercurial have affected our efforts.", 
            "title": "Supporting CPython on Unsupported Platforms", 
            "plenary": false, 
            "abstract_html": "<p>Vocollect produces voice-based wearable embedded devices for industry. We also provide a development environment that third-party developers can use to create applications to run on our devices, which are based on a customized version of Windows CE. Several years ago we decided to replace our 15-year-old graphical scripting environment with a better-supported scripting language.  In the end, we chose Python.\r</p>\n<p>We originally started by modifying the open-source \"PythonCE\" project, but after significant effort, we realized that the result wasn't something that we'd be able to support long-term.\r</p>\n<p>Having learned from that effort, we threw out the code, started with a clean trunk, and set down some internal guidelines for developing our own fork. As a result, we now have a cleaner, more maintainable port of Python customized for our platform, which we'll be able to keep in sync for years in the future.\r</p>\n<p>I'll talk about the specific challenges that made our first effort unsupportable, the guidelines we're using to prevent them from occurring again, and how recent developments like the Python 3 transition and the move to Mercurial have affected our efforts.</p>\n", 
            "speaker": 68, 
            "submitted": "2010-10-22 14:55:08", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 40, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This session presents an experimental approach that uses mobile simulators - BlackBerry\u2122 and Android\u2122 to run automated end-to-end tests using the Python\u2122 programming language. We\u2019ll walk through the testing process - from the basics of interacting with both device simulators, writing reusable tests on both these devices and executing these tests in PyUnit. Sample code is included.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "If you like to learn about how to interact with BlackBerry and Android mobile simulators, then this session is for you. A step-by-step demo with code snippets on how to automate native mobile applications from running a use case/test, validating your test and reporting test results, and using Python mobile simulators libraries.  The tests can be reused to run against different resolutions and the framework can be used for different mobile platforms.\r\n\r\n**Key Takeaways:  What benefits will attendees get from participating in your session**\r\n----\r\n# Know  what tools are available in BlackBerry, Android\r\n# Learn how to abstract device-dependent test implementation from test cases\r\n# See a demo of tests using native Address Book application on BlackBerry and Android.\r\n# One is able to quickly automate tests after this session\r\n\r\n**Session Discussion Points**\r\n----\r\n\r\n**1. Overview : Tools in device simulators**\r\n\r\nOutline what the tools are in Android and BlackBerry simulators that will help users interact with the simulators. E.g. For BlackBerry, there is fledgecontroller. For Android, there is adb.\r\n\r\n**2. Introduce bblib.py and androidlib.py**\r\n\r\nShow how we can abstract these tools using Python and provide common interaction interface with both devices. Demo examples of commonly used commands in both Python libraries.\r\n\r\n{{{\r\n    def enter(string=None):\r\n        \"\"\" If string is None, simulate Enter key in simulator. \r\n\r\n    def backspaces(count=1):\r\n        \"\"\" Press backspaces specified by count.\"\"\"\r\n\r\n    def touch(xcoord, ycoord):\r\n        \"\"\" Touch screen at (xcoord, ycoord).\"\"\"\r\n\r\n    def thumbwheel(direction='up', count=1):\r\n\r\n    def trackball(direction='left', count=1):\r\n}}}\r\n\r\n**3. Writing device independent tests**\r\n{{{\r\n       #1. Use python name typing to decide the device to use\r\n       def getDevice(self):\r\n           mobileDevice = testenv.getDevice()\r\n           if mobileDevice == 'android':\r\n               deviceClass = android.AndroidImpl()\r\n           else:\r\n               deviceClass = bb.BlackBerryImpl()\r\n           log.debug('Device is ' + mobileDevice)\r\n           return deviceClass \r\n\r\n       #2. Usecase implementation\r\n      \r\n       # On BlackBerry\r\n       def login(username, password):\r\n           enter(username)\r\n           thumbwheel('down',1)\r\n           enter(password)\r\n           thumbwheel('down',1)\r\n           enter()\r\n\r\n      #3. Testcases (device independent) for Login\r\n\r\n      class LoginBAT(unittest.TestCase):\r\n          device = testlib.testenv.getDevice()\r\n\r\n          def testIncorrectUsername():\r\n              self.device.login(incorrectUser, correctPin)\r\n              self.assertTrue(imagelib.compare(self.device,\\\r\n              self._testMethodName, '100%x40%+0+35%'))\r\n\r\n          def testSuccessfulLogin():\r\n              self.device.login(correctUser,correctPin)\r\n              self.assertTrue(imagelib.compare(self.device,\\\r\n              self._testMethodName, '100%x40%+0+35%'))\r\n\r\n     Test assertion use imagelib.py - takes screenshot of current\r\n     image and compare with expected image with crop settings and \r\n     tolerance level using ImageMagick. \r\n\r\n     def compare(device, image, cropSettings=None, tolerance=500):\r\n\r\n     #4. Run test, showing assertion results.\r\n}}}\r\n\r\n**4. Summary : Test Framework**\r\n\r\nWalkthrough test framework architecture (diagram will be included). Lowest level is test utilities - imagelib.py, logger.py testlib.py (exceptions handling etc.). \r\n\r\nNext up is device simulator libraries - bblib.py, androidlib.py containing device controls. \r\n\r\nAbove this is application use case implementation, followed by end-to-end device independent tests. \r\n\r\nFinally, at the top layer is test runner and reporting framework.\r\n\r\n**5. Advantages and Limitations**\r\n\r\nAdvantages\r\n{{{\r\n- Zero startup cost low cost of maintenance\r\n- Can be agile\r\n- Full control of the devices\r\n- No sharing or scheduling of resources\r\n- Reuse of tests for different resolutions, OS and devices.\r\n}}}\r\nLimitations\r\n{{{\r\n- Device simulator is not suitable for hardware (e.g. blue tooth,\r\n  multimedia) and network configurations testing.\r\n- Does not simulate actual performance.\r\n- Does not test dynamic images or results well.\r\n}}}", 
            "title": "Mobile applications testing using Python - an experimental technique", 
            "plenary": false, 
            "abstract_html": "<p>If you like to learn about how to interact with BlackBerry and Android mobile simulators, then this session is for you. A step-by-step demo with code snippets on how to automate native mobile applications from running a use case/test, validating your test and reporting test results, and using Python mobile simulators libraries.  The tests can be reused to run against different resolutions and the framework can be used for different mobile platforms.\r</p>\n<p><b>Key Takeaways:  What benefits will attendees get from participating in your session</b>\r</p>\n<hr><ol>\n<li>Know  what tools are available in BlackBerry, Android\r</li>\n<li>Learn how to abstract device-dependent test implementation from test cases\r</li>\n<li>See a demo of tests using native Address Book application on BlackBerry and Android.\r</li>\n<li>One is able to quickly automate tests after this session\r</li>\n</ol>\n<p><b>Session Discussion Points</b>\r</p>\n<hr><p><b>1. Overview : Tools in device simulators</b>\r</p>\n<p>Outline what the tools are in Android and BlackBerry simulators that will help users interact with the simulators. E.g. For BlackBerry, there is fledgecontroller. For Android, there is adb.\r</p>\n<p><b>2. Introduce bblib.py and androidlib.py</b>\r</p>\n<p>Show how we can abstract these tools using Python and provide common interaction interface with both devices. Demo examples of commonly used commands in both Python libraries.\r</p>\n<pre>    def enter(string=None):\r\n        \"\"\" If string is None, simulate Enter key in simulator. \r\n\r\n    def backspaces(count=1):\r\n        \"\"\" Press backspaces specified by count.\"\"\"\r\n\r\n    def touch(xcoord, ycoord):\r\n        \"\"\" Touch screen at (xcoord, ycoord).\"\"\"\r\n\r\n    def thumbwheel(direction='up', count=1):\r\n\r\n    def trackball(direction='left', count=1):\r</pre><p><b>3. Writing device independent tests</b>\r</p>\n<pre>       #1. Use python name typing to decide the device to use\r\n       def getDevice(self):\r\n           mobileDevice = testenv.getDevice()\r\n           if mobileDevice == 'android':\r\n               deviceClass = android.AndroidImpl()\r\n           else:\r\n               deviceClass = bb.BlackBerryImpl()\r\n           log.debug('Device is ' + mobileDevice)\r\n           return deviceClass \r\n\r\n       #2. Usecase implementation\r\n      \r\n       # On BlackBerry\r\n       def login(username, password):\r\n           enter(username)\r\n           thumbwheel('down',1)\r\n           enter(password)\r\n           thumbwheel('down',1)\r\n           enter()\r\n\r\n      #3. Testcases (device independent) for Login\r\n\r\n      class LoginBAT(unittest.TestCase):\r\n          device = testlib.testenv.getDevice()\r\n\r\n          def testIncorrectUsername():\r\n              self.device.login(incorrectUser, correctPin)\r\n              self.assertTrue(imagelib.compare(self.device,\\\r\n              self._testMethodName, '100%x40%+0+35%'))\r\n\r\n          def testSuccessfulLogin():\r\n              self.device.login(correctUser,correctPin)\r\n              self.assertTrue(imagelib.compare(self.device,\\\r\n              self._testMethodName, '100%x40%+0+35%'))\r\n\r\n     Test assertion use imagelib.py - takes screenshot of current\r\n     image and compare with expected image with crop settings and \r\n     tolerance level using ImageMagick. \r\n\r\n     def compare(device, image, cropSettings=None, tolerance=500):\r\n\r\n     #4. Run test, showing assertion results.\r</pre><p><b>4. Summary : Test Framework</b>\r</p>\n<p>Walkthrough test framework architecture (diagram will be included). Lowest level is test utilities - imagelib.py, logger.py testlib.py (exceptions handling etc.). \r</p>\n<p>Next up is device simulator libraries - bblib.py, androidlib.py containing device controls. \r</p>\n<p>Above this is application use case implementation, followed by end-to-end device independent tests. \r</p>\n<p>Finally, at the top layer is test runner and reporting framework.\r</p>\n<p><b>5. Advantages and Limitations</b>\r</p>\n<p>Advantages\r</p>\n<pre>- Zero startup cost low cost of maintenance\r\n- Can be agile\r\n- Full control of the devices\r\n- No sharing or scheduling of resources\r\n- Reuse of tests for different resolutions, OS and devices.\r</pre><p>Limitations\r</p>\n<pre>- Device simulator is not suitable for hardware (e.g. blue tooth,\r\n  multimedia) and network configurations testing.\r\n- Does not simulate actual performance.\r\n- Does not test dynamic images or results well.\r</pre>", 
            "speaker": 71, 
            "submitted": "2010-10-22 19:37:40", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 41, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Javascript as a diff on Python.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "You know Python.  You should know Javascript.  The two aren't so different, but this talk will explain exactly how they are different -- lists, dicts, objects, functions, loops and all the other details of Javascript described in terms of Python.", 
            "title": "Javascript for people who know Python", 
            "plenary": false, 
            "abstract_html": "<p>You know Python.  You should know Javascript.  The two aren't so different, but this talk will explain exactly how they are different -- lists, dicts, objects, functions, loops and all the other details of Javascript described in terms of Python.</p>\n", 
            "speaker": 72, 
            "submitted": "2010-10-23 19:45:52", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 50, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "SOLVCON is the first Python-based software framework for high-resolution simulations of multi-physics conservation laws. More than ninety percents of the codes are done in Python. Performance hot-spots are optimized by C and glued by ctypes library. SOLVCON is high-performance in nature and has been able to utilize 512 4-core nodes at Ohio Supercomputer Center.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "In this decade, performance improvements of scientific computing will mainly come from major changes in the computing hardware. A well-organized software structure is imperative to accommodate such changes. Based on Python, [[http://solvcon.net/|SOLVCON (http://solvcon.net/)]] is designed as a software framework to develop conservation-law solvers by segregating solving kernels from various supportive functionalities. Being the governing equations for the physical world, conservation laws are applied everywhere in science and engineering. Although it is well known that the numerical algorithms and physical models form the kernel of any conservation-law solver, few if not none code can cleanly separate those core components from supportive functionalities. The lack of organization has hindered the development of legacy codes. To address the issues, the supportive functionalities are internalized in the framework of SOLVCON. Aided by the framework, both multi-physics and hybrid parallelism can be implemented in an organized way. To date, SOLVCON has utilized up to 512 4-core nodes at Ohio Supercomputer Center for high-resolution simulations of computational fluid dynamics (CFD). SOLVCON targets to concurrently utilize thousands of computer nodes for high-resolution simulations using over one billion mesh points.\r\n\r\nOne of the major purposes of SOLVCON is to resolve the complicated programming efforts for GPU clusters. Supercomputing is undergoing the third revolution by the emerging GPU computing. To date, the fastest supercomputer in the [[http://top500.org/|Top 500]] list, Tianhe-1A, is a GPU cluster.  GPU computing promises numerical analysts to reduce the time for the high-resolution simulations from months to days. In order to use GPU computing to accelerate such large-scale problems, GPU nodes must be networked together to form a GPU cluster. As such, shared-memory and distributed-memory parallelization must be simultaneously utilized to achieve the so-called hybrid parallelism. Parallel computing is difficult, and hybrid parallel computing is more difficult. By using Python to develop the fundamental software structure, GPU or multi-threaded programming for shared-memory parallelization are locked in solving kernels. Complex message-passing is implemented in SOLVCON and isolated from solving-kernel developers. Highly optimized C and GPU codes are glued into SOLVCON without loss of performance by using the ctypes package. Othere important features of SOLVCON include:\r\n\r\n* Pluggable multi-physics.\r\n* Built-in [[http://www.grc.nasa.gov/WWW/microbus/|CESE]] solvers.\r\n* Unstructured mesh consisting of mixed elements.\r\n* Interface to Message-Passing Interface (MPI) libraries.\r\n* Socket communication layer: working without MPI installed.\r\n* Automatic distributed-memory parallelization by domain decomposition.\r\n* Parallel I/O.\r\n* In situ visualization by [[http://vtk.org|VTK]] library.\r\n* Standalone writers to VTK legacy and XML file formats.\r\n* Integration to supercomputer (cluster) batch systems.\r\n\r\nSOLVCON has been applied to computation fluid dynamics and computational mechanics. More physical solvers are being developed for various propagating wave problems, e.g., electromagnetic waves. By using Python as the foundation in SOLVCON, performance and extensibility are well balanced, and computational research is being done in the most productive way. In this talk, the author of SOLVCON will make an introduction to the software framework by including the following topics:\r\n\r\n# Simulations of conservation laws and hybrid parallelism for supercomputing.\r\n# Issues in legacy codes and challenges to code for emerging supercomputer hardware.\r\n# Using SOLVCON in the simple way by pre-defined modules.\r\n# Fixed parts in SOLVCON.\r\n## Distributed computing.\r\n## Multi-thread utilities.\r\n# Customizable parts in SOLVCON.\r\n## Pluggable multi-physics and GPGPU computing.\r\n## Supercomputer batch system and bootstrapping.\r\n## In situ visualization.\r\n# Conclusion.\r\n\r\nThe talk will take 30 minutes.", 
            "title": "SOLVCON: A New Python-Based Software Framework for Massively Parallelized Numerical Simulations", 
            "plenary": false, 
            "abstract_html": "<p>In this decade, performance improvements of scientific computing will mainly come from major changes in the computing hardware. A well-organized software structure is imperative to accommodate such changes. Based on Python, <a href=\"http://solvcon.net/\">SOLVCON (http://solvcon.net/)</a> is designed as a software framework to develop conservation-law solvers by segregating solving kernels from various supportive functionalities. Being the governing equations for the physical world, conservation laws are applied everywhere in science and engineering. Although it is well known that the numerical algorithms and physical models form the kernel of any conservation-law solver, few if not none code can cleanly separate those core components from supportive functionalities. The lack of organization has hindered the development of legacy codes. To address the issues, the supportive functionalities are internalized in the framework of SOLVCON. Aided by the framework, both multi-physics and hybrid parallelism can be implemented in an organized way. To date, SOLVCON has utilized up to 512 4-core nodes at Ohio Supercomputer Center for high-resolution simulations of computational fluid dynamics (CFD). SOLVCON targets to concurrently utilize thousands of computer nodes for high-resolution simulations using over one billion mesh points.\r</p>\n<p>One of the major purposes of SOLVCON is to resolve the complicated programming efforts for GPU clusters. Supercomputing is undergoing the third revolution by the emerging GPU computing. To date, the fastest supercomputer in the <a href=\"http://top500.org/\">Top 500</a> list, Tianhe-1A, is a GPU cluster.  GPU computing promises numerical analysts to reduce the time for the high-resolution simulations from months to days. In order to use GPU computing to accelerate such large-scale problems, GPU nodes must be networked together to form a GPU cluster. As such, shared-memory and distributed-memory parallelization must be simultaneously utilized to achieve the so-called hybrid parallelism. Parallel computing is difficult, and hybrid parallel computing is more difficult. By using Python to develop the fundamental software structure, GPU or multi-threaded programming for shared-memory parallelization are locked in solving kernels. Complex message-passing is implemented in SOLVCON and isolated from solving-kernel developers. Highly optimized C and GPU codes are glued into SOLVCON without loss of performance by using the ctypes package. Othere important features of SOLVCON include:\r</p>\n<ul>\n<li>Pluggable multi-physics.\r</li>\n<li>Built-in <a href=\"http://www.grc.nasa.gov/WWW/microbus/\">CESE</a> solvers.\r</li>\n<li>Unstructured mesh consisting of mixed elements.\r</li>\n<li>Interface to Message-Passing Interface (MPI) libraries.\r</li>\n<li>Socket communication layer: working without MPI installed.\r</li>\n<li>Automatic distributed-memory parallelization by domain decomposition.\r</li>\n<li>Parallel I/O.\r</li>\n<li>In situ visualization by <a href=\"http://vtk.org\">VTK</a> library.\r</li>\n<li>Standalone writers to VTK legacy and XML file formats.\r</li>\n<li>Integration to supercomputer (cluster) batch systems.\r</li>\n</ul>\n<p>SOLVCON has been applied to computation fluid dynamics and computational mechanics. More physical solvers are being developed for various propagating wave problems, e.g., electromagnetic waves. By using Python as the foundation in SOLVCON, performance and extensibility are well balanced, and computational research is being done in the most productive way. In this talk, the author of SOLVCON will make an introduction to the software framework by including the following topics:\r</p>\n<ol>\n<li>Simulations of conservation laws and hybrid parallelism for supercomputing.\r</li>\n<li>Issues in legacy codes and challenges to code for emerging supercomputer hardware.\r</li>\n<li>Using SOLVCON in the simple way by pre-defined modules.\r</li>\n<li>Fixed parts in SOLVCON.\r<ol>\n<li>Distributed computing.\r</li>\n<li>Multi-thread utilities.\r</li>\n</ol>\n</li>\n<li>Customizable parts in SOLVCON.\r<ol>\n<li>Pluggable multi-physics and GPGPU computing.\r</li>\n<li>Supercomputer batch system and bootstrapping.\r</li>\n<li>In situ visualization.\r</li>\n</ol>\n</li>\n<li>Conclusion.\r</li>\n</ol>\n<p>The talk will take 30 minutes.</p>\n", 
            "speaker": 83, 
            "submitted": "2010-10-26 01:42:05", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 51, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Traditionally, C is the preferred language for low level network programming and works well for those who have the time and patience to work with it.  As it turns out, Python is very capable for prototyping low level network code, collecting data, and testing ideas quickly without getting lost in the land of C.  ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "While not as robust as C, python provides a simple and elegant solution for many cases to either prove a theory or gather data before developing a more robust solution. Obscure topics such as raw sockets, multicast, network bridging, rolling your own vpn, and disruption tolerant networking will be covered.  Use of python can enable building a custom protocols, debugging a network, fixing broken nets, custom logging and processing, and simulation of networks.  The author will talk about his experiences using python on linux for extreme network programming and possibilities for future efforts.\r\n", 
            "title": "Extreme Network Programming with Python and Linux", 
            "plenary": false, 
            "abstract_html": "<p>While not as robust as C, python provides a simple and elegant solution for many cases to either prove a theory or gather data before developing a more robust solution. Obscure topics such as raw sockets, multicast, network bridging, rolling your own vpn, and disruption tolerant networking will be covered.  Use of python can enable building a custom protocols, debugging a network, fixing broken nets, custom logging and processing, and simulation of networks.  The author will talk about his experiences using python on linux for extreme network programming and possibilities for future efforts.\r</p>\n", 
            "speaker": 66, 
            "submitted": "2010-10-26 01:48:31", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 52, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "PyReplica is a simple replication solution for PostgreSQL made with Python.\r\nIt's small and customizable with stability and performance in mind, and can be used to do Master-Slave and Multimaster asynchronic modes. \r\nIt also includes Alerce, a dbapi-2 wrapper to provide a synchronic replication method, load balancing and high availability to Python programs.", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "The poster will cover:\r\n\r\n* Overview of PyReplica and main features:\r\n** Python (PlPython) based, customizable KISS code\r\n** Master/Slave and limited Multimaster support\r\n** Two-Phase commit for psycopg2\r\n** Email Notifications\r\n** Conditional replication\r\n** Async/sync implementations\r\n* Case studies:\r\n** Backup and load balancing: dns mirroring\r\n** HA multimaster setup\r\n** Remote servers, conditional replication (POS)\r\n** Alerce: Syncronic replication for python (election counting)\r\n\r\nPresentation given at PgConBr 2009:\r\nhttps://docs.google.com/present/view?id=dd9bm82g_402fjtsdmdd\r\n\r\nPgFoundry project page:\r\nhttp://pgfoundry.org/projects/pyreplica/", 
            "title": "Introducing PyReplica: PostgreSQL replication really simple (pure Python!)", 
            "plenary": false, 
            "abstract_html": "<p>The poster will cover:\r</p>\n<ul>\n<li>Overview of PyReplica and main features:\r<ul>\n<li>Python (PlPython) based, customizable KISS code\r</li>\n<li>Master/Slave and limited Multimaster support\r</li>\n<li>Two-Phase commit for psycopg2\r</li>\n<li>Email Notifications\r</li>\n<li>Conditional replication\r</li>\n<li>Async/sync implementations\r</li>\n</ul>\n</li>\n<li>Case studies:\r<ul>\n<li>Backup and load balancing: dns mirroring\r</li>\n<li>HA multimaster setup\r</li>\n<li>Remote servers, conditional replication (POS)\r</li>\n<li>Alerce: Syncronic replication for python (election counting)\r</li>\n</ul>\n</li>\n</ul>\n<p>Presentation given at PgConBr 2009:\r <a href=\"https://docs.google.com/present/view?id=dd9bm82g_402fjtsdmdd\">https://docs.google.com/present/view?id=dd9bm82g_402fjtsdmdd</a>\r</p>\n<p>PgFoundry project page:\r <a href=\"http://pgfoundry.org/projects/pyreplica/\">http://pgfoundry.org/projects/pyreplica/</a></p>\n", 
            "speaker": 82, 
            "submitted": "2010-10-26 01:52:12", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 248, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk will go into detail on current cloud computing technology, specifically OpenStack and libvirt and how Python is the \"secret sauce\" that powers the open cloud. We'll show how to bring up your own cloud \"from scratch\", and explain why you would do such a thing.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Covered topics:\r\n* How to use VirtualBox\r\n* How to use kvm\r\n* How to use libvirt with Python\r\n* How to check out, build, and deploy OpenStack\r\n* How to setup and maintain your own cloud\r\n* Real world examples", 
            "title": "Python - The Secret Sauce in the Open Cloud", 
            "plenary": false, 
            "abstract_html": "<p>Covered topics:\r</p>\n<ul>\n<li>How to use VirtualBox\r</li>\n<li>How to use kvm\r</li>\n<li>How to use libvirt with Python\r</li>\n<li>How to check out, build, and deploy OpenStack\r</li>\n<li>How to setup and maintain your own cloud\r</li>\n<li>Real world examples</li>\n</ul>\n", 
            "speaker": 215, 
            "submitted": "2010-11-02 07:18:29", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 44, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "This is a course that will cover the Python-C API and will describe how to write a wrapper for a C library enabling it to be used from Python. It will not discuss all parts of the API but will focus on what's necessary to actually write a wrapper and do something useful. The tutorial will use [[http://sourceforge.net/projects/libcsv/|libcsv]] as a vehicle to teach the API.\r\n", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "While Python comes with batteries attached, it is sometimes necessary to drop down to lower levels for performance reasons or simply because an existing library already does all the low level work. The ability to \"wrap\" C libraries as Python modules makes Python a very effective \"glue language\". \r\n\r\nThere are many ways to wrap such libraries so as to make them accessible from within Python. This presentation will discuss the raw Python-C API and how it can be used to accomplish this. \r\n\r\nWe will take a simple C library ([[http://sourceforge.net/projects/libcsv/|libcsv]]) and write a wrapper for it enabling to be imported and used from within the Python interpreter as if it were a regular Python module. A sizeable fraction of the tutorial will be devoted to making the module a well behaved Python object (proper exceptions, string representations, object oriented handling etc.).\r\n\r\nThe presentation is designed to be practically useful rather than an in-depth technical discussion. The focus will be on getting the module to work rather than on all the details of the Python-C API.\r\n\r\nAll participants are expected to be comfortable with C and with Python itself. Lack of experience with C will make it hard to follow the tutorial. The presentation will be in a Gnu/Linux environment.\r\n\r\nThis tutorial will **not** cover ctypes, swig and any of the other extension writing tools. It will focus purely on the vanilla Python-C API.", 
            "title": "Writing Python extensions in C", 
            "plenary": false, 
            "abstract_html": "<p>While Python comes with batteries attached, it is sometimes necessary to drop down to lower levels for performance reasons or simply because an existing library already does all the low level work. The ability to \"wrap\" C libraries as Python modules makes Python a very effective \"glue language\". \r</p>\n<p>There are many ways to wrap such libraries so as to make them accessible from within Python. This presentation will discuss the raw Python-C API and how it can be used to accomplish this. \r</p>\n<p>We will take a simple C library (<a href=\"http://sourceforge.net/projects/libcsv/\">libcsv</a>) and write a wrapper for it enabling to be imported and used from within the Python interpreter as if it were a regular Python module. A sizeable fraction of the tutorial will be devoted to making the module a well behaved Python object (proper exceptions, string representations, object oriented handling etc.).\r</p>\n<p>The presentation is designed to be practically useful rather than an in-depth technical discussion. The focus will be on getting the module to work rather than on all the details of the Python-C API.\r</p>\n<p>All participants are expected to be comfortable with C and with Python itself. Lack of experience with C will make it hard to follow the tutorial. The presentation will be in a Gnu/Linux environment.\r</p>\n<p>This tutorial will <b>not</b> cover ctypes, swig and any of the other extension writing tools. It will focus purely on the vanilla Python-C API.</p>\n", 
            "speaker": 11, 
            "submitted": "2010-10-25 01:44:08", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 54, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Starting from a basic 'hello world' OpenGL app, a simple & Pythonic model of 3D polyhedra is presented, with neat generators to convert these into ctype arrays for OpenGL. Geometric algorithms then generate some fun geometry, and these are compounded to produce successively more complex & interesting shapes.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The author's intent is to demonstrate that effective stylistic 3D graphics can be achieved using surprisingly small amounts of code. This hopefully makes the topic amenable to 3D beginners, while possibly suggesting some alternative approaches to those with 3D experience.\r\n\r\n===Talk Outline\r\n\r\nThroughout, discussion of ideas and code dissection alternates with live animated demos, at 60fps on very modest hardware.\r\n\r\n# Inspirations - Effective non-photo-realistic work in gaming, movies and the demo scene. (1m)\r\n# A convenient & Pythonic way to model 3D polyhedra, and some neat generators to convert these into OpenGL arrays at runtime. (7m)\r\n# Composition of polyhedra to create more complex shapes. (3m)\r\n# The resulting performance characteristics: What works well from Python, and what doesn't. (2m)\r\n# Koch tetrahedron & tetrix, aka Sierpinski tetrahedron. (1m)\r\n# Surprisingly effective 3D models created from small bitmaps. (1m)\r\n# Automatic generation of trees, mazes, complex spaces. (3m)\r\n# Algorithmic modification of existing shapes, such as bevels, geometric duals, and polyhedron stellation. (2m)\r\n# Shapes that morph: Rearranging vertices on the fly (5m)\r\n# Questions (5m)\r\n\r\nThe ideas demonstrated in the talk are written against OpenGL 2.1, but written in a 'mostly OpenGL 3' style, using vertex buffer objects or vertex arrays.\r\n\r\nThe demo code uses pyglet to create a window and handle GUI events, and uses PyOpenGL for the majority of OpenGL calls, since it provides a more friendly and Pythonic interface. In the performance-sensitive inner render loop, however, I use pyglet's slightly more bare-bones OpenGL bindings.\r\n\r\nHowever, the majority of the talk focuses on the manipulation of abstract data structures to represent geometry, which is not affected by these or other OpenGL library choices.\r\n\r\nThis is a substantially improved version of the talk 'Flying High: Hobbyist OpenGL from Python', previously presented at EuroPython 2010.\r\n", 
            "title": "Algorithmic Generation of OpenGL Geometry", 
            "plenary": false, 
            "abstract_html": "<p>The author's intent is to demonstrate that effective stylistic 3D graphics can be achieved using surprisingly small amounts of code. This hopefully makes the topic amenable to 3D beginners, while possibly suggesting some alternative approaches to those with 3D experience.\r</p>\n<h3>Talk Outline</h3>\n<p>Throughout, discussion of ideas and code dissection alternates with live animated demos, at 60fps on very modest hardware.\r</p>\n<ol>\n<li>Inspirations - Effective non-photo-realistic work in gaming, movies and the demo scene. (1m)\r</li>\n<li>A convenient &amp; Pythonic way to model 3D polyhedra, and some neat generators to convert these into OpenGL arrays at runtime. (7m)\r</li>\n<li>Composition of polyhedra to create more complex shapes. (3m)\r</li>\n<li>The resulting performance characteristics: What works well from Python, and what doesn't. (2m)\r</li>\n<li>Koch tetrahedron &amp; tetrix, aka Sierpinski tetrahedron. (1m)\r</li>\n<li>Surprisingly effective 3D models created from small bitmaps. (1m)\r</li>\n<li>Automatic generation of trees, mazes, complex spaces. (3m)\r</li>\n<li>Algorithmic modification of existing shapes, such as bevels, geometric duals, and polyhedron stellation. (2m)\r</li>\n<li>Shapes that morph: Rearranging vertices on the fly (5m)\r</li>\n<li>Questions (5m)\r</li>\n</ol>\n<p>The ideas demonstrated in the talk are written against OpenGL 2.1, but written in a 'mostly OpenGL 3' style, using vertex buffer objects or vertex arrays.\r</p>\n<p>The demo code uses pyglet to create a window and handle GUI events, and uses PyOpenGL for the majority of OpenGL calls, since it provides a more friendly and Pythonic interface. In the performance-sensitive inner render loop, however, I use pyglet's slightly more bare-bones OpenGL bindings.\r</p>\n<p>However, the majority of the talk focuses on the manipulation of abstract data structures to represent geometry, which is not affected by these or other OpenGL library choices.\r</p>\n<p>This is a substantially improved version of the talk 'Flying High: Hobbyist OpenGL from Python', previously presented at EuroPython 2010.\r</p>\n", 
            "speaker": 20, 
            "submitted": "2010-10-26 10:06:20", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 56, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Django Packages is the place to review Django apps, frameworks, and projects. This talk is for everyone, including non-Django users, and covers everything from architecture, API development, to interacting with PyPI, Github, Bitbucket, etc. It will include tools, lessons learned, and projects that fork the code to save the world and will finish with an overview of the forthcoming pypackages.com.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Since launch [[http://djangopackages.com|Django Packages]] has become the place to find and compare apps, frameworks and projects produced by the Django Community. Through the use of public APIs, Django Packages constantly fetches hard data from **PyPI**, **Github**, and **Bitbucket**, aproviding a powerful mash-up of real-world data on the volume of usage of a particular package. At a glance you can see which package is the most downloaded, which is the most used, and which has seen ongoing development.\r\n\r\nThe project is open sourced on [[http://github.com/django-packages/django-packages|Github]], with all non-user data accessible available via the  [[http://www.djangopackages.com/api/v1/docs/|API]]. Django Packages was conceived and and launched in the [[http://djangodash.com/|2010 Django Dash]]. Since launch it has seen features added incrementally and was a frequently mentioned project at the 2010 DjangoCon and was #1 on [[http://news.ycombinator.com/|Hacker News]] on Sunday, December 5, 2010.  It's purpose is to provide a place for Django Developers to submit, research, and review apps, projects, and frameworks. \r\n\r\nThe talk will cover:\r\n\r\n* Launching the project\r\n** The pre-Django Packages state of finding Django apps\r\n** Grids, not tags\r\n** Only hard metrics allowed, no opinions or rating systems!\r\n** Slurping content from PyPI, Github, Bitbucket, Launchpad, SourceForge, and Google Project Hosting\r\n** Lessons Learned AKA The Zen of Python and PEP-8\r\n** Deployment and backups\r\n* The Month after launch\r\n** New feature considerations\r\n** Handing over the keys to reduce bus factor\r\n** Excitement when seeing it being used as a reference\r\n* DjangoCon\r\n** Sprint tactics for your pet project\r\n** Development of an API\r\n** Github, Google Project Hosting, and PyPI\r\n* Going forward\r\n** Planned new features for Django Packages\r\n** Forking Django Packages to save the world\r\n** pypackages.com - a forthcoming place to review Python applications, frameworks, and packages\r\n\r\nIf a 45 minute slot is assigned to this talk, then these elements will be added:\r\n\r\n* Launching the project\r\n** Architecture\r\n* The Month after launch\r\n** Optimization\r\n** Promotion\r\n* DjangoCon\r\n** More optimization\r\n", 
            "title": "Django Packages: A Case Study", 
            "plenary": false, 
            "abstract_html": "<p>Since launch <a href=\"http://djangopackages.com\">Django Packages</a> has become the place to find and compare apps, frameworks and projects produced by the Django Community. Through the use of public APIs, Django Packages constantly fetches hard data from <b>PyPI</b>, <b>Github</b>, and <b>Bitbucket</b>, aproviding a powerful mash-up of real-world data on the volume of usage of a particular package. At a glance you can see which package is the most downloaded, which is the most used, and which has seen ongoing development.\r</p>\n<p>The project is open sourced on <a href=\"http://github.com/django-packages/django-packages\">Github</a>, with all non-user data accessible available via the  <a href=\"http://www.djangopackages.com/api/v1/docs/\">API</a>. Django Packages was conceived and and launched in the <a href=\"http://djangodash.com/\">2010 Django Dash</a>. Since launch it has seen features added incrementally and was a frequently mentioned project at the 2010 DjangoCon and was #1 on <a href=\"http://news.ycombinator.com/\">Hacker News</a> on Sunday, December 5, 2010.  It's purpose is to provide a place for Django Developers to submit, research, and review apps, projects, and frameworks. \r</p>\n<p>The talk will cover:\r</p>\n<ul>\n<li>Launching the project\r<ul>\n<li>The pre-Django Packages state of finding Django apps\r</li>\n<li>Grids, not tags\r</li>\n<li>Only hard metrics allowed, no opinions or rating systems!\r</li>\n<li>Slurping content from PyPI, Github, Bitbucket, Launchpad, SourceForge, and Google Project Hosting\r</li>\n<li>Lessons Learned AKA The Zen of Python and PEP-8\r</li>\n<li>Deployment and backups\r</li>\n</ul>\n</li>\n<li>The Month after launch\r<ul>\n<li>New feature considerations\r</li>\n<li>Handing over the keys to reduce bus factor\r</li>\n<li>Excitement when seeing it being used as a reference\r</li>\n</ul>\n</li>\n<li>DjangoCon\r<ul>\n<li>Sprint tactics for your pet project\r</li>\n<li>Development of an API\r</li>\n<li>Github, Google Project Hosting, and PyPI\r</li>\n</ul>\n</li>\n<li>Going forward\r<ul>\n<li>Planned new features for Django Packages\r</li>\n<li>Forking Django Packages to save the world\r</li>\n<li>pypackages.com - a forthcoming place to review Python applications, frameworks, and packages\r</li>\n</ul>\n</li>\n</ul>\n<p>If a 45 minute slot is assigned to this talk, then these elements will be added:\r</p>\n<ul>\n<li>Launching the project\r<ul>\n<li>Architecture\r</li>\n</ul>\n</li>\n<li>The Month after launch\r<ul>\n<li>Optimization\r</li>\n<li>Promotion\r</li>\n</ul>\n</li>\n<li>DjangoCon\r<ul>\n<li>More optimization\r</li>\n</ul>\n</li>\n</ul>\n", 
            "speaker": 15, 
            "submitted": "2010-10-26 19:17:30", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 58, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python provides many features for introspecting, analyzing, parsing, compiling, and otherwise grokking Python code.  This talk will cover a number of the techniques for writing Python-Aware Python, and will hopefully inspire you to build the next great Python tool.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Python provides many features for introspecting, analyzing, parsing, compiling, and otherwise grokking Python code.  These modules and techniques provide the foundation for developer's tools such as autocompletion IDE's, code analysis tools, test runners, profilers, and so on.  \r\n\r\nI'll delve into a number of the common techniques used to write Python-Aware Python.  Each has its area of applicability and its strengths and weaknesses. I'll demonstrate small samples that show how those techniques underlie the tools we all know and love.\r\n\r\nThe world of Python tools is ready for new exploration.  This talk will give you the foundation you need to write the next great Python-aware application.", 
            "title": "Python-Aware Python", 
            "plenary": false, 
            "abstract_html": "<p>Python provides many features for introspecting, analyzing, parsing, compiling, and otherwise grokking Python code.  These modules and techniques provide the foundation for developer's tools such as autocompletion IDE's, code analysis tools, test runners, profilers, and so on.  \r</p>\n<p>I'll delve into a number of the common techniques used to write Python-Aware Python.  Each has its area of applicability and its strengths and weaknesses. I'll demonstrate small samples that show how those techniques underlie the tools we all know and love.\r</p>\n<p>The world of Python tools is ready for new exploration.  This talk will give you the foundation you need to write the next great Python-aware application.</p>\n", 
            "speaker": 92, 
            "submitted": "2010-10-26 22:30:38", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 60, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "A three-for-one talk by the main developers of three popular Python web frameworks!  We'll (very) briefly cover the state of each of our individual frameworks and communities, and then we'll describe the results of our efforts to work together and share code.", 
            "additional_speakers": [
                97, 
                170
            ], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Pylons is a popular, lightweight Python web framework.\r\n\r\nTurboGears 2 is a full-stack framework built atop Pylons.\r\n\r\nrepoze.bfg is a moderately popular, lightweight Python web framework.\r\n\r\nThe main developers and community leaders of these frameworks have been working together and sharing as much as possible over the course of roughly the last year.  We'll very briefly describe to the audience the states of our individual efforts, then we'll discuss how we intend to move forward and share more code and effort in the year to come.  The talk will be more socially-oriented than technical.\r\n\r\nIt's unusual for open source code and communities to bridge minor perceived differences in scope and style and to start sharing code and ideas openly.  If you're a user of any of these frameworks, you'll want to be present for this talk.\r\n", 
            "title": "State of Pylons/TurboGears 2/repoze.bfg", 
            "plenary": false, 
            "abstract_html": "<p>Pylons is a popular, lightweight Python web framework.\r</p>\n<p>TurboGears 2 is a full-stack framework built atop Pylons.\r</p>\n<p>repoze.bfg is a moderately popular, lightweight Python web framework.\r</p>\n<p>The main developers and community leaders of these frameworks have been working together and sharing as much as possible over the course of roughly the last year.  We'll very briefly describe to the audience the states of our individual efforts, then we'll discuss how we intend to move forward and share more code and effort in the year to come.  The talk will be more socially-oriented than technical.\r</p>\n<p>It's unusual for open source code and communities to bridge minor perceived differences in scope and style and to start sharing code and ideas openly.  If you're a user of any of these frameworks, you'll want to be present for this talk.\r</p>\n", 
            "speaker": 95, 
            "submitted": "2010-10-27 00:38:25", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 68, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "A numerical algorithm for designing on-board aircraft engine diagnostics has been implemented in Python. Employing the optimization techniques within SciPy, the code performs a search for an optimal vector of parameters for estimating engine variables, including exhaust temperatures and thrust. The algorithm exploits the numerical strengths of Python and SciPy for speed and interoperability.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "An emerging field of aircraft engine diagnostics is the inclusion of on-board engine performance tracking algorithms.  These algorithms utilize data provided by a limited number of engine sensors to determine the current engine performance, which tends to degrade over time.  However, estimating engine performance instantaneously is problematic due to the limited number of sensors normally available on a commercial aircraft engine.\r\n\r\nOne common practice is to estimate and track engine performance in software using a Kalman filter, a mathematical construct for tuning a numerical model to better track actual measurements  (1).  A new technique has been devised to optimize the design of this filter in aircraft engine applications (2).   An optimization procedure to aid in the design of the filter has been implemented in Python and exercised against the significant number of minimization and optimization strategies available in SciPy.  The talk focuses on the design of this optimization procedure in Python.  The object-oriented nature of Python offers benefits over alternative numerical languages; speed, availability, and maintainability played central roles in the selection of Python as the implementation language.   The availability of the multiprocessing module allowed for full utilization of modern multi-core CPUs, in contrast with often limited commercial numerical computing packages, further improving computational speed.\r\n\r\nSome difficulties were encountered during this design exercise.  Discussion of these obstacles and their eventual solution is presented.  Specifically, iterative solvers for the discrete algebraic Riccati equation and the discrete Lyapunov equation had to be authored in Python (3,4).  Additional framework for working with discrete state-space control systems was created, exploiting the object-oriented features of the language (5).  \r\n\r\nThe Python implementation was able to verify the solution of the optimization problem.  Comparison with an alternative, reference MATLAB implementation will be presented briefly.  The results of this research is planned to be presented at the American Society for Mechanical Engineers Turbo Expo 2011 Conference in June, 2011 (6).  The algorithm design in Python is meant to showcase the ability to perform controls engineering tasks in the Python language efficiently.\r\n--\r\n1. \u201cKalman Filter,\u201d Wikipedia: http://en.wikipedia.org/wiki/Kalman_filter\r\n\r\n2. Simon, D. L. and Garg, S., \u201cOptimal Tuner Selection for Kalman Filter-Based Aircraft Engine Performance Estimation\u201d. Journal of Engineering for Gas Turbines and Power. March 2010, Vol. 132.\r\n\r\n3. \u201cAlgebraic Riccati Equation,\u201d Wikipedia: http://en.wikipedia.org/wiki/Algebraic_Riccati_equation\r\n\r\n4. \u201cLyapunov Equation,\u201d Wikipedia: http://en.wikipedia.org/wiki/Lyapunov_equation\r\n\r\n5. \u201cState Space,\u201d Wikipedia: http://en.wikipedia.org/wiki/State-space\r\n\r\n6. Simon, D. L., Armstrong, J. B., \"Application of an Optimal Tuner Selection Approach for On-Board Self-Tuning Engine Models,\" Proceedings of the ASME Turbo Expo 2011, GT2011-46408, 2011 (To Be Published).\r\n\r\n\r\n\r\n", 
            "title": "Optimal Aircraft Engine Tuner Selection in Python", 
            "plenary": false, 
            "abstract_html": "<p>An emerging field of aircraft engine diagnostics is the inclusion of on-board engine performance tracking algorithms.  These algorithms utilize data provided by a limited number of engine sensors to determine the current engine performance, which tends to degrade over time.  However, estimating engine performance instantaneously is problematic due to the limited number of sensors normally available on a commercial aircraft engine.\r</p>\n<p>One common practice is to estimate and track engine performance in software using a Kalman filter, a mathematical construct for tuning a numerical model to better track actual measurements  (1).  A new technique has been devised to optimize the design of this filter in aircraft engine applications (2).   An optimization procedure to aid in the design of the filter has been implemented in Python and exercised against the significant number of minimization and optimization strategies available in SciPy.  The talk focuses on the design of this optimization procedure in Python.  The object-oriented nature of Python offers benefits over alternative numerical languages; speed, availability, and maintainability played central roles in the selection of Python as the implementation language.   The availability of the multiprocessing module allowed for full utilization of modern multi-core CPUs, in contrast with often limited commercial numerical computing packages, further improving computational speed.\r</p>\n<p>Some difficulties were encountered during this design exercise.  Discussion of these obstacles and their eventual solution is presented.  Specifically, iterative solvers for the discrete algebraic Riccati equation and the discrete Lyapunov equation had to be authored in Python (3,4).  Additional framework for working with discrete state-space control systems was created, exploiting the object-oriented features of the language (5).  \r</p>\n<p>The Python implementation was able to verify the solution of the optimization problem.  Comparison with an alternative, reference MATLAB implementation will be presented briefly.  The results of this research is planned to be presented at the American Society for Mechanical Engineers Turbo Expo 2011 Conference in June, 2011 (6).  The algorithm design in Python is meant to showcase the ability to perform controls engineering tasks in the Python language efficiently.\r --\r 1. \u201cKalman Filter,\u201d Wikipedia: <a href=\"http://en.wikipedia.org/wiki/Kalman_filter\">http://en.wikipedia.org/wiki/Kalman_filter</a>\r</p>\n<p>2. Simon, D. L. and Garg, S., \u201cOptimal Tuner Selection for Kalman Filter-Based Aircraft Engine Performance Estimation\u201d. Journal of Engineering for Gas Turbines and Power. March 2010, Vol. 132.\r</p>\n<p>3. \u201cAlgebraic Riccati Equation,\u201d Wikipedia: <a href=\"http://en.wikipedia.org/wiki/Algebraic_Riccati_equation\">http://en.wikipedia.org/wiki/Algebraic_Riccati_equation</a>\r</p>\n<p>4. \u201cLyapunov Equation,\u201d Wikipedia: <a href=\"http://en.wikipedia.org/wiki/Lyapunov_equation\">http://en.wikipedia.org/wiki/Lyapunov_equation</a>\r</p>\n<p>5. \u201cState Space,\u201d Wikipedia: <a href=\"http://en.wikipedia.org/wiki/State-space\">http://en.wikipedia.org/wiki/State-space</a>\r</p>\n<p>6. Simon, D. L., Armstrong, J. B., \"Application of an Optimal Tuner Selection Approach for On-Board Self-Tuning Engine Models,\" Proceedings of the ASME Turbo Expo 2011, GT2011-46408, 2011 (To Be Published).\r</p>\n", 
            "speaker": 109, 
            "submitted": "2010-10-28 14:36:51", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 69, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Montr\u00e9al-Python is a user-group formed in 2007.  It has since then grown into a thriving community with code sprint and  regular meetings attracting over 50 attendees.  This talk will present history of the group and will highlight the key\r\nfactors behind its success with the hope to inspire others to\r\nreplicate that accomplishment.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The talk will first walk the audience through the factors inherent to Montr\u00e9al itself and how it affected other user groups before Montr\u00e9al-Python.  These groups inspired us to get a group of Python hackers started the presentation will show how we were able to leverage on the success of other user groups to bring our young community forward.\r\n\r\nThe various stages of our growth will be presented along with insights on how we managed to find speakers and venues at each point.  The presentation will then go through an overview of our current activities, sharing in the process how effective they are in engaging the community.  Our plans for the next few years will be presented then a summary will provide advice to anyone who would like to get started organizing a local Python user group.\r\n", 
            "title": "Montr\u00e9al-Python -- Lessons Learned from Bootstraping a Python Community", 
            "plenary": false, 
            "abstract_html": "<p>The talk will first walk the audience through the factors inherent to Montr\u00e9al itself and how it affected other user groups before Montr\u00e9al-Python.  These groups inspired us to get a group of Python hackers started the presentation will show how we were able to leverage on the success of other user groups to bring our young community forward.\r</p>\n<p>The various stages of our growth will be presented along with insights on how we managed to find speakers and venues at each point.  The presentation will then go through an overview of our current activities, sharing in the process how effective they are in engaging the community.  Our plans for the next few years will be presented then a summary will provide advice to anyone who would like to get started organizing a local Python user group.\r</p>\n", 
            "speaker": 111, 
            "submitted": "2010-10-28 15:00:25", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 71, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Pluggable or reusable applications are a key feature of Django, but there is little guidance on writing them well. We'll dig into the different types of Django applications and coding patterns that make writing a reusable application easier. The talk also covers ways to avoid common implementation gotchas.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Reusable, or pluggable, applications are a powerful feature of Django. Your code can do more if written with a few ideas and techniques in mind. We'll cover:\r\n\r\n* The four qualities of a pluggable application\r\n* The three types of Django applications\r\n* Ten common situations in implementing reusable code and coding patterns to handle them", 
            "title": "Pluggable Django Patterns", 
            "plenary": false, 
            "abstract_html": "<p>Reusable, or pluggable, applications are a powerful feature of Django. Your code can do more if written with a few ideas and techniques in mind. We'll cover:\r</p>\n<ul>\n<li>The four qualities of a pluggable application\r</li>\n<li>The three types of Django applications\r</li>\n<li>Ten common situations in implementing reusable code and coding patterns to handle them</li>\n</ul>\n", 
            "speaker": 32, 
            "submitted": "2010-10-28 17:16:55", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 72, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "A lot of people want to use Python, but their customer, management, school, government, or organization won't let them. Python is a great tool, but it can be challenging to get in the door. This panel will explore how companies and individuals have successfully introduced Python, what tools are available to sell Python, and what pitfalls there are to avoid.", 
            "additional_speakers": [
                207, 
                211, 
                239, 
                238
            ], 
            "session_type": 2, 
            "track": null, 
            "abstract": "A lot of people want to use Python, but their customer, management, school, government, or organization won't let them. Python is a great tool, but it can be challenging to get in the door. This panel will explore how companies and individuals have successfully introduced Python, what tools are available to sell Python, and what pitfalls there are to avoid.\r\n\r\nPossible questions will include:\r\n\r\n* What is a good example success story you can share?\r\n* What pitfalls should you avoid?\r\n* How do you deal with organizations that have already spent bucketloads of money on a piss-poor technology stack, are hurting for it, but can't seem to let go?\r\n* How do you fight Fear-Uncertainty-Doubt (FUD) spread by people who stand to lose from introducing Python?\r\n* What tools are available to help sell Python?\r\n\r\nFive panelists will be chosen from a broad spectrum of individuals including academic, government, for-profit organizations, and non-profit organizations. \r\n\r\nSpeakers:\r\n\r\n* **Academia** C. Titus Brown\r\n* **Goverment** Chris Shenton of Koansys/NASA\r\n* **Large Commercial Organization** Dan Mesh of Evite\r\n* **Small Commercial Organization** Frank Wiles of RevSys\r\n* **Non-Profit Organization** Rich Leland of National Geographic", 
            "title": "How to sell Python", 
            "plenary": false, 
            "abstract_html": "<p>A lot of people want to use Python, but their customer, management, school, government, or organization won't let them. Python is a great tool, but it can be challenging to get in the door. This panel will explore how companies and individuals have successfully introduced Python, what tools are available to sell Python, and what pitfalls there are to avoid.\r</p>\n<p>Possible questions will include:\r</p>\n<ul>\n<li>What is a good example success story you can share?\r</li>\n<li>What pitfalls should you avoid?\r</li>\n<li>How do you deal with organizations that have already spent bucketloads of money on a piss-poor technology stack, are hurting for it, but can't seem to let go?\r</li>\n<li>How do you fight Fear-Uncertainty-Doubt (FUD) spread by people who stand to lose from introducing Python?\r</li>\n<li>What tools are available to help sell Python?\r</li>\n</ul>\n<p>Five panelists will be chosen from a broad spectrum of individuals including academic, government, for-profit organizations, and non-profit organizations. \r</p>\n<p>Speakers:\r</p>\n<ul>\n<li><b>Academia</b> C. Titus Brown\r</li>\n<li><b>Goverment</b> Chris Shenton of Koansys/NASA\r</li>\n<li><b>Large Commercial Organization</b> Dan Mesh of Evite\r</li>\n<li><b>Small Commercial Organization</b> Frank Wiles of RevSys\r</li>\n<li><b>Non-Profit Organization</b> Rich Leland of National Geographic</li>\n</ul>\n", 
            "speaker": 15, 
            "submitted": "2010-10-28 18:25:06", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 74, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Combining Python with inexpensive robots is a very effective way of teaching programming at the middle and high school levels. Since Python is easy to understand a constructivist approach is possible - students learn by creating and running simple programs, observing the results, and then modifying their code to fix bugs and add functionality. \r\n\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The approach suggested in this talk is partly based upon that\r\ndeveloped at the Institute for Personal Robots in Education\r\n(http://wiki.roboteducation.org) by staff from Georgia Tech and Bryn\r\nMawr, combined with my own experiences teaching programming with\r\nPython as described in my talk \"Goodbye, Hello World: Rethinking\r\nTeaching with Python\", PyCon 2007, and my subsequent talks at NECC.\r\n\r\nBecause students are able to see what their code is doing and because Python is easy to understand, students can explore simple programming concepts, learning features as they need them. This approach increases both student engagement and retention. It also seems that this approach is more appealing to girls than a more traditional programming class. \r\n\r\nI'll illustrate my talk with samples of code created by students and video of the students/robots in action.\r\n\r\n**Outline**\r\n\r\nIntroduction - school background, course structure, origin of approach \r\n\r\nHardware and computer setup used \r\n\r\nInitial exercises and first projects \r\n* Control of robot\r\n* Program as sequence of commands\r\n* Basic programming concepts - looping, branching, functions\r\n\r\nAdvanced projects \r\n* obtacle detection\r\n* image processing\r\n* simple AI approaches\r\n\r\nPitfalls and strategies for using robots \r\n\r\nQuestions and Suggestions ", 
            "title": "Python and Robots: Teaching Programming in High School", 
            "plenary": false, 
            "abstract_html": "<p>The approach suggested in this talk is partly based upon that\r developed at the Institute for Personal Robots in Education\r (<a href=\"http://wiki.roboteducation.org\">http://wiki.roboteducation.org</a>) by staff from Georgia Tech and Bryn\r Mawr, combined with my own experiences teaching programming with\r Python as described in my talk \"Goodbye, Hello World: Rethinking\r Teaching with Python\", PyCon 2007, and my subsequent talks at NECC.\r</p>\n<p>Because students are able to see what their code is doing and because Python is easy to understand, students can explore simple programming concepts, learning features as they need them. This approach increases both student engagement and retention. It also seems that this approach is more appealing to girls than a more traditional programming class. \r</p>\n<p>I'll illustrate my talk with samples of code created by students and video of the students/robots in action.\r</p>\n<p><b>Outline</b>\r</p>\n<p>Introduction - school background, course structure, origin of approach \r</p>\n<p>Hardware and computer setup used \r</p>\n<p>Initial exercises and first projects \r</p>\n<ul>\n<li>Control of robot\r</li>\n<li>Program as sequence of commands\r</li>\n<li>Basic programming concepts - looping, branching, functions\r</li>\n</ul>\n<p>Advanced projects \r</p>\n<ul>\n<li>obtacle detection\r</li>\n<li>image processing\r</li>\n<li>simple AI approaches\r</li>\n</ul>\n<p>Pitfalls and strategies for using robots \r</p>\n<p>Questions and Suggestions </p>\n", 
            "speaker": 108, 
            "submitted": "2010-10-28 20:04:08", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 79, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Creating high-concurrency python web applications is inherently difficult for a variety of reasons. In this talk, I'll discuss the various iterations of application server paradigms we've used at meebo, the advantages/disadvantages of each approach, and why we've settled on a coroutine-based WSGI setup to handle our high-concurrency web applications going forward.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "There are a number of ways in which to create a web application in python.  Some examples include a straight-up CGI scripts that run anew with each request, preforked Apache workers that each handle multiple requests, and using an asynchronous web framework like Twisted.\r\n\r\nAt meebo, we've settled on using gunicorn, a lightweight WSGI server, which supports gevent, a coroutine-based network library for python.  Gevent monkeypatches python's system modules to make network requests asynchronous using an event loop based on libevent.  This trick allows the developer to use a simple blocking CGI as a non-blocking web application that can handle many concurrent requests.\r\n\r\nI'll discuss our iteration process through these approaches to building web applications, why we ended up choosing gunicorn+gevent, the challenges this new framework presents, and how we've dealt with them.", 
            "title": "Using Coroutines to Create Efficient, High-Concurrency Web Applications", 
            "plenary": false, 
            "abstract_html": "<p>There are a number of ways in which to create a web application in python.  Some examples include a straight-up CGI scripts that run anew with each request, preforked Apache workers that each handle multiple requests, and using an asynchronous web framework like Twisted.\r</p>\n<p>At meebo, we've settled on using gunicorn, a lightweight WSGI server, which supports gevent, a coroutine-based network library for python.  Gevent monkeypatches python's system modules to make network requests asynchronous using an event loop based on libevent.  This trick allows the developer to use a simple blocking CGI as a non-blocking web application that can handle many concurrent requests.\r</p>\n<p>I'll discuss our iteration process through these approaches to building web applications, why we ended up choosing gunicorn+gevent, the challenges this new framework presents, and how we've dealt with them.</p>\n", 
            "speaker": 114, 
            "submitted": "2010-10-29 11:21:51", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 81, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Packaging or installing a Python application can be extremely painful.\r\n\r\nThis talk will deep-dive into the new Distutils2 features and explain how you can use them in your project *today* to make life easier for everyone (users, OS package managers, developers, etc.). \r\n\r\n\r\n\r\n\r\n\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "# Distutils2 presentation and goals\r\n## Framework\r\n## Command-driven packaging system\r\n# Changes from Distutils1\r\n## R.I.P. setup.py\r\n## The new metadata fields (PEP 345)\r\n## versions for your project (PEP 386)\r\n## PyPI goodies\r\n### browsing\r\n### uploading docs\r\n## What's installed ? what to install ? (PEP 376)\r\n### The Dependency graph tool\r\n## Extensibility !\r\n### commands\r\n### compilers\r\n# Pysetup, one command to rule them all\r\n## install !\r\n## remove\r\n## do other things\r\n# Examples\r\n## Example 1: A simple Distutils2 project\r\n## Example 2: Porting your project to Distutils2, and keep it working in Distutils/Setuptools/zc.buildout environments.\r\n## Example 3: Creating and releasing your own commands and compilers\r\n## Example 4: Developement process made simple with Distutils2  \r\n# Conclusion\r\n## Roadmap\r\n", 
            "title": "Packaging, from Distutils to Distutils2", 
            "plenary": false, 
            "abstract_html": "<ol>\n<li>Distutils2 presentation and goals\r<ol>\n<li>Framework\r</li>\n<li>Command-driven packaging system\r</li>\n</ol>\n</li>\n<li>Changes from Distutils1\r<ol>\n<li>R.I.P. setup.py\r</li>\n<li>The new metadata fields (PEP 345)\r</li>\n<li>versions for your project (PEP 386)\r</li>\n<li>PyPI goodies\r<ol>\n<li>browsing\r</li>\n<li>uploading docs\r</li>\n</ol>\n</li>\n<li>What's installed ? what to install ? (PEP 376)\r<ol>\n<li>The Dependency graph tool\r</li>\n</ol>\n</li>\n<li>Extensibility !\r<ol>\n<li>commands\r</li>\n<li>compilers\r</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>Pysetup, one command to rule them all\r<ol>\n<li>install !\r</li>\n<li>remove\r</li>\n<li>do other things\r</li>\n</ol>\n</li>\n<li>Examples\r<ol>\n<li>Example 1: A simple Distutils2 project\r</li>\n<li>Example 2: Porting your project to Distutils2, and keep it working in Distutils/Setuptools/zc.buildout environments.\r</li>\n<li>Example 3: Creating and releasing your own commands and compilers\r</li>\n<li>Example 4: Developement process made simple with Distutils2  \r</li>\n</ol>\n</li>\n<li>Conclusion\r<ol>\n<li>Roadmap\r</li>\n</ol>\n</li>\n</ol>\n", 
            "speaker": 123, 
            "submitted": "2010-10-29 12:44:00", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": true, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 82, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Blender 2.5 (a free and open source software 3d graphics suite) includes a new BPY python API which is usable for scripting modeling, animation, etc.  Learn to use this API to speed up your workflow, create procedural graphics, and cool new tools.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Since 2.5, the API has become more pythonic and self-descriptive.  Blender's UI can show you the Python equivalent for nearly every user action and includes a full datablock exploration tool.  Users will be taught how to use so they can quickly adapt to their appropriate needs with a little Blender experience and no previous BPY experience.\r\n\r\nThere will be a brief Blender overview, an introduction to the API and how to use it, as well as / along with an overview of some of the presenter's own tools / use cases.  Some other popular 3rd party Python tools will also be shown as an example.\r\n\r\nIf there is time, a brief demo of the Blender Game Engine will also be given, though that is a separate API.", 
            "title": "Using Blender's new BPY Python API", 
            "plenary": false, 
            "abstract_html": "<p>Since 2.5, the API has become more pythonic and self-descriptive.  Blender's UI can show you the Python equivalent for nearly every user action and includes a full datablock exploration tool.  Users will be taught how to use so they can quickly adapt to their appropriate needs with a little Blender experience and no previous BPY experience.\r</p>\n<p>There will be a brief Blender overview, an introduction to the API and how to use it, as well as / along with an overview of some of the presenter's own tools / use cases.  Some other popular 3rd party Python tools will also be shown as an example.\r</p>\n<p>If there is time, a brief demo of the Blender Game Engine will also be given, though that is a separate API.</p>\n", 
            "speaker": 122, 
            "submitted": "2010-10-29 12:59:28", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 90, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "One reason for Python's success is its restraint in adding new language features.  Only the most essential changes make it--and for every change that gets accepted, many more are rejected.  Come learn about proposed changes to the Python language that failed--what, how, and why.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "* Quick overview of the process\r\n** First ten years: send GvR a patch\r\n** The modern approach: python-ideas, write a PEP, produce a reference implementation\r\n* Discuss the \"prickly\" Python community\r\n** This is a good thing!  Only the best ideas survive the python-dev gauntlet!\r\n** They do this not because they're mean, but because they care so much.\r\n** We must have eternal vigilance to prevent unnecessary changes!\r\n* A survey of some changes that didn't make it\r\n** The switch/case statement (PEP 3103)\r\n** The \"freeze protocol\" (PEP 351)\r\n** The \"dynamic attribute access\" proposal from python-dev, 2007/02\r\n** Many more possibilities await in the rejected PEPs!\r\n* My message to the audience\r\n** Start with a post to python-ideas, please!\r\n** Don't be surprised if you get a negative reaction\r\n** Don't let your fear of a negative reaction stop you from trying, necessarily\r\n** Do your homework, and be your own worst critic\r\n", 
            "title": "The Python That Wasn't", 
            "plenary": false, 
            "abstract_html": "<ul>\n<li>Quick overview of the process\r<ul>\n<li>First ten years: send GvR a patch\r</li>\n<li>The modern approach: python-ideas, write a PEP, produce a reference implementation\r</li>\n</ul>\n</li>\n<li>Discuss the \"prickly\" Python community\r<ul>\n<li>This is a good thing!  Only the best ideas survive the python-dev gauntlet!\r</li>\n<li>They do this not because they're mean, but because they care so much.\r</li>\n<li>We must have eternal vigilance to prevent unnecessary changes!\r</li>\n</ul>\n</li>\n<li>A survey of some changes that didn't make it\r<ul>\n<li>The switch/case statement (PEP 3103)\r</li>\n<li>The \"freeze protocol\" (PEP 351)\r</li>\n<li>The \"dynamic attribute access\" proposal from python-dev, 2007/02\r</li>\n<li>Many more possibilities await in the rejected PEPs!\r</li>\n</ul>\n</li>\n<li>My message to the audience\r<ul>\n<li>Start with a post to python-ideas, please!\r</li>\n<li>Don't be surprised if you get a negative reaction\r</li>\n<li>Don't let your fear of a negative reaction stop you from trying, necessarily\r</li>\n<li>Do your homework, and be your own worst critic\r</li>\n</ul>\n</li>\n</ul>\n", 
            "speaker": 105, 
            "submitted": "2010-10-29 21:40:37", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 83, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Firefox Sync let you access your history, passwords, bookmarks and even open tabs across all your devices, while remaining unreadable on the server through encryption.\r\n\r\nAfter a brief introduction on the Sync protocol, this talk will focus on the server, which is written in Python.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The talk will briefly explain how Syncing works then will focus on the Server architecture and code. You will discover through this talk how the server was built and what technologies it uses.  \r\n\r\n# Firefox Sync in numbers\r\n# How synchronisation happens - the big picture\r\n## Desktop\r\n## iPhone (Firefox Home)\r\n# How encryption works\r\n# Overview of the APIs\r\n## Sync 1.1\r\n## User 1.0\r\n# Server architecture\r\n## User & Data storage\r\n## Web Services\r\n## Libraries used\r\n# Scaling and benchmarking\r\n## Grinder\r\n## Funkload\r\n# Run your own server !\r\n# What's Next\r\n", 
            "title": "Firefox Sync", 
            "plenary": false, 
            "abstract_html": "<p>The talk will briefly explain how Syncing works then will focus on the Server architecture and code. You will discover through this talk how the server was built and what technologies it uses.  \r</p>\n<ol>\n<li>Firefox Sync in numbers\r</li>\n<li>How synchronisation happens - the big picture\r<ol>\n<li>Desktop\r</li>\n<li>iPhone (Firefox Home)\r</li>\n</ol>\n</li>\n<li>How encryption works\r</li>\n<li>Overview of the APIs\r<ol>\n<li>Sync 1.1\r</li>\n<li>User 1.0\r</li>\n</ol>\n</li>\n<li>Server architecture\r<ol>\n<li>User &amp; Data storage\r</li>\n<li>Web Services\r</li>\n<li>Libraries used\r</li>\n</ol>\n</li>\n<li>Scaling and benchmarking\r<ol>\n<li>Grinder\r</li>\n<li>Funkload\r</li>\n</ol>\n</li>\n<li>Run your own server !\r</li>\n<li>What's Next\r</li>\n</ol>\n", 
            "speaker": 123, 
            "submitted": "2010-10-29 13:00:48", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 85, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Every Python programmer is brilliant in his or her own way.  That brilliance shines in code and peer-to-peer conversation.  But how do you display your skills to a non-programmer?  How do you impress management and human resources?  What do you need to do (and not do) to successfully navigate the hiring process and land the job?", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Imaginary Landscape has been interviewing, hiring and not hiring Python talent since 1999.  Throughout these many years, there have been good candidates, bad candidates and downright ugly candidates.  This talk will use actual correspondence and examples to demonstrate what can separate you from the crowd and what can separate you from consideration.  Imaginary Landscape non-technical Managing Partner Brian Moloney will lead the session by describing how he evaluates potential hires and what goes through his mind while speaking with potential Python candidates.  Attendees will take away a specific set of guidelines for mastering the non-technical aspects of the recruiting process.", 
            "title": "Getting the job:  the do's and don'ts of landing a Python job", 
            "plenary": false, 
            "abstract_html": "<p>Imaginary Landscape has been interviewing, hiring and not hiring Python talent since 1999.  Throughout these many years, there have been good candidates, bad candidates and downright ugly candidates.  This talk will use actual correspondence and examples to demonstrate what can separate you from the crowd and what can separate you from consideration.  Imaginary Landscape non-technical Managing Partner Brian Moloney will lead the session by describing how he evaluates potential hires and what goes through his mind while speaking with potential Python candidates.  Attendees will take away a specific set of guidelines for mastering the non-technical aspects of the recruiting process.</p>\n", 
            "speaker": 62, 
            "submitted": "2010-10-29 15:43:35", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 86, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk is about continuous deployment practices and tools, lessons learned from implementing it, and putting them into perspective. The goal is to give other people tips and pointers for applying these ideas themselves.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Continuous deployment is the practice of putting the latest revision of software into production use all the time, as opposed to working towards larger releases. The important difference is iteration time: whereas large software packages produce new software in timeframes of years or months, continuous deployment teams typically put new code into production in timeframes of hours or less.\r\n\r\nThe practice is slowly attracting a small but growing group of loyal followers, just like continuous integration over the past few years and test-driven development did before that. They can be explained in terms of being natural extensions of each other. Like TDD and CI, CD gets eyed somewhat suspiciously (and rightfully so: skeptical analysis is great), but the undersigned believes there's a legitimate advantage for many applications.\r\n\r\nMany years ago, TTD and testing tools in general were mostly ad-hockery. Now, with many different production-quality testing tools, this has become unthinkable. Similarly, continuous integration was something //other// people did for a long time, but now we have tools such as Buildbot and Hudson. Continuous deployment is still somewhat in the early stage in terms of ready-to-use tools, but it's likely that we'll see a similar evolution.\r\n\r\nHere's a rough outline of what I plan to cover:\r\n* a short history of people developed software\r\n* from the recent models to CD (sort of a working definition of CD here)\r\n* when is it a good idea? pros/cons\r\n* requirements & battle plan for applying CD in an existing development environment (and possibly code base)\r\n* an overview of existing tools and how they work together\r\n* caveat emptors, known pitfalls (deployment and recovery strategies go here, since most implementations figure out they need them after stuff blows up)\r\n* questions! (hopefully lots of people who've tried or are thinking about implementing something similar -- like I said, there are a lot of people implementing it but not too many ideas being bounced around)\r\n", 
            "title": "Continuous deployment", 
            "plenary": false, 
            "abstract_html": "<p>Continuous deployment is the practice of putting the latest revision of software into production use all the time, as opposed to working towards larger releases. The important difference is iteration time: whereas large software packages produce new software in timeframes of years or months, continuous deployment teams typically put new code into production in timeframes of hours or less.\r</p>\n<p>The practice is slowly attracting a small but growing group of loyal followers, just like continuous integration over the past few years and test-driven development did before that. They can be explained in terms of being natural extensions of each other. Like TDD and CI, CD gets eyed somewhat suspiciously (and rightfully so: skeptical analysis is great), but the undersigned believes there's a legitimate advantage for many applications.\r</p>\n<p>Many years ago, TTD and testing tools in general were mostly ad-hockery. Now, with many different production-quality testing tools, this has become unthinkable. Similarly, continuous integration was something <i>other</i> people did for a long time, but now we have tools such as Buildbot and Hudson. Continuous deployment is still somewhat in the early stage in terms of ready-to-use tools, but it's likely that we'll see a similar evolution.\r</p>\n<p>Here's a rough outline of what I plan to cover:\r</p>\n<ul>\n<li>a short history of people developed software\r</li>\n<li>from the recent models to CD (sort of a working definition of CD here)\r</li>\n<li>when is it a good idea? pros/cons\r</li>\n<li>requirements &amp; battle plan for applying CD in an existing development environment (and possibly code base)\r</li>\n<li>an overview of existing tools and how they work together\r</li>\n<li>caveat emptors, known pitfalls (deployment and recovery strategies go here, since most implementations figure out they need them after stuff blows up)\r</li>\n<li>questions! (hopefully lots of people who've tried or are thinking about implementing something similar -- like I said, there are a lot of people implementing it but not too many ideas being bounced around)\r</li>\n</ul>\n", 
            "speaker": 48, 
            "submitted": "2010-10-29 17:24:56", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 88, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Designing interfaces so that other code can interact with ours (whether our code is a library, framework, application, website...) is a very common and clearly crucial activity, but fraught with dangers -- stuff we all keep doing wrong time after time. This talks shows some common cases of API design errors encountered in the wild, with tips on how to avoid them when you design your next API.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Whenever we write code we should always be thinking about how **other** code (whether our own, or other people's) will interact with ours (an \"API\", in common parlance).  Indeed, the most common and terrible mistake in API design is... not doing any! -- i.e., not providing //any// designed, architected way for other code to interact with ours.  That's fortunately less common when \"our code\" is a library or framework;-), but, alas!, sadly widespread when \"our code\" is an application or website -- that's why questions about screen-scraping the web and simulating keystrokes and mouse gestures need be so tragically frequent all over the web.\r\n\r\nOnce past the obvious hurdle of not having any API at all, there's still plenty of ways we can go badly wrong in the process of designing one -- and many of those ways fall into recognizable categories, i.e., **patterns**.  Specifically, since they're frequently observed categories of defective design, they're **anti**-patterns -- and //that//'s what this talk is in fact about (as the smartest among you could tell from the title...).\r\n\r\nI'm eminently qualified to present on this subject, since, in a lifetime spent mostly stumbling into software (after actually qualifying to design **hardware** in college, but only doing that for a few years), I've been responsible for more of my shares of API design fumbles (plus, of course, just like every other programmer, I've done my share of swearing at the design fumbles of //other// API designers).  And, as novelist Richard Bach reminds us, \"You teach best what you most need to learn\"!-)\r\n", 
            "title": "API Design anti-patterns", 
            "plenary": false, 
            "abstract_html": "<p>Whenever we write code we should always be thinking about how <b>other</b> code (whether our own, or other people's) will interact with ours (an \"API\", in common parlance).  Indeed, the most common and terrible mistake in API design is... not doing any! -- i.e., not providing <i>any</i> designed, architected way for other code to interact with ours.  That's fortunately less common when \"our code\" is a library or framework;-), but, alas!, sadly widespread when \"our code\" is an application or website -- that's why questions about screen-scraping the web and simulating keystrokes and mouse gestures need be so tragically frequent all over the web.\r</p>\n<p>Once past the obvious hurdle of not having any API at all, there's still plenty of ways we can go badly wrong in the process of designing one -- and many of those ways fall into recognizable categories, i.e., <b>patterns</b>.  Specifically, since they're frequently observed categories of defective design, they're <b>anti</b>-patterns -- and <i>that</i>'s what this talk is in fact about (as the smartest among you could tell from the title...).\r</p>\n<p>I'm eminently qualified to present on this subject, since, in a lifetime spent mostly stumbling into software (after actually qualifying to design <b>hardware</b> in college, but only doing that for a few years), I've been responsible for more of my shares of API design fumbles (plus, of course, just like every other programmer, I've done my share of swearing at the design fumbles of <i>other</i> API designers).  And, as novelist Richard Bach reminds us, \"You teach best what you most need to learn\"!-)\r</p>\n", 
            "speaker": 130, 
            "submitted": "2010-10-29 18:18:59", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": true, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 89, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Building a great business is quite different from building a great product, but by measuring Key Performance Indicators (things like cash flow, if users keep coming back, etc.) you can make sure your business is on the right track. In this talk I'll cover common KPI in the tech business and show you how we automate collecting and presenting KPI at Olark.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "As a hacker-turned-founder, you quickly realize there's more to building a great business than just building a great product. The easiest way to know your business is on the right track is to measure Key Performance Indicators (KPIs): things like cash flow, what parts of the product is used the most, if your users keep coming back, if users are experiencing problems... and many, many others. How are you supposed to keep track of it all without getting lost in a sea of noise?\r\n\r\nWith Python, of course! In this talk I'll cover the most common KPIs technology businesses track and show you how we used Python at Olark to automatically collect and present KPIs to the team. This has made it much easier to quickly answer business questions and help us know we're on the right track.\r\n\r\nSo if you're a Python hacker who would like to learn more about how to engineer a business, or if you're a business person who's just starting to learn Python, come learn how Python isn't just for engineering.", 
            "title": "Serious Business: Python is not just for Engineering", 
            "plenary": false, 
            "abstract_html": "<p>As a hacker-turned-founder, you quickly realize there's more to building a great business than just building a great product. The easiest way to know your business is on the right track is to measure Key Performance Indicators (KPIs): things like cash flow, what parts of the product is used the most, if your users keep coming back, if users are experiencing problems... and many, many others. How are you supposed to keep track of it all without getting lost in a sea of noise?\r</p>\n<p>With Python, of course! In this talk I'll cover the most common KPIs technology businesses track and show you how we used Python at Olark to automatically collect and present KPIs to the team. This has made it much easier to quickly answer business questions and help us know we're on the right track.\r</p>\n<p>So if you're a Python hacker who would like to learn more about how to engineer a business, or if you're a business person who's just starting to learn Python, come learn how Python isn't just for engineering.</p>\n", 
            "speaker": 129, 
            "submitted": "2010-10-29 18:42:17", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 114, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Pypes is a component oriented framework for designing dataflow applications. It uses Stackless Python to model components as computational entities that operate by sending and receiving messages. Components are designed to process streams of data modeled as a series of messages which are exchanged asynchronously. Data streams are initiated over an asynchronous REST interface.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "There's been some recent momentum around data flow programming with a number of new frameworks having been released. This new found interest is due largely in part to the increasing amount of data being produced and consumed by applications. MapReduce has become a general topic of discussion for analytics over large data sets but it's increasingly evident that it's not a panacea.\r\n\r\nSimple batch processing tools like MapReduce and Hadoop are just not powerful enough in any one of the dimensions of the big data space that really matters. One particular area where MapReduce falls short is in near real-time search. It used to be common to run batch processing jobs on a nightly basis which would index the days events, making them searchable.\r\n\r\nGiven today's social dynamics, people have come to expect instant access to data as opposed to a daily digest. Batch oriented semantics are being superseded by event driven architectures that act on live, real-time streams of data. This shift in paradigm has sparked new interest in dataflow concepts.\r\n\r\nDataflow frameworks promote the data to become the main concept behind any program. It becomes a matter of \"data-flow\" over \"control-flow\" where processes are just the way data is created, manipulated and destroyed. This concept is well represented in the Unix operating system which pipes data between small single-purpose tools to produce more sophisticated applications.\r\n\r\nPypes is a dataflow framework that leverages Stackless Python to model processes as black box operations that communicate by sending and receiving messages. These processes are naturally component oriented allowing them to be connected in different ways to form new applications. Components are inherently stateless making parallel processing relatively simple. Because a component is an abstraction of a Stackless tasklet (true coroutines), expensive setups such as loading machine learning models are done once during initialization and can then be used throughout the life of the component. This is in contrast to MapReduce frameworks that typically incur this overhead each time the map function is called or try to manage some sort of global state.\r\n\r\nOne aspect that differentiates Pypes from other dataflow frameworks is its \"push\" model. Unlike generator based solutions which pull data through the system, Pypes provides a RESTful interface that allows data to be pushed in. This allows Pypes to sit more natural as an event driven middleware component in the context of a larger architecture. A data push model also simplifies scalability since an entire cluster of nodes can be setup behind a load balancer which will then automatically partition the incoming data stream. Generator based \"pull models\" cannot easily partition data without somehow coordinating access to the data which involves global state.\r\n\r\nPypes was designed to be a highly scalable, event driven, dataflow scheduling and execution environment. Writing your own components is simple and Pypes provides Paste templates for creating new projects. Components are packaged as Python eggs and discovered automatically. They can be wired together using a visual editor that runs in any HTML5 compliant browser. Pypes supports Directed Acyclic Graphs and data streams are modeled as a series of JSON (dict) packets which support meta-data at both the packet level and the field level.\r\n\r\nPypes also leverages the Python multiprocessing module to scale up. Data arriving through the REST interface on any given node will be distributed across parallel instances of the graph running on different cores/CPUs. Data submission is completely asynchronous.\r\n\r\nThis talk will provide a gentle introduction to the Pypes architecture and design.\r\n\r\nOutline:\r\n * Brief intro to Stackless Python (benefits it provides)\r\n * Control-Flow vs Data-Flow\r\n * Preemptive vs Cooperative Scheduling\r\n * The Topological Scheduler\r\n * The REST API (Submitting Data - Asynchronous Web Service)\r\n * Packet API: A unified data model with meta-data support\r\n * Writing Custom Components - Paste templates and pluggable eggs\r\n * Scale up - multiprocessing support\r\n * Scale out - cloud friendly\r\n * Questions", 
            "title": "Large Scale Data Conditioning & Processing with Stackless Python and Pypes", 
            "plenary": false, 
            "abstract_html": "<p>There's been some recent momentum around data flow programming with a number of new frameworks having been released. This new found interest is due largely in part to the increasing amount of data being produced and consumed by applications. MapReduce has become a general topic of discussion for analytics over large data sets but it's increasingly evident that it's not a panacea.\r</p>\n<p>Simple batch processing tools like MapReduce and Hadoop are just not powerful enough in any one of the dimensions of the big data space that really matters. One particular area where MapReduce falls short is in near real-time search. It used to be common to run batch processing jobs on a nightly basis which would index the days events, making them searchable.\r</p>\n<p>Given today's social dynamics, people have come to expect instant access to data as opposed to a daily digest. Batch oriented semantics are being superseded by event driven architectures that act on live, real-time streams of data. This shift in paradigm has sparked new interest in dataflow concepts.\r</p>\n<p>Dataflow frameworks promote the data to become the main concept behind any program. It becomes a matter of \"data-flow\" over \"control-flow\" where processes are just the way data is created, manipulated and destroyed. This concept is well represented in the Unix operating system which pipes data between small single-purpose tools to produce more sophisticated applications.\r</p>\n<p>Pypes is a dataflow framework that leverages Stackless Python to model processes as black box operations that communicate by sending and receiving messages. These processes are naturally component oriented allowing them to be connected in different ways to form new applications. Components are inherently stateless making parallel processing relatively simple. Because a component is an abstraction of a Stackless tasklet (true coroutines), expensive setups such as loading machine learning models are done once during initialization and can then be used throughout the life of the component. This is in contrast to MapReduce frameworks that typically incur this overhead each time the map function is called or try to manage some sort of global state.\r</p>\n<p>One aspect that differentiates Pypes from other dataflow frameworks is its \"push\" model. Unlike generator based solutions which pull data through the system, Pypes provides a RESTful interface that allows data to be pushed in. This allows Pypes to sit more natural as an event driven middleware component in the context of a larger architecture. A data push model also simplifies scalability since an entire cluster of nodes can be setup behind a load balancer which will then automatically partition the incoming data stream. Generator based \"pull models\" cannot easily partition data without somehow coordinating access to the data which involves global state.\r</p>\n<p>Pypes was designed to be a highly scalable, event driven, dataflow scheduling and execution environment. Writing your own components is simple and Pypes provides Paste templates for creating new projects. Components are packaged as Python eggs and discovered automatically. They can be wired together using a visual editor that runs in any HTML5 compliant browser. Pypes supports Directed Acyclic Graphs and data streams are modeled as a series of JSON (dict) packets which support meta-data at both the packet level and the field level.\r</p>\n<p>Pypes also leverages the Python multiprocessing module to scale up. Data arriving through the REST interface on any given node will be distributed across parallel instances of the graph running on different cores/CPUs. Data submission is completely asynchronous.\r</p>\n<p>This talk will provide a gentle introduction to the Pypes architecture and design.\r</p>\n<p>Outline:\r</p>\n<ul>\n<li>Brief intro to Stackless Python (benefits it provides)\r</li>\n<li>Control-Flow vs Data-Flow\r</li>\n<li>Preemptive vs Cooperative Scheduling\r</li>\n<li>The Topological Scheduler\r</li>\n<li>The REST API (Submitting Data - Asynchronous Web Service)\r</li>\n<li>Packet API: A unified data model with meta-data support\r</li>\n<li>Writing Custom Components - Paste templates and pluggable eggs\r</li>\n<li>Scale up - multiprocessing support\r</li>\n<li>Scale out - cloud friendly\r</li>\n<li>Questions</li>\n</ul>\n", 
            "speaker": 148, 
            "submitted": "2010-10-30 21:27:30", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 96, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The OSI Superboard II was the computer on which I first learned to program back in 1979. Python is why programming remains fun today. In this tale of old meets new, I describe how I have used Python 3 to create a cloud computing service for my still-working Superboard--a problem complicated by it only having 8Kb of RAM and 300-baud cassette tape audio ports for I/O.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Python 3, what good is it?  Cloud computing? Bah! In this talk, I describe how I have used Python 3 to build a distributed cloud-computing service for my Superboard II system.  Originally built in 1978, the Superboard is an obvious candidate for cloud computing due to its extremely constrained memory (8Kb), slow processor (a 1Mhz 6502), crippled I/O (300 baud over audio), and retro programming environment (Microsoft Basic 1.0).  The only question is how to do it?\r\n\r\nTo answer that question, this talk consist of two main parts.  In the first part, I discuss the problem of building a communications stack between the Superboard and a Mac using nothing but audio line-in/line-out ports--a problem involving a tricky I/O handling, real-time audio signal processing, and the creation of a data-link layer communication protocol.    In the second part, I discuss the creation of a distributed cloud-computing service and related topics including messaging systems, key-value stores, map-reduce, etc.   \r\n\r\nThe primary implementation language for all of this work is Python 3.  Throughout the talk, I will mention interesting Python 3 programming idioms along with pros and cons.  I'll conclude by summarizing my experience trying to build a significant project entirely in Python 3. ", 
            "title": "Using Python 3 to Build a Cloud Computing Service for my Superboard II", 
            "plenary": false, 
            "abstract_html": "<p>Python 3, what good is it?  Cloud computing? Bah! In this talk, I describe how I have used Python 3 to build a distributed cloud-computing service for my Superboard II system.  Originally built in 1978, the Superboard is an obvious candidate for cloud computing due to its extremely constrained memory (8Kb), slow processor (a 1Mhz 6502), crippled I/O (300 baud over audio), and retro programming environment (Microsoft Basic 1.0).  The only question is how to do it?\r</p>\n<p>To answer that question, this talk consist of two main parts.  In the first part, I discuss the problem of building a communications stack between the Superboard and a Mac using nothing but audio line-in/line-out ports--a problem involving a tricky I/O handling, real-time audio signal processing, and the creation of a data-link layer communication protocol.    In the second part, I discuss the creation of a distributed cloud-computing service and related topics including messaging systems, key-value stores, map-reduce, etc.   \r</p>\n<p>The primary implementation language for all of this work is Python 3.  Throughout the talk, I will mention interesting Python 3 programming idioms along with pros and cons.  I'll conclude by summarizing my experience trying to build a significant project entirely in Python 3. </p>\n", 
            "speaker": 128, 
            "submitted": "2010-10-30 11:21:51", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": true, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 97, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Django\u2019s among the best documented open source projects; I'm intensely proud of that accomplishment. If any part of Django endures, I hope it\u2019ll be a \u201cdocumentation culture\u201d \u2014 an ethos that values great, well-written documentation. To that end, this talk looks at the tools, tips, and techniques I\u2019ve learned over the years. I hope it helps you write great documentation, too.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk looks at tips, tools, and techniques you can use to produce great technical documentation.\r\n\r\nIt's split roughly into two parts:\r\n\r\n* Part 1: technique. We'll look at the structural elements that make documentation useful: tutorials, high-level overviews, topical guides, reference material, FAQs, and more. We'll cover some tips on how to get documentation done, and community processes for handling documentation in teams (open or not). We'll also talk about what I'm calling \"Documentation Driven Development\" - a technique riffing off Test Driven Development that calls for writing documentation before code.\r\n\r\n* Part 2: tools. Over the last couple of years a few fantastic tools have sprung up that ease the technical aspects of writing documentation. We'll talk about which tools are suitable for which uses, and look at a handful of cool tools including [[http://sphinx.pocoo.org/|Sphinx]], [[http://epydoc.sourceforge.net/|Epydoc]], and [[pycoo|http://fitzgen.github.com/pycco/]].\r\n\r\nThis talk is mostly targeted towards those documenting libraries or frameworks intended for use by other developers, but much of it probably applies to any sort of technical documentation.", 
            "title": "Writing great documentation", 
            "plenary": false, 
            "abstract_html": "<p>This talk looks at tips, tools, and techniques you can use to produce great technical documentation.\r</p>\n<p>It's split roughly into two parts:\r</p>\n<ul>\n<li>Part 1: technique. We'll look at the structural elements that make documentation useful: tutorials, high-level overviews, topical guides, reference material, FAQs, and more. We'll cover some tips on how to get documentation done, and community processes for handling documentation in teams (open or not). We'll also talk about what I'm calling \"Documentation Driven Development\" - a technique riffing off Test Driven Development that calls for writing documentation before code.\r</li>\n</ul>\n<ul>\n<li>Part 2: tools. Over the last couple of years a few fantastic tools have sprung up that ease the technical aspects of writing documentation. We'll talk about which tools are suitable for which uses, and look at a handful of cool tools including <a href=\"http://sphinx.pocoo.org/\">Sphinx</a>, <a href=\"http://epydoc.sourceforge.net/\">Epydoc</a>, and <a href=\"pycoo\">http://fitzgen.github.com/pycco/</a>.\r</li>\n</ul>\n<p>This talk is mostly targeted towards those documenting libraries or frameworks intended for use by other developers, but much of it probably applies to any sort of technical documentation.</p>\n", 
            "speaker": 24, 
            "submitted": "2010-10-30 12:04:59", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 98, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "In this talk I will demonstrate how to use ZeroMQ with Python (and others) to do really advanced or even weird network architectures.  You'll see Python talk to other languages, handle HTTP, JSON, XML, WebSockets, encode videos, chat messaging, etc.  All in a short talk with only code, no diagrams.  You should know ZeroMQ already.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk will demonstrate a series of progressively difficult problems that you can solve with ZeroMQ:\r\n\r\n1. Basic messaging types (request/response, publish/subscribe).\r\n2. Mongrel2 and HTTP processing.\r\n3. Coroutine based web frameworks and why they suck (so quit making them).\r\n4. Distributed worker queues of various flavors.\r\n5. Asynchronous chat protocols with JSON and XML.\r\n6. Clusters of calculators considering and communicating.\r\n7. Talking to other languages and easily ditching Python if you need.\r\n8. Anything else I can think up and do in a single screen of Python.\r\n\r\nThis talk will assume you know ZeroMQ and Python, but if you don't know ZeroMQ you can probably still keep up.\r\n", 
            "title": "Advanced Network Architectures With ZeroMQ", 
            "plenary": false, 
            "abstract_html": "<p>This talk will demonstrate a series of progressively difficult problems that you can solve with ZeroMQ:\r</p>\n<p>1. Basic messaging types (request/response, publish/subscribe).\r 2. Mongrel2 and HTTP processing.\r 3. Coroutine based web frameworks and why they suck (so quit making them).\r 4. Distributed worker queues of various flavors.\r 5. Asynchronous chat protocols with JSON and XML.\r 6. Clusters of calculators considering and communicating.\r 7. Talking to other languages and easily ditching Python if you need.\r 8. Anything else I can think up and do in a single screen of Python.\r</p>\n<p>This talk will assume you know ZeroMQ and Python, but if you don't know ZeroMQ you can probably still keep up.\r</p>\n", 
            "speaker": 138, 
            "submitted": "2010-10-30 13:00:23", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 101, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Deployed web applications are typically run on top of stacks of highly configurable middleware. The number of tunable parameters and their impact are rarely fully explored. Using SciPy and a set of common Python-based web tools this session will present a new method of automatically tuning a typical LAMP stack for optimal performance.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Deployed web applications typically run on top of stacks of configurable technology (e.g. web servers, interface modules, software load balancers, databases). Each of these components often has dozens of tuneable parameters. How many times are those values typically tweaked before a final set of tuned parameters are settled on? What criteria are typically used to determine the optimal set? \r\n\r\nThis session presents a new method of automatically tuning a common LAMP stack for optimal performance. We explore a solution using some common Python-based automated deployment and load testing tools and dive into scientific computing with SciPy.\r\n", 
            "title": "Swarming the Web: Evolving the Perfect Config File", 
            "plenary": false, 
            "abstract_html": "<p>Deployed web applications typically run on top of stacks of configurable technology (e.g. web servers, interface modules, software load balancers, databases). Each of these components often has dozens of tuneable parameters. How many times are those values typically tweaked before a final set of tuned parameters are settled on? What criteria are typically used to determine the optimal set? \r</p>\n<p>This session presents a new method of automatically tuning a common LAMP stack for optimal performance. We explore a solution using some common Python-based automated deployment and load testing tools and dive into scientific computing with SciPy.\r</p>\n", 
            "speaker": 93, 
            "submitted": "2010-10-30 14:42:30", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 113, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Developers usually leave documentation as a final step; one that they will get to as soon as they are forced with threats of bodily harm. Writing the documentation before writing the code, can lead to better code, better implementation and, of course, actual documentation.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "\"Documentation Driven Design\" was coined by our team after noticing how documenting code dramatically changed how we approached problems. By writing the documentation first, you saw the problem from a different perspective: the end user or programmer. This talk will focus on a few items:\r\n\r\n**Usable, not just functional.** Many times developers write code that solves the problem, but is a real pain in the neck to use. Writing the documentation first demonstrates how easy or difficult it is to implement the solution right away.\r\n\r\n**A guide to what to write.** Many developers leave documentation undone because they don't know how to approach it. Having some idea of what needs writing can make the task seem less daunting.\r\n", 
            "title": "Documentation Driven Development", 
            "plenary": false, 
            "abstract_html": "<p>\"Documentation Driven Design\" was coined by our team after noticing how documenting code dramatically changed how we approached problems. By writing the documentation first, you saw the problem from a different perspective: the end user or programmer. This talk will focus on a few items:\r</p>\n<p><b>Usable, not just functional.</b> Many times developers write code that solves the problem, but is a real pain in the neck to use. Writing the documentation first demonstrates how easy or difficult it is to implement the solution right away.\r</p>\n<p><b>A guide to what to write.</b> Many developers leave documentation undone because they don't know how to approach it. Having some idea of what needs writing can make the task seem less daunting.\r</p>\n", 
            "speaker": 32, 
            "submitted": "2010-10-30 19:38:37", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 111, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "Pinax (http://pinaxproject.com) is a platform built on top of Django for rapidly developing websites. This solutions based tutorial will instruct on installation, projects, applications, templates, settings, deployment, contributing back, and much more. The presenters are Pinax core developers and will run through practical hands-on examples. Questions will be taken throughout the tutorial.", 
            "additional_speakers": [
                143
            ], 
            "session_type": 3, 
            "track": null, 
            "abstract": "Pinax ([[http://pinaxproject.com|http://pinaxproject.com]]) is a platform built on top of Django ([[http://djangoproject.com|http://djangoproject.com]]) for rapidly developing websites. This tutorial will instruct on Pinax installation, creating projects, leveraging applications, modification of templates, Pinax-specific settings, media handling, deployment, how to contribute back to Pinax, and much more. The goal of the tutorial is to provide the attendees with the solutions to real world obstacles. The presenters are Pinax core developers and will run through lots of small, practical hands-on examples. We will take questions throughout the tutorial.\r\n\r\n**Intended Audience**\r\n\r\nIntermediate level Python programmers. Familiarity with Django and CPython 2.6+ assumed.\r\n\r\n**Class outline:**\r\n\r\n* Introduction\r\n* Pinax Installation\r\n* Projects\r\n* Pinax specific settings\r\n* Authentication\r\n** Open ID\r\n** Facebook\r\n* Extending profiles via Idios\r\n* Changing avatar defaults\r\n* Modification of existing Pinax applications\r\n* Adding your own Django applications\r\n* Usage of group aware applications\r\n* Modification of templates\r\n* Django-Uni-Form\r\n* Media handling\r\n* jQuery and Pinax\r\n* Deploying Pinax\r\n* Finding help\r\n* Contributing back to Pinax\r\n* Q&A and time overrun buffer\r\n\r\n**Requirements**\r\n\r\nAttendees are required to bring a laptop with Python 2.6+ installed.", 
            "title": "Pinax Solutions", 
            "plenary": false, 
            "abstract_html": "<p>Pinax (<a href=\"http://pinaxproject.com\">http://pinaxproject.com</a>) is a platform built on top of Django (<a href=\"http://djangoproject.com\">http://djangoproject.com</a>) for rapidly developing websites. This tutorial will instruct on Pinax installation, creating projects, leveraging applications, modification of templates, Pinax-specific settings, media handling, deployment, how to contribute back to Pinax, and much more. The goal of the tutorial is to provide the attendees with the solutions to real world obstacles. The presenters are Pinax core developers and will run through lots of small, practical hands-on examples. We will take questions throughout the tutorial.\r</p>\n<p><b>Intended Audience</b>\r</p>\n<p>Intermediate level Python programmers. Familiarity with Django and CPython 2.6+ assumed.\r</p>\n<p><b>Class outline:</b>\r</p>\n<ul>\n<li>Introduction\r</li>\n<li>Pinax Installation\r</li>\n<li>Projects\r</li>\n<li>Pinax specific settings\r</li>\n<li>Authentication\r<ul>\n<li>Open ID\r</li>\n<li>Facebook\r</li>\n</ul>\n</li>\n<li>Extending profiles via Idios\r</li>\n<li>Changing avatar defaults\r</li>\n<li>Modification of existing Pinax applications\r</li>\n<li>Adding your own Django applications\r</li>\n<li>Usage of group aware applications\r</li>\n<li>Modification of templates\r</li>\n<li>Django-Uni-Form\r</li>\n<li>Media handling\r</li>\n<li>jQuery and Pinax\r</li>\n<li>Deploying Pinax\r</li>\n<li>Finding help\r</li>\n<li>Contributing back to Pinax\r</li>\n<li>Q&amp;A and time overrun buffer\r</li>\n</ul>\n<p><b>Requirements</b>\r</p>\n<p>Attendees are required to bring a laptop with Python 2.6+ installed.</p>\n", 
            "speaker": 15, 
            "submitted": "2010-10-30 18:07:02", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 106, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "This lab teaches you how to harvest, store, analyze, and visualize data from the most popular social networking sites (Twitter, Facebook, LinkedIn, etc.) with Python, pragmatic storage technologies like Redis and CouchDB, and popular visualization tools like Graphviz and JavaScript toolkits.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "Popular social networks such as Facebook, Twitter, and LinkedIn generate a tremendous amount of valuable social data. Who's talking to whom? What are they talking about? How often are they talking? Where are they at? This lab tutorial teaches you how to answer these types of questions and more. Each teaching module presents a soup-to-nuts approach that combines popular social web data, analysis techniques, and visualization so that you can find the needles you've been looking for as well as some of the ones you didn't even know to look for in the first place.\r\n\r\nThis lab is taught by the author of [[http://amzn.to/d1Ci8A | Mining the Social Web]], and exercises are largely adapted from the the same. Much of the source code for the lab is [[http://bit.ly/biais2 | already available on GitHub ]], and you are encouraged (but not required) to hack on it prior to the lab, so that you are ready with questions and ideas.\r\n\r\n* Get a concise and straightforward synopsis of the social web landscape so you know which 20% of the space to spend 80% of your time on\r\n* Use easily adaptable scripts hosted on GitHub to harvest data from popular social network APIs including Twitter, Facebook, and LinkedIn\r\n* Learn how to slice and dice social web data with easy to use Python tools as well as apply more advanced mining techniques such as TF-IDF, cosine similarity, collocation analysis, document summarization, and clique detection\r\n* Build interactive visualizations with easily adaptable web technologies built upon HTML5 and JavaScript toolkits\r\n", 
            "title": "Mining and Visualizing Data from the Social Web with Python", 
            "plenary": false, 
            "abstract_html": "<p>Popular social networks such as Facebook, Twitter, and LinkedIn generate a tremendous amount of valuable social data. Who's talking to whom? What are they talking about? How often are they talking? Where are they at? This lab tutorial teaches you how to answer these types of questions and more. Each teaching module presents a soup-to-nuts approach that combines popular social web data, analysis techniques, and visualization so that you can find the needles you've been looking for as well as some of the ones you didn't even know to look for in the first place.\r</p>\n<p>This lab is taught by the author of <a href=\"http://amzn.to/d1Ci8A\">Mining the Social Web</a>, and exercises are largely adapted from the the same. Much of the source code for the lab is <a href=\"http://bit.ly/biais2\">already available on GitHub</a>, and you are encouraged (but not required) to hack on it prior to the lab, so that you are ready with questions and ideas.\r</p>\n<ul>\n<li>Get a concise and straightforward synopsis of the social web landscape so you know which 20% of the space to spend 80% of your time on\r</li>\n<li>Use easily adaptable scripts hosted on GitHub to harvest data from popular social network APIs including Twitter, Facebook, and LinkedIn\r</li>\n<li>Learn how to slice and dice social web data with easy to use Python tools as well as apply more advanced mining techniques such as TF-IDF, cosine similarity, collocation analysis, document summarization, and clique detection\r</li>\n<li>Build interactive visualizations with easily adaptable web technologies built upon HTML5 and JavaScript toolkits\r</li>\n</ul>\n", 
            "speaker": 142, 
            "submitted": "2010-10-30 16:25:04", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 119, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "In this poster session, we shall review how SPM.Python,\r\na solution recognized as a \"Disruptive Technology\" by the \r\nSuper Computing Conference (2010), achieves scalability \r\nby describing solutions to three formerly open problems.\r\n", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "Spm.Python, a commercial product, extends Python with a programming\r\nparadigm for solving parallel problems and strives to do so in a\r\npythonic (natural) way. This is achieved by augmenting the serial\r\nPython language with parallel concepts like parallel task managers and\r\ncommunication primitives.\r\n\r\nIn this poster session, we examine the what, why and how this augmentation was done. The context for and solutions to three\r\nformerly open technical problems will be discussed, including:\r\n* extensions to the general exception handling infrastructure across  many compute resources,\r\n\r\n* design of parallel constructs in a way so that serial components are delineated from parallel components, and\r\n\r\n* declaration and definition of parallel closures, the building blocks of all parallel constructs.\r\n\r\n==== Parallel exception infrastructure\r\n\r\nTo quote Wikipedia, //\"exception handling is a construct designed\r\n    to handle the occurrence of exceptions, special conditions\r\n    that change the normal flow of program execution\"//.\r\n\r\nAs such, the ability to throw and catch exceptions forms the bedrock of the serial Python language. We will review\r\n    details of how we extended the basic serial exception\r\n    infrastructure to account for exceptions that may occur across\r\n    many compute resources.\r\n\r\n    Our solution is predicated on the notion that parallel managers\r\n    must take ownership of how serial exceptions are handled across\r\n    all resources under their control. In other words, unlike in the\r\n    serial world, the parallel exception handling infrastructure must\r\n    be customized for each parallel manager.\r\n\r\n==== Decoupling serial components from parallel  components\r\n\r\nOne of the main tenants of the serial software eco-system is the\r\n    asymptotic parity between the serial compute resources available to the\r\n    developers and the end-users, which makes possible the easy\r\n    reporting, reproduction, and resolution of bugs.\r\n\r\n    With parallel software, this most fundamental of tenants is\r\n    violated; software engineers need to be able to produce high-quality\r\n    parallel software in what is an essentially serial environment,\r\n    yet be able to deploy that software in a parallel environment.\r\n \r\n    We will describe how SPM.Python addresses this dichotomy by offering easy to relate to\r\n    parallel primitives. These primitives permit the prototyping,\r\n    validation, and testing of parallel ideas in the essentially\r\n    serial development environment, and yet deliver performance\r\n    when exercised in the parallel environment.\r\n\r\n==== Declaring and defining parallel closures\r\n\r\nIn SPM.Python, parallel closures are the building blocks of all\r\n    parallel constructs, and provide the sole means by which one\r\n    may express how serial components interact with parallel\r\n    components. The interactions may take place in one of two contexts (a) when\r\n    creating, submitting, and evaluating tasks, and (b) when creating\r\n    and processing messages.\r\n\r\n    However, any //usage// of a parallel closure within //any resource// is\r\n    predicated on a successful, safe, asynchronous and race-free //declaration and\r\n    definition across many compute resources//.\r\n\r\n    We shall describe how SPM.Python solves this fundamental problem\r\n    by augmenting the traditional concept of serial sequence points.\r\n\r\n=== Conclusion\r\n\r\nDuring the development of SPM.Python, several fundamental problems  \r\n   were solved in order to deliver a scalable parallel version of the serial\r\n   Python language. At the poster session, the audience will possess\r\n   an understanding of the technical challenges involved and how they\r\n   were addressed.\r\n", 
            "title": "A Technical Anatomy of SPM.Python, a Scalable, Parallel Version of Python", 
            "plenary": false, 
            "abstract_html": "<p>Spm.Python, a commercial product, extends Python with a programming\r paradigm for solving parallel problems and strives to do so in a\r pythonic (natural) way. This is achieved by augmenting the serial\r Python language with parallel concepts like parallel task managers and\r communication primitives.\r</p>\n<p>In this poster session, we examine the what, why and how this augmentation was done. The context for and solutions to three\r formerly open technical problems will be discussed, including:\r</p>\n<ul>\n<li>extensions to the general exception handling infrastructure across  many compute resources,\r</li>\n</ul>\n<ul>\n<li>design of parallel constructs in a way so that serial components are delineated from parallel components, and\r</li>\n</ul>\n<ul>\n<li>declaration and definition of parallel closures, the building blocks of all parallel constructs.\r</li>\n</ul>\n<h4>Parallel exception infrastructure</h4>\n<p>To quote Wikipedia, <i>\"exception handling is a construct designed\r     to handle the occurrence of exceptions, special conditions\r     that change the normal flow of program execution\"</i>.\r</p>\n<p>As such, the ability to throw and catch exceptions forms the bedrock of the serial Python language. We will review\r     details of how we extended the basic serial exception\r     infrastructure to account for exceptions that may occur across\r     many compute resources.\r</p>\n<p>    Our solution is predicated on the notion that parallel managers\r     must take ownership of how serial exceptions are handled across\r     all resources under their control. In other words, unlike in the\r     serial world, the parallel exception handling infrastructure must\r     be customized for each parallel manager.\r</p>\n<h4>Decoupling serial components from parallel  components</h4>\n<p>One of the main tenants of the serial software eco-system is the\r     asymptotic parity between the serial compute resources available to the\r     developers and the end-users, which makes possible the easy\r     reporting, reproduction, and resolution of bugs.\r</p>\n<p>    With parallel software, this most fundamental of tenants is\r     violated; software engineers need to be able to produce high-quality\r     parallel software in what is an essentially serial environment,\r     yet be able to deploy that software in a parallel environment.\r</p>\n<p>    We will describe how SPM.Python addresses this dichotomy by offering easy to relate to\r     parallel primitives. These primitives permit the prototyping,\r     validation, and testing of parallel ideas in the essentially\r     serial development environment, and yet deliver performance\r     when exercised in the parallel environment.\r</p>\n<h4>Declaring and defining parallel closures</h4>\n<p>In SPM.Python, parallel closures are the building blocks of all\r     parallel constructs, and provide the sole means by which one\r     may express how serial components interact with parallel\r     components. The interactions may take place in one of two contexts (a) when\r     creating, submitting, and evaluating tasks, and (b) when creating\r     and processing messages.\r</p>\n<p>    However, any <i>usage</i> of a parallel closure within <i>any resource</i> is\r     predicated on a successful, safe, asynchronous and race-free <i>declaration and\r     definition across many compute resources</i>.\r</p>\n<p>    We shall describe how SPM.Python solves this fundamental problem\r     by augmenting the traditional concept of serial sequence points.\r</p>\n<h3>Conclusion</h3>\n<p>During the development of SPM.Python, several fundamental problems  \r    were solved in order to deliver a scalable parallel version of the serial\r    Python language. At the poster session, the audience will possess\r    an understanding of the technical challenges involved and how they\r    were addressed.\r</p>\n", 
            "speaker": 77, 
            "submitted": "2010-10-31 02:47:33", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 121, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "After a year of the Flask microframework it's time to draw some conclusions, see things that went right and things that should be improved.  The talk gives both an introduction into Flask itself as well as well as the ecosystem that evolved around it.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Flask is a microframework that was born out of an April's fool joke that quickly became more than that.  Based on the powerful foundation of Werkzeug and Jinja2 it's one of the most popular frameworks for Python now.\r\n\r\nThe talk starts with a very quick introduction into Flask, where it all started and why I think people like it.  We will look into the design of Flask and why it works the way it works.\r\n\r\nFurthermore we will look into the Flask ecosystem and how extensions work and have a brief look in what is planned for the future, especially regarding Python 3.\r\n\r\nThe talk assumes basic knowledge of web applications.", 
            "title": "Opening the Flask", 
            "plenary": false, 
            "abstract_html": "<p>Flask is a microframework that was born out of an April's fool joke that quickly became more than that.  Based on the powerful foundation of Werkzeug and Jinja2 it's one of the most popular frameworks for Python now.\r</p>\n<p>The talk starts with a very quick introduction into Flask, where it all started and why I think people like it.  We will look into the design of Flask and why it works the way it works.\r</p>\n<p>Furthermore we will look into the Flask ecosystem and how extensions work and have a brief look in what is planned for the future, especially regarding Python 3.\r</p>\n<p>The talk assumes basic knowledge of web applications.</p>\n", 
            "speaker": 145, 
            "submitted": "2010-10-31 08:02:36", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 123, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "At the Chicago Tribune we develop, test, and deploy production web applications on schedules that range from two hours to two months.  This talk will discuss the tools and techniques that allow us to make our deadlines, including automated deployments, frameworks, just-in-time testing, and more.  Attention will be paid to http://github.com/newsapps/beeswithmachineguns and the problems they solve.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "On my first day at the Chicago Tribune I was given a CSV of data about defoliant spraying in Vietnam and told to build this: [[http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage|Agent Orange]].  What followed was one of the most stressful and difficult weeks of my life, during which I learned an incredible amount about web development.  I had to stop thinking about databases and start thinking about serialized JSON structures stashed on S3; stop thinking about building tools and start thinking about mashing up tech that was never designed to be married (in this case [[http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage|Simile Timeline]] and Google Maps); stop thinking about idealistic development practices and start thinking about getting a working product out the door.  In short: I had to rewire my brain for news.\r\n\r\nThis talk will go in-depth on deadline-oriented strategies that I've learned in a year of building news applications.  Some of these revolve around specific technologies, like [[http://docs.fabfile.org/0.9.2/|fabric]] for single-keystroke deployments or [[http://www.varnish-cache.org/|Varnish]] for caching, but most will be matters of practice, like what to test when you have no time for testing or how to avoid (yes, avoid!) database migrations.\r\n\r\nThey say Django is \"the web framework for perfectionists with deadlines.\"  This is their Art of War.\r\n\r\nTalk outline:\r\n\r\n* An anecdote: [[http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage|Agent Orange]]\r\n* We can't have nice things (or best practices)\r\n* Low-hanging fruit: staging environment, git branches, PEP8.\r\n* Only build it once: Iterations, interviews and stakeholders\r\n* Salvage, share and steal [code]\r\n* Keeping track: Be a ticketing warrior\r\n* Tools improve faster than you do: iterate your stack\r\n* Single-keystroke deployment (fabric)\r\n* Migrations are hard: Building read-only apps\r\n* Don't serve that: Using S3 for hosting\r\n* Caching > optimization (varnish)\r\n* Know your load limits (beeswithmachineguns)\r\n* Configuration-as-application: application frameworks (maps, tables)\r\n* Pair programming > functional testing > unit testing\r\n* except UseWordpress, e: print \"No, really\"\r\n\r\nSites that will be used as examples:\r\n\r\n* [[http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage|Agent Orange]]\r\n* [[http://www.burroakmemorial.com/|Burr Oak Memorial]]\r\n* [[http://media.apps.chicagotribune.com/maps/census_participation_2010.html|Census 2010: Cook county participation rates map]]\r\n* [[http://media.apps.chicagotribune.com/tables/speed.html|Area judges and supervision rates of speeders table]]\r\n* [[http://homicides.redeyechicago.com/|RedEye Homicide Tracker]]\r\n* [[http://elections.chicagotribune.com/|Chicago Tribune Elections Center]]\r\n* [[http://schools.chicagotribune.com/|2010 Illinois School Report Cards]]\r\n* [[http://triblocal.com/|TribLocal]]", 
            "title": "Best Practices for Impossible Deadlines", 
            "plenary": false, 
            "abstract_html": "<p>On my first day at the Chicago Tribune I was given a CSV of data about defoliant spraying in Vietnam and told to build this: <a href=\"http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage\">Agent Orange</a>.  What followed was one of the most stressful and difficult weeks of my life, during which I learned an incredible amount about web development.  I had to stop thinking about databases and start thinking about serialized JSON structures stashed on S3; stop thinking about building tools and start thinking about mashing up tech that was never designed to be married (in this case <a href=\"http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage\">Simile Timeline</a> and Google Maps); stop thinking about idealistic development practices and start thinking about getting a working product out the door.  In short: I had to rewire my brain for news.\r</p>\n<p>This talk will go in-depth on deadline-oriented strategies that I've learned in a year of building news applications.  Some of these revolve around specific technologies, like <a href=\"http://docs.fabfile.org/0.9.2/\">fabric</a> for single-keystroke deployments or <a href=\"http://www.varnish-cache.org/\">Varnish</a> for caching, but most will be matters of practice, like what to test when you have no time for testing or how to avoid (yes, avoid!) database migrations.\r</p>\n<p>They say Django is \"the web framework for perfectionists with deadlines.\"  This is their Art of War.\r</p>\n<p>Talk outline:\r</p>\n<ul>\n<li>An anecdote: <a href=\"http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage\">Agent Orange</a>\r</li>\n<li>We can't have nice things (or best practices)\r</li>\n<li>Low-hanging fruit: staging environment, git branches, PEP8.\r</li>\n<li>Only build it once: Iterations, interviews and stakeholders\r</li>\n<li>Salvage, share and steal [code]\r</li>\n<li>Keeping track: Be a ticketing warrior\r</li>\n<li>Tools improve faster than you do: iterate your stack\r</li>\n<li>Single-keystroke deployment (fabric)\r</li>\n<li>Migrations are hard: Building read-only apps\r</li>\n<li>Don't serve that: Using S3 for hosting\r</li>\n<li>Caching &gt; optimization (varnish)\r</li>\n<li>Know your load limits (beeswithmachineguns)\r</li>\n<li>Configuration-as-application: application frameworks (maps, tables)\r</li>\n<li>Pair programming &gt; functional testing &gt; unit testing\r</li>\n<li>except UseWordpress, e: print \"No, really\"\r</li>\n</ul>\n<p>Sites that will be used as examples:\r</p>\n<ul>\n<li><a href=\"http://www.chicagotribune.com/health/agentorange/chi-091204-agentorange-map,0,1959438.htmlpage\">Agent Orange</a>\r</li>\n<li><a href=\"http://www.burroakmemorial.com/\">Burr Oak Memorial</a>\r</li>\n<li><a href=\"http://media.apps.chicagotribune.com/maps/census_participation_2010.html\">Census 2010: Cook county participation rates map</a>\r</li>\n<li><a href=\"http://media.apps.chicagotribune.com/tables/speed.html\">Area judges and supervision rates of speeders table</a>\r</li>\n<li><a href=\"http://homicides.redeyechicago.com/\">RedEye Homicide Tracker</a>\r</li>\n<li><a href=\"http://elections.chicagotribune.com/\">Chicago Tribune Elections Center</a>\r</li>\n<li><a href=\"http://schools.chicagotribune.com/\">2010 Illinois School Report Cards</a>\r</li>\n<li><a href=\"http://triblocal.com/\">TribLocal</a></li>\n</ul>\n", 
            "speaker": 152, 
            "submitted": "2010-10-31 10:39:07", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 122, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "As most Python programmers know, Python 3 breaks backwards compatibility with Python 2.  One of the most significant changes concerns the new I/O system.  In this tutorial, we're going to take a top-to-bottom tour of the entire Python 3 I/O system and provide practical advice for programmers porting code from Python 2 to Python 3.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "As most Python programmers know, Python 3 breaks backwards\r\ncompatibility with Python 2 in a number of significant ways.  Although\r\nguides to Python 3 tend to focus on superficial incompatibilities such\r\nas the new print function, changes to exception handling, or new\r\nlanguage features, the most substantial changes concern the strict\r\nseparation of Unicode and bytes as well as the new I/O stack.  Not\r\nonly do these changes have far-reaching effects throughout the\r\nstandard library, but changes to I/O are likely to be the most major\r\nsource of problems for anyone porting an existing Python application\r\nto Python 3.  In this tutorial, we're going to take a top-to-bottom\r\ntour of the entire Python 3 I/O system.  We'll focus on how to\r\nproperly handle both text and binary data, changes to standard library\r\nmodules, examine advanced features such as the buffer API, perform\r\nsome performance experiments, and end with practical advice for\r\nprogrammers working on porting applications from Python 2 to 3.\r\n\r\nThe following major topics will be covered:\r\n\r\n- Introducing Python 3 (with a focus on I/O)\r\n- Text Processing\r\n- Binary Data Handling\r\n- Dealing with System Interfaces and External Programs\r\n- The New io library\r\n- Network programming\r\n- Porting from Python 2 to 3.\r\n", 
            "title": "Mastering Python 3 I/O", 
            "plenary": false, 
            "abstract_html": "<p>As most Python programmers know, Python 3 breaks backwards\r compatibility with Python 2 in a number of significant ways.  Although\r guides to Python 3 tend to focus on superficial incompatibilities such\r as the new print function, changes to exception handling, or new\r language features, the most substantial changes concern the strict\r separation of Unicode and bytes as well as the new I/O stack.  Not\r only do these changes have far-reaching effects throughout the\r standard library, but changes to I/O are likely to be the most major\r source of problems for anyone porting an existing Python application\r to Python 3.  In this tutorial, we're going to take a top-to-bottom\r tour of the entire Python 3 I/O system.  We'll focus on how to\r properly handle both text and binary data, changes to standard library\r modules, examine advanced features such as the buffer API, perform\r some performance experiments, and end with practical advice for\r programmers working on porting applications from Python 2 to 3.\r</p>\n<p>The following major topics will be covered:\r</p>\n<p>- Introducing Python 3 (with a focus on I/O)\r - Text Processing\r - Binary Data Handling\r - Dealing with System Interfaces and External Programs\r - The New io library\r - Network programming\r - Porting from Python 2 to 3.\r</p>\n", 
            "speaker": 128, 
            "submitted": "2010-10-31 08:07:56", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 118, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "Are you new to Python and want to learn how to step it up to the next level? Have you wondered about functional programming, closures, decorators, context managers, generators or list comprehensions and when you should use them and how to test them? This hands-on tutorial will cover these intermediate subjects in detail, by explaining the theory behind them then walking through examples.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "Tutorial will be in the the form of short lecture, short assignment to practice the concepts.\r\n\r\nAttendees should come with a laptop and Python 2.x (3.x differences will be noted).\r\n\r\nTutorial will cover:\r\n\r\n* Testing (unittest and doctest)\r\n* Functional Programming\r\n* Functions\r\n* Closures \r\n* Decorators\r\n* Class decorators\r\n* Properties \r\n* Context Managers\r\n* List comprehensions\r\n* Iterator pattern \r\n* Generators \r\n\r\nMaterials include slides, handout and assignment code.  Prizes to be awarded for completion of assignment.", 
            "title": "Hands on Intermediate Python", 
            "plenary": false, 
            "abstract_html": "<p>Tutorial will be in the the form of short lecture, short assignment to practice the concepts.\r</p>\n<p>Attendees should come with a laptop and Python 2.x (3.x differences will be noted).\r</p>\n<p>Tutorial will cover:\r</p>\n<ul>\n<li>Testing (unittest and doctest)\r</li>\n<li>Functional Programming\r</li>\n<li>Functions\r</li>\n<li>Closures \r</li>\n<li>Decorators\r</li>\n<li>Class decorators\r</li>\n<li>Properties \r</li>\n<li>Context Managers\r</li>\n<li>List comprehensions\r</li>\n<li>Iterator pattern \r</li>\n<li>Generators \r</li>\n</ul>\n<p>Materials include slides, handout and assignment code.  Prizes to be awarded for completion of assignment.</p>\n", 
            "speaker": 150, 
            "submitted": "2010-10-31 00:31:43", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 131, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The Catch.com backend provides an API for publishing and querying your personal data - used by many hugely popular Android, iOS and Web clients. We ported this system to Python and MongoDB, using the Pylons Web framework. This talk details our reasoning for choosing - and experiences with - these cutting-edge Web and NoSQL database technologies in a high-traffic, real-world production system.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Faced with the limits of our initial Catch.com Java/BDB backend implemention, we evaluated various alternative technologies including Amazon SimpleDB, MySQL, Cassandra and MongoDB. Eventually we settled on Python, Pylons and MongoDB.\r\n\r\nWe found Python and MongoDB gave us unique flexibility with our data model, allowed us to scale for increased reliability and performance and decreased feature development time - and in this talk we'll describe exactly how.\r\n\r\nWhile there are many advantages, Python/Pylons and MongoDB (as a relative newcomer on the database scene) certainly have issues and limitations which must be taken into careful consideration for any real-world production deployment.\r\n\r\nWe compare MongoDB with other database technologies such as more traditional RDBMS like MySQL and competing NoSQL options such as Cassandra, CouchDB and BDB.\r\n\r\nWe give a detailed introducton to data modeling in MongoDB - with special attention paid to how this differs from a traditional relational system - the operators provided by its rich query language and utilizing advanced features such as GeoSpatial indexing, Replica Sets, Sharding - and how to deal with some of the more publicized limitations of the system (such as single-server durability). \r\n\r\nWhile much of this talk will be about using MongoDB with Python, we will also touch on issues surrounding production deployment of the Pylons Web framework, including how we work around the GIL to take advantage of multi-core machines.", 
            "title": "MongoDB + Pylons at Catch.com: Scalable Web Apps with Python and NoSQL", 
            "plenary": false, 
            "abstract_html": "<p>Faced with the limits of our initial Catch.com Java/BDB backend implemention, we evaluated various alternative technologies including Amazon SimpleDB, MySQL, Cassandra and MongoDB. Eventually we settled on Python, Pylons and MongoDB.\r</p>\n<p>We found Python and MongoDB gave us unique flexibility with our data model, allowed us to scale for increased reliability and performance and decreased feature development time - and in this talk we'll describe exactly how.\r</p>\n<p>While there are many advantages, Python/Pylons and MongoDB (as a relative newcomer on the database scene) certainly have issues and limitations which must be taken into careful consideration for any real-world production deployment.\r</p>\n<p>We compare MongoDB with other database technologies such as more traditional RDBMS like MySQL and competing NoSQL options such as Cassandra, CouchDB and BDB.\r</p>\n<p>We give a detailed introducton to data modeling in MongoDB - with special attention paid to how this differs from a traditional relational system - the operators provided by its rich query language and utilizing advanced features such as GeoSpatial indexing, Replica Sets, Sharding - and how to deal with some of the more publicized limitations of the system (such as single-server durability). \r</p>\n<p>While much of this talk will be about using MongoDB with Python, we will also touch on issues surrounding production deployment of the Pylons Web framework, including how we work around the GIL to take advantage of multi-core machines.</p>\n", 
            "speaker": 9, 
            "submitted": "2010-10-31 16:52:29", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 137, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "With its clean, highly readable syntax, Python would seem to be quite a challenge for a programmer attempting to write obfuscated code.  Fortunately, it provides a wide variety of high-level abstractions that can be misused in exciting ways.  This survey of obfuscation strategies will include topics such as decorator abuse, lambda calculus, and bytecode manipulation.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Python's clean syntax can make traditional approaches to writing obfuscated code much more challenging.  Fortunately, Python provides many useful abstractions that can be misused to write code that is unreadable or even deliberately misleading.  This talk will provide a survey of silly python tricks that explore the boundaries of the language.\r\n\r\n** Topics **\r\n* Redefining builtins\r\n* Rarely used syntax\r\n* Comparison edge cases\r\n* Things you probably shouldn't do with decorators\r\n* Fun with lambdas\r\n* Bytecode manipulation", 
            "title": "How to write obfuscated python", 
            "plenary": false, 
            "abstract_html": "<p>Python's clean syntax can make traditional approaches to writing obfuscated code much more challenging.  Fortunately, Python provides many useful abstractions that can be misused to write code that is unreadable or even deliberately misleading.  This talk will provide a survey of silly python tricks that explore the boundaries of the language.\r</p>\n<p><b> Topics </b>\r</p>\n<ul>\n<li>Redefining builtins\r</li>\n<li>Rarely used syntax\r</li>\n<li>Comparison edge cases\r</li>\n<li>Things you probably shouldn't do with decorators\r</li>\n<li>Fun with lambdas\r</li>\n<li>Bytecode manipulation</li>\n</ul>\n", 
            "speaker": 57, 
            "submitted": "2010-10-31 19:18:35", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 138, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Believe it or not, but you can write pretty horrendously awful code even in a language as elegant as Python.  Over the years, I've committed my share of sins; now it's time to come clean.  Step right up for a tour of twisted, evil, and downright wrong code, and learn some strategies to avoid writing criminally bad code--if you dare!", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "What does it look like when good intentions go horribly wrong?  This talk will take a tour through pathological code from my past (as well as some contributions from friends, coworkers, and the community), featuring such terrors as:\r\n\r\n* Lies, Damn Lies, and Hungarian Notation\r\n* Crimes Against PEP-8\r\n* The Diaper Pattern\r\n* The Beast With a Thousand Elifs\r\n* The Mile-Long Club\r\n* God Objects and God Methods\r\n* The Malignant Menace of Mutable Keyword Arguments\r\n* The Seductive Lure of Global State\r\n* Slower Applications Through DTO Bondage\r\n* A Twisty Maze of Single-Character Variables, All Alike\r\n* Lambdas, Lambdas Everywhere\r\n* The List Comprehension That Ate Cincinnati\r\n* Adventures in Wheel Reinvention\r\n* New and Creative Ways to Break the Build\r\n\r\n...as well as others as time permits.", 
            "title": "Exhibition of Atrocity", 
            "plenary": false, 
            "abstract_html": "<p>What does it look like when good intentions go horribly wrong?  This talk will take a tour through pathological code from my past (as well as some contributions from friends, coworkers, and the community), featuring such terrors as:\r</p>\n<ul>\n<li>Lies, Damn Lies, and Hungarian Notation\r</li>\n<li>Crimes Against PEP-8\r</li>\n<li>The Diaper Pattern\r</li>\n<li>The Beast With a Thousand Elifs\r</li>\n<li>The Mile-Long Club\r</li>\n<li>God Objects and God Methods\r</li>\n<li>The Malignant Menace of Mutable Keyword Arguments\r</li>\n<li>The Seductive Lure of Global State\r</li>\n<li>Slower Applications Through DTO Bondage\r</li>\n<li>A Twisty Maze of Single-Character Variables, All Alike\r</li>\n<li>Lambdas, Lambdas Everywhere\r</li>\n<li>The List Comprehension That Ate Cincinnati\r</li>\n<li>Adventures in Wheel Reinvention\r</li>\n<li>New and Creative Ways to Break the Build\r</li>\n</ul>\n<p>...as well as others as time permits.</p>\n", 
            "speaker": 161, 
            "submitted": "2010-10-31 20:12:06", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 140, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "HTTP is the lingua franca of the web, and many things done in Python depend on it, yet HTTP in Python isn't always as good as one would expect. It's well worth knowing the options and tradeoffs available.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "HTTP in Python is very much a mixed bag of available technology. What's implemented mostly works well, but there are some frustrating gaps in different libraries that are poorly documented. I've gone wading through every HTTP library I can find for Python while trying to fix an obscure bug in Mercurial and decided to write my own. I'll cover what's available today and why I'm starting from scratch with a completely new implementation.", 
            "title": "HTTP in Python: which library for what task?", 
            "plenary": false, 
            "abstract_html": "<p>HTTP in Python is very much a mixed bag of available technology. What's implemented mostly works well, but there are some frustrating gaps in different libraries that are poorly documented. I've gone wading through every HTTP library I can find for Python while trying to fix an obscure bug in Mercurial and decided to write my own. I'll cover what's available today and why I'm starting from scratch with a completely new implementation.</p>\n", 
            "speaker": 162, 
            "submitted": "2010-10-31 20:44:13", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 145, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "With Andreas Kl\u00f6ckner's PyCUDA, you can harness the massively parallel supercomputing power of your NVIDIA graphics card to crunch numerically intensive scientific computing applications in a fraction of the runtime it would take on a CPU and at a fraction of the development cost of C++. We'll cover hardware architecture, API fundamentals and several examples to get you started.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "There are two approaches to parallelizing a computationally heavy procedure: use a messaging queue such as AMQP to distribute tasks among a networked cluster or increase the number of processors in a single machine.  This talk focuses on techniques for adapting mathematical code to run on specialized multi-core graphic processors.\r\n\r\nModern graphic processors have hard-coded transistors for common vector and matrix operations, making them ideal for general scientific computing.  However, the NVIDIA CUDA's unique design requires knowledge of its hardware to adapt algorithms effectively.  This talk covers basic CUDA architecture, API functions and several examples to illustrate the different kinds of problems that will benefit from parallelization.", 
            "title": "Introduction to Parallel Computing on an NVIDIA GPU using PyCUDA", 
            "plenary": false, 
            "abstract_html": "<p>There are two approaches to parallelizing a computationally heavy procedure: use a messaging queue such as AMQP to distribute tasks among a networked cluster or increase the number of processors in a single machine.  This talk focuses on techniques for adapting mathematical code to run on specialized multi-core graphic processors.\r</p>\n<p>Modern graphic processors have hard-coded transistors for common vector and matrix operations, making them ideal for general scientific computing.  However, the NVIDIA CUDA's unique design requires knowledge of its hardware to adapt algorithms effectively.  This talk covers basic CUDA architecture, API functions and several examples to illustrate the different kinds of problems that will benefit from parallelization.</p>\n", 
            "speaker": 153, 
            "submitted": "2010-10-31 21:26:36", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 146, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Modeling of chemical processes in the subsurface is very important for a the\r\ninvestigation of environmental problems. The leading modeling software in this\r\nfield is PHREEQC.\r\nWhen combined with Python new applications  such as comprehensive scenario\r\nanalysis, construction of phase diagrams, or multi-dimensional reactive\r\ntransport modeling become possible.", 
            "additional_speakers": [
                169
            ], 
            "session_type": 4, 
            "track": null, 
            "abstract": "Mine water drainage, landfill drainage, or abandoned industrial plants cause\r\nmany environmental problems. To solve these problems complicated chemical\r\nprocesses in the subsurface have to be examined.\r\n\r\nNumerical modeling has been established as viable method to describe and\r\npredict the hydro-geo-chemistry of complex systems. PHREEQC, a Public Domain\r\nprogram by the United States Geological Survey, is probably the worldwide most\r\nused software for this type of modeling. The reasons for its popularity are the\r\nnumerous processes it can handle as well as the very flexible text-based input\r\nformat.\r\n\r\nPython is very powerful when it comes to string processing and hence can be\r\nused to programmatically generate input files for PHREEQC. After running\r\nPHREEQC with help of the module {{{subprocess}}} the modeling results can be\r\neasily read with Python. This simple technique opens up the possibility for a\r\nwide range of new applications.\r\n\r\nPreviously nearly impossible tasks become simple. Hydro-geo-chemists with only\r\na little Python experience can quickly automatically assemble input files and\r\nrun hundreds or thousands of calculations without any manual effort.\r\nPhase diagrams can easily be constructed using this technique.\r\nMulti-dimensional, reactive transport modeling is surprisingly simple using\r\nPython. Two programs, a flow-and-transport software and PHREEQC are\r\nsequentially run with Python. Constructing input files and reading output files\r\ncombined with the appropriate conversions of data in Python can be used to\r\ncreate a new model without changing the original programs. Even though this\r\ninvolves some more programming and demands more Python expertise, it is much\r\nless laborious than coupling the models with compiled languages.\r\n\r\nPublication-quality diagrams can be generated from the modeling results with\r\n{{{matplotlib}}}. Once automated, the workflow of changing input values,\r\nrerunning the calculations, and displaying the results is much faster than\r\nthe traditional spreadsheet-base approach.", 
            "title": "Python for Hydro-Geo-Chemical Modeling", 
            "plenary": false, 
            "abstract_html": "<p>Mine water drainage, landfill drainage, or abandoned industrial plants cause\r many environmental problems. To solve these problems complicated chemical\r processes in the subsurface have to be examined.\r</p>\n<p>Numerical modeling has been established as viable method to describe and\r predict the hydro-geo-chemistry of complex systems. PHREEQC, a Public Domain\r program by the United States Geological Survey, is probably the worldwide most\r used software for this type of modeling. The reasons for its popularity are the\r numerous processes it can handle as well as the very flexible text-based input\r format.\r</p>\n<p>Python is very powerful when it comes to string processing and hence can be\r used to programmatically generate input files for PHREEQC. After running\r PHREEQC with help of the module <tt>subprocess</tt> the modeling results can be\r easily read with Python. This simple technique opens up the possibility for a\r wide range of new applications.\r</p>\n<p>Previously nearly impossible tasks become simple. Hydro-geo-chemists with only\r a little Python experience can quickly automatically assemble input files and\r run hundreds or thousands of calculations without any manual effort.\r Phase diagrams can easily be constructed using this technique.\r Multi-dimensional, reactive transport modeling is surprisingly simple using\r Python. Two programs, a flow-and-transport software and PHREEQC are\r sequentially run with Python. Constructing input files and reading output files\r combined with the appropriate conversions of data in Python can be used to\r create a new model without changing the original programs. Even though this\r involves some more programming and demands more Python expertise, it is much\r less laborious than coupling the models with compiled languages.\r</p>\n<p>Publication-quality diagrams can be generated from the modeling results with\r <tt>matplotlib</tt>. Once automated, the workflow of changing input values,\r rerunning the calculations, and displaying the results is much faster than\r the traditional spreadsheet-base approach.</p>\n", 
            "speaker": 135, 
            "submitted": "2010-10-31 21:35:21", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 147, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Showing how to use Python to prototype powerful concurrency features for Stackless Python. We do want you to try this at home. ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Google\u2019s introduction of the Go language raised eyebrows in the Stackless Python community. Although very different languages, Go and Stackless Python\u2019s concurrency model share a common ancestor: the Bell Labs family of languages (i.e., Newsqueak, Limbo). The common feature are channels: a synchronous message passing mechanism based on Tony Hoare\u2019s Communicating Sequential Processes (CSP).\r\n\r\nBoth Go and Python have channels. However with the select language statement, Go has the ability to wait on multiple channels simultaneously. Select greatly simplifies many concurrent programming problems. Stackless Python does not have this feature. Other channel based languages also feature powerful concurrency constructs. How hard would these constructs be to implement for Stackless Python?\r\n\r\nThis talk explores the prototyping potential of stackless.py, the PyPy's framework's implementation of Stackless Python. The beauty of stackless.py is that it is written in Python and implements much of Stackless Python's API! The \"case study\" involves prototyping Go's select in stackless.py before reimplementing select in C based Stackless Python.\r\n\r\nDuring this talk, it will be shown how stackless.py can be used with CPython and the greenlet package (no need to install another Python). The audience will also get an in depth look at how channels are implemented. Channels are at the heart of Stackless Python's message based concurrency model. Finally the audience will gain insights into future directions of Stackless Python.", 
            "title": "Prototyping Go's Select with stackless.py for Stackless Python", 
            "plenary": false, 
            "abstract_html": "<p>Google\u2019s introduction of the Go language raised eyebrows in the Stackless Python community. Although very different languages, Go and Stackless Python\u2019s concurrency model share a common ancestor: the Bell Labs family of languages (i.e., Newsqueak, Limbo). The common feature are channels: a synchronous message passing mechanism based on Tony Hoare\u2019s Communicating Sequential Processes (CSP).\r</p>\n<p>Both Go and Python have channels. However with the select language statement, Go has the ability to wait on multiple channels simultaneously. Select greatly simplifies many concurrent programming problems. Stackless Python does not have this feature. Other channel based languages also feature powerful concurrency constructs. How hard would these constructs be to implement for Stackless Python?\r</p>\n<p>This talk explores the prototyping potential of stackless.py, the PyPy's framework's implementation of Stackless Python. The beauty of stackless.py is that it is written in Python and implements much of Stackless Python's API! The \"case study\" involves prototyping Go's select in stackless.py before reimplementing select in C based Stackless Python.\r</p>\n<p>During this talk, it will be shown how stackless.py can be used with CPython and the greenlet package (no need to install another Python). The audience will also get an in depth look at how channels are implemented. Channels are at the heart of Stackless Python's message based concurrency model. Finally the audience will gain insights into future directions of Stackless Python.</p>\n", 
            "speaker": 165, 
            "submitted": "2010-10-31 21:35:53", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 144, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "Gain an in-depth understanding of Python's geospatial libraries by working in small groups on an extensive set of guided exercises with provided solutions.  Groups are paired by common interest and answers to common questions are shared with the class every half-hour.  Each category also has a challenge question and an attendee who successfully solves a challenge question receives a cash prize.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "Student should be well versed in Python and should have all of the standard geospatial packages installed before class (listed below).\r\n\r\nThe work-at-your-own pace format lets the tutorial cover a much larger set of topics than a standard presentation.  Exercises are divided into five categories: \r\n* core \r\n** creating and comparing geometries with shapely/geos\r\n** reading and writing kml/shapefiles with gdal\r\n** transforming between spatial references with proj\r\n* mapping \r\n** reading and writing to spatial databases such as Spatialite and PostGIS with geoalchemy\r\n** displaying vector and raster data using geojson and openlayers/polymaps\r\n** creating static base layers with mapnik\r\n* visualization \r\n** displaying parts of 16-bit satellite images with matplotlib\r\n** creating 3D maps with mayavis2\r\n* extensions \r\n** creating a qgis plugin\r\n** creating an ArcGIS plugin\r\n** creating a plugin for GeoProcessor.org\r\n* parallelization \r\n** writing simple algorithms to run on GPUs using PyCUDA\r\n** scaling your geoprocessing framework using AMQP", 
            "title": "Geospatial Computation and Visualization Cooperative Lab", 
            "plenary": false, 
            "abstract_html": "<p>Student should be well versed in Python and should have all of the standard geospatial packages installed before class (listed below).\r</p>\n<p>The work-at-your-own pace format lets the tutorial cover a much larger set of topics than a standard presentation.  Exercises are divided into five categories: \r</p>\n<ul>\n<li>core \r<ul>\n<li>creating and comparing geometries with shapely/geos\r</li>\n<li>reading and writing kml/shapefiles with gdal\r</li>\n<li>transforming between spatial references with proj\r</li>\n</ul>\n</li>\n<li>mapping \r<ul>\n<li>reading and writing to spatial databases such as Spatialite and PostGIS with geoalchemy\r</li>\n<li>displaying vector and raster data using geojson and openlayers/polymaps\r</li>\n<li>creating static base layers with mapnik\r</li>\n</ul>\n</li>\n<li>visualization \r<ul>\n<li>displaying parts of 16-bit satellite images with matplotlib\r</li>\n<li>creating 3D maps with mayavis2\r</li>\n</ul>\n</li>\n<li>extensions \r<ul>\n<li>creating a qgis plugin\r</li>\n<li>creating an ArcGIS plugin\r</li>\n<li>creating a plugin for GeoProcessor.org\r</li>\n</ul>\n</li>\n<li>parallelization \r<ul>\n<li>writing simple algorithms to run on GPUs using PyCUDA\r</li>\n<li>scaling your geoprocessing framework using AMQP</li>\n</ul>\n</li>\n</ul>\n", 
            "speaker": 153, 
            "submitted": "2010-10-31 21:25:52", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 150, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Sourceforge.net has been in the top 100 sites on the internet, and we discovered that python was easily able to scale up to handle that traffic.   In fact Python is now the core language for all new features, and is taking over all of sourceforge.net. ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The path from legacy PHP to modern python tools has been long an bumpy, and this is the story of how we took Python  from a single prototype site, to the core technology driving SourceForge.net.   I will discuss the mistakes we made along the way, the benefits that sold python, and the real secret behind our python transformation. \r\n\r\nA few highlights include: \r\n\r\n* How we abused libraries for fun and profit\r\n* How a major mistake made us look good\r\n* How the python community worked for us\r\n* How we couldn't have done it without Django AND TurboGears\r\n", 
            "title": "Scaling Python past 100", 
            "plenary": false, 
            "abstract_html": "<p>The path from legacy PHP to modern python tools has been long an bumpy, and this is the story of how we took Python  from a single prototype site, to the core technology driving SourceForge.net.   I will discuss the mistakes we made along the way, the benefits that sold python, and the real secret behind our python transformation. \r</p>\n<p>A few highlights include: \r</p>\n<ul>\n<li>How we abused libraries for fun and profit\r</li>\n<li>How a major mistake made us look good\r</li>\n<li>How the python community worked for us\r</li>\n<li>How we couldn't have done it without Django AND TurboGears\r</li>\n</ul>\n", 
            "speaker": 170, 
            "submitted": "2010-10-31 22:59:55", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 152, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "I may be BDFL of one framework, but that's also why I pay attention to the whole ecosystem. From the release of Plone 4,  TurboGears 2, Django 1.2 and Pylons 1 ,it's been an interesting year. And things like html5lib, an updated WSGI spec, and a contender for the next generation WSGI have all made things interesting.  Come explore the wild and dynamic jungle that I call \"the python web toolkit.\"", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk will not teach people to use python to make websites.  It's to teach people who already use python, that there are lots of different tools out there, and to help us all get some perspective on the python web toolkit. \r\n\r\nIn 2005 Pycon had the great PyWebOff, and while this talk won't be about throwing Twisted into a cage match with Zope3, or setting Flask up in a fight to the death against web.py, it will one again provide an attempt to survey the full landscape of the python web world, and to see how far we've come in the last 5 years. \r\n\r\nWe've definitely come a long way.  Django has brought over many converts to Python, google released app engine with python as the first supported language, and there are quite a few sites in the top 100 using python to serve up dynamic content to hundreds of millions of users.\r\n\r\nBut it hasn't all been good either, there's more fragmentation than ever.   We've also got more half finished libraries, and broken framework extensions, and abandoned projects littering up the landscape. ", 
            "title": "An (biased) survey of the python web", 
            "plenary": false, 
            "abstract_html": "<p>This talk will not teach people to use python to make websites.  It's to teach people who already use python, that there are lots of different tools out there, and to help us all get some perspective on the python web toolkit. \r</p>\n<p>In 2005 Pycon had the great PyWebOff, and while this talk won't be about throwing Twisted into a cage match with Zope3, or setting Flask up in a fight to the death against web.py, it will one again provide an attempt to survey the full landscape of the python web world, and to see how far we've come in the last 5 years. \r</p>\n<p>We've definitely come a long way.  Django has brought over many converts to Python, google released app engine with python as the first supported language, and there are quite a few sites in the top 100 using python to serve up dynamic content to hundreds of millions of users.\r</p>\n<p>But it hasn't all been good either, there's more fragmentation than ever.   We've also got more half finished libraries, and broken framework extensions, and abandoned projects littering up the landscape. </p>\n", 
            "speaker": 170, 
            "submitted": "2010-10-31 23:32:20", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 153, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk explains the modern techniques that every module maintainer needs to know in order to support all major versions of Python.  You probably already have a massive test suite using a tool like nosetests, py.test, unittest, or a custom runner.  Using the tox command line tool, you'll see how to run your tests in Python 2.x, 3.x, Jython, and whatever else in parallel.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "[[http://codespeak.net/tox/Tox|tox]] is a new tool that lets you set up isolated [[http://pypi.python.org/pypi/virtualenv|virtual environments]] to\r\ntest your module's deployment and compatibility with all major versions of\r\nPython. It's easy to install and is flexible enough that it probably already\r\nsupports your existing test suite. With one simple command you can execute\r\nyour test suite in each version of Python, you can build its documentation\r\nwith [[http://sphinx.pocoo.org/|Sphinx]], and get a nice printout of the results. It has also been\r\ndesigned from the ground up to integrate into continuous integration (CI)\r\ntools like [[http://hudson-ci.org/|Hudson]].\r\n\r\nUsing practical examples, this talk will show you how to toxify your existing test suite and trick it out with the tox.ini config file.  You'll also see how to leverage Hudson's matrix build so that each code checkin will run tests in all versions of Python and report detailed failures.\r\n\r\nYour app supports Python 3, right?  No?  Tox is the best way to develop in parallel with 2.x and 3.x.  We'll go over how to set up tox for that.\r\n\r\n\r\n", 
            "title": "Supporting All Versions of Python All The Time With Tox", 
            "plenary": false, 
            "abstract_html": "<p><a href=\"http://codespeak.net/tox/Tox\">tox</a> is a new tool that lets you set up isolated <a href=\"http://pypi.python.org/pypi/virtualenv\">virtual environments</a> to\r test your module's deployment and compatibility with all major versions of\r Python. It's easy to install and is flexible enough that it probably already\r supports your existing test suite. With one simple command you can execute\r your test suite in each version of Python, you can build its documentation\r with <a href=\"http://sphinx.pocoo.org/\">Sphinx</a>, and get a nice printout of the results. It has also been\r designed from the ground up to integrate into continuous integration (CI)\r tools like <a href=\"http://hudson-ci.org/\">Hudson</a>.\r</p>\n<p>Using practical examples, this talk will show you how to toxify your existing test suite and trick it out with the tox.ini config file.  You'll also see how to leverage Hudson's matrix build so that each code checkin will run tests in all versions of Python and report detailed failures.\r</p>\n<p>Your app supports Python 3, right?  No?  Tox is the best way to develop in parallel with 2.x and 3.x.  We'll go over how to set up tox for that.\r</p>\n", 
            "speaker": 172, 
            "submitted": "2010-11-01 00:38:34", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 154, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Let's take an outsiders look at coroutines, the underlying concept used by greenlets. First we'll define what they are conceptually, and show some typical use cases. Then we'll take a look at a sampling of the implementations out there to see what they are actually doing to implement the concept. Finally, we'll show their pluses and minuses, and highlight some features of packages that use them.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Talk outline:\r\n\r\n # Define what a coroutine is\r\n ## Coroutine state not known to operating system\r\n ## Difference between a thread or process\r\n ## What state is required for tracking\r\n # Show how coroutines are used\r\n ## gevent example\r\n ## concurrence example\r\n # Review two implementations\r\n ## Greenlets\r\n ## Python based co-routines using generators\r\n # Advantages/Disadvantages\r\n # Differentiating features of packages that use them\r\n ## Concurrence\r\n ## Gevent\r\n ## Eventlets", 
            "title": "An outsider's look at co-routines.", 
            "plenary": false, 
            "abstract_html": "<p>Talk outline:\r</p>\n<ol>\n<li>Define what a coroutine is\r<ol>\n<li>Coroutine state not known to operating system\r</li>\n<li>Difference between a thread or process\r</li>\n<li>What state is required for tracking\r</li>\n</ol>\n</li>\n<li>Show how coroutines are used\r<ol>\n<li>gevent example\r</li>\n<li>concurrence example\r</li>\n</ol>\n</li>\n<li>Review two implementations\r<ol>\n<li>Greenlets\r</li>\n<li>Python based co-routines using generators\r</li>\n</ol>\n</li>\n<li>Advantages/Disadvantages\r</li>\n<li>Differentiating features of packages that use them\r<ol>\n<li>Concurrence\r</li>\n<li>Gevent\r</li>\n<li>Eventlets</li>\n</ol>\n</li>\n</ol>\n", 
            "speaker": 171, 
            "submitted": "2010-11-01 00:48:35", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 155, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Puppet is a configuration management tool that we'll learn to use the easy way.  We'll introduce the Puppet language and the concept of resources like packages, files, shell commands, and more.  We'll use Puppet to build our dev environment and deploy it to production servers.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "We've all been there: religiously following the steps in some blog post for the 47th time trying to setup a shiny new server.  We thought we'd improved the situation when we copied our Bash history into doit.sh and committed it.  Then along came Pip and requirements.txt files.\r\n\r\nThat's where most of us are today.  Pip can only manage Python packages so much of our servers' behavior is left to Lady Luck.  Puppet gives us the power to efficiently and confidently specify everything our program needs.\r\n\r\nWe'll start at square one and the concept of resources, the basic unit of configuration management.  We'll learn the Puppet language's resource syntax.  We'll talk about obvious resource types like packages and files plus less obvious types like shell commands, users, groups, and daemons.  We'll compose resources into larger ones, declare dependencies between resources, and accommodate differences between OS X and Linux.\r\n\r\nThese Puppet manifests can satisfy our program's dependencies on demand, making them ideal parts of the deploy process.  We'll walk through how Puppet is used to build production environments both through tools such as Fabric and Puppet's traditional client-server mode.\r\n\r\nDependency hell doesn't have to be your reality.  Consistent, reliable environments can be had with Puppet.", 
            "title": "Dependency management with Puppet", 
            "plenary": false, 
            "abstract_html": "<p>We've all been there: religiously following the steps in some blog post for the 47th time trying to setup a shiny new server.  We thought we'd improved the situation when we copied our Bash history into doit.sh and committed it.  Then along came Pip and requirements.txt files.\r</p>\n<p>That's where most of us are today.  Pip can only manage Python packages so much of our servers' behavior is left to Lady Luck.  Puppet gives us the power to efficiently and confidently specify everything our program needs.\r</p>\n<p>We'll start at square one and the concept of resources, the basic unit of configuration management.  We'll learn the Puppet language's resource syntax.  We'll talk about obvious resource types like packages and files plus less obvious types like shell commands, users, groups, and daemons.  We'll compose resources into larger ones, declare dependencies between resources, and accommodate differences between OS X and Linux.\r</p>\n<p>These Puppet manifests can satisfy our program's dependencies on demand, making them ideal parts of the deploy process.  We'll walk through how Puppet is used to build production environments both through tools such as Fabric and Puppet's traditional client-server mode.\r</p>\n<p>Dependency hell doesn't have to be your reality.  Consistent, reliable environments can be had with Puppet.</p>\n", 
            "speaker": 65, 
            "submitted": "2010-11-01 01:35:45", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 156, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "[[http://zodb.org|ZODB]] is a transactional persistence system written entirely in Python.  This talk will serve as an introduction to using the ZODB in a Python application.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk will provide a high-level overview of ZODB useful to a novice or intermediate Python programmer.  The talk will cover the following topics:\r\n\r\n* What Is ZODB?\r\n\r\n  * Brief history\r\n\r\n  * ZODB vs. relational databases\r\n\r\n  * ZODB vs. NoSQL databases\r\n\r\n  * ZODB vs. pickle\r\n\r\n* Using ZODB\r\n\r\n  * Creating a Persistent Object\r\n\r\n  * Storing a Persistent Object\r\n\r\n  * Retrieving a Persistent Object\r\n\r\n  * Modifying a Persistent Object\r\n\r\n  * Saving Changes\r\n\r\n  * Folders\r\n\r\n* Aspects\r\n\r\n  * Pluggable storages\r\n\r\n  * Scaling across multiple clients\r\n\r\n  * Caching\r\n\r\n* Indexing and Searching\r\n\r\n  * repoze.catalog\r\n\r\nAt the end of the talk, an attendee should have a basic understanding of how to create an application which depends on ZODB persistence.\r\n", 
            "title": "ZODB: A Python Persistence System", 
            "plenary": false, 
            "abstract_html": "<p>This talk will provide a high-level overview of ZODB useful to a novice or intermediate Python programmer.  The talk will cover the following topics:\r</p>\n<ul>\n<li>What Is ZODB?\r</li>\n</ul>\n<ul>\n<li>Brief history\r</li>\n</ul>\n<ul>\n<li>ZODB vs. relational databases\r</li>\n</ul>\n<ul>\n<li>ZODB vs. NoSQL databases\r</li>\n</ul>\n<ul>\n<li>ZODB vs. pickle\r</li>\n</ul>\n<ul>\n<li>Using ZODB\r</li>\n</ul>\n<ul>\n<li>Creating a Persistent Object\r</li>\n</ul>\n<ul>\n<li>Storing a Persistent Object\r</li>\n</ul>\n<ul>\n<li>Retrieving a Persistent Object\r</li>\n</ul>\n<ul>\n<li>Modifying a Persistent Object\r</li>\n</ul>\n<ul>\n<li>Saving Changes\r</li>\n</ul>\n<ul>\n<li>Folders\r</li>\n</ul>\n<ul>\n<li>Aspects\r</li>\n</ul>\n<ul>\n<li>Pluggable storages\r</li>\n</ul>\n<ul>\n<li>Scaling across multiple clients\r</li>\n</ul>\n<ul>\n<li>Caching\r</li>\n</ul>\n<ul>\n<li>Indexing and Searching\r</li>\n</ul>\n<ul>\n<li>repoze.catalog\r</li>\n</ul>\n<p>At the end of the talk, an attendee should have a basic understanding of how to create an application which depends on ZODB persistence.\r</p>\n", 
            "speaker": 95, 
            "submitted": "2010-11-01 01:39:07", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 157, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk introduces one 'NoSQL' solution, CouchDB, and how to get it to play well with Python. Topics covered:\r\n\r\n* Introduction to CouchDB\r\n* A python ORM for CouchDB\r\n* Parsing CouchDB documents within python\r\n* Writing view functions in python\r\n* Map/reduce on CouchDB from python\r\n* Lessons learned from managing and distributing a live deployment at scale under high load", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "== This is a rough draft==\r\n\r\n=== NoSQL ===\r\n* CouchDB stores schema free documents\r\n\r\n=== Why CouchDB? ===\r\n* Complicated mapping structures handled\r\n* Revision history\r\n* Maps nicely to Python objects\r\n* HTTP protocol\r\n\r\n=== Python ORM ===\r\n* couchdb-python\r\n* Mapping structures\r\n* //demo//\r\n\r\n=== View functions ===\r\n* write in Erlang, Javascript, Python?\r\n* //demo//\r\n\r\n=== Scaling ===\r\n* Distributed map/reduce\r\n* BigCouch\r\n* Read/write quorum", 
            "title": "CouchDB and Python in practice", 
            "plenary": false, 
            "abstract_html": "<h2>This is a rough draft</h2>\n<h3>NoSQL</h3>\n<ul>\n<li>CouchDB stores schema free documents\r</li>\n</ul>\n<h3>Why CouchDB?</h3>\n<ul>\n<li>Complicated mapping structures handled\r</li>\n<li>Revision history\r</li>\n<li>Maps nicely to Python objects\r</li>\n<li>HTTP protocol\r</li>\n</ul>\n<h3>Python ORM</h3>\n<ul>\n<li>couchdb-python\r</li>\n<li>Mapping structures\r</li>\n<li><i>demo</i>\r</li>\n</ul>\n<h3>View functions</h3>\n<ul>\n<li>write in Erlang, Javascript, Python?\r</li>\n<li><i>demo</i>\r</li>\n</ul>\n<h3>Scaling</h3>\n<ul>\n<li>Distributed map/reduce\r</li>\n<li>BigCouch\r</li>\n<li>Read/write quorum</li>\n</ul>\n", 
            "speaker": 44, 
            "submitted": "2010-11-01 02:13:14", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 159, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "In this talk I would like to present the SKA (Square Kilometer Array) project in South Africa and how is it run. The main focus will be what the problem area is, how to handle high data-throughput in the telescope and how to make it all work in Python.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Running large scale projects is always a challenge. At SKA South Africa, it was decided some time ago that the expressiveness of Python outweighs its potential drawbacks. In this talk I'll present the problem domain of running a large telescope, with a special focus of how to handle it in Python.\r\n\r\nAlmost everything in this project is written in Python. The production servers run Python for monitoring, control and data processing. Our full testing infrastructure (e.g. simulators) are written in Python. Python technologies in use include NumPy, SciPy and h5py.\r\n\r\nOn of the central points of our implementation is the KATCP network protocol, which is built in a way that it's possible to introspect devices around you. It has implementations using a normal select loop, twisted, Ruby and C. I'll describe how this protocol works, why it's better than others available and how we manage a large set of devices almost purely within Python.\r\n\r\nLessons learned while implementing software for SKA could be used for any other large-scale high-complexity python scientific projects.\r\n\r\nThe SKA will be a two thousand antenna radio telescope with an effective collecting area of one square kilometer [1]. Two countries are bidding to host this astronomical instrument -- South Africa and Australia. Construction of the SKA is expected to start in 2016 and be completed around 2024.\r\n\r\nSouth Africa's bid includes the construction of a sixty-four antenna array named MeerKAT which will itself be a leading radio astronomy instrument until the SKA is completed [2]. KAT7, a seven antenna prototype of MeerKAT is already in place on the MeerKAT site.\r\n\r\nMany important parts of the KAT7 system use Python, including::\r\n\r\n* monitoring of the entire system\r\n* simulators for the entire system\r\n* all low-level devices except the correlator and antenna motor controller\r\n* control of antenna positions\r\n* control of all ancillary devices\r\n* generation and presentation of data for user displays\r\n* post-processing of data\r\n* analysis of data (via NumPy, SciPy and CASA)\r\n\r\nA number of Python libraries have been released by the project under open source licenses::\r\n\r\n* PySPEAD (the correlator data transfer protocol) [3]\r\n* KATCP (the monitoring and control protocol) [4]\r\n* an HTML5 backend for matplotlib [5]\r\n* CASPER correlator interface utilities [6]\r\n\r\n[1] http://en.wikipedia.org/wiki/Square_Kilometre_Array\r\n[2] http://en.wikipedia.org/wiki/MeerKAT\r\n[3] http://github.com/sratcliffe/PySPEAD\r\n[4] http://pypi.python.org/pypi/katcp/0.3.0\r\n[5] http://code.google.com/p/mplh5canvas/\r\n[6] http://pypi.python.org/pypi/corr/0.5.1\r\n", 
            "title": "Running ultra large telescopes in Python", 
            "plenary": false, 
            "abstract_html": "<p>Running large scale projects is always a challenge. At SKA South Africa, it was decided some time ago that the expressiveness of Python outweighs its potential drawbacks. In this talk I'll present the problem domain of running a large telescope, with a special focus of how to handle it in Python.\r</p>\n<p>Almost everything in this project is written in Python. The production servers run Python for monitoring, control and data processing. Our full testing infrastructure (e.g. simulators) are written in Python. Python technologies in use include NumPy, SciPy and h5py.\r</p>\n<p>On of the central points of our implementation is the KATCP network protocol, which is built in a way that it's possible to introspect devices around you. It has implementations using a normal select loop, twisted, Ruby and C. I'll describe how this protocol works, why it's better than others available and how we manage a large set of devices almost purely within Python.\r</p>\n<p>Lessons learned while implementing software for SKA could be used for any other large-scale high-complexity python scientific projects.\r</p>\n<p>The SKA will be a two thousand antenna radio telescope with an effective collecting area of one square kilometer [1]. Two countries are bidding to host this astronomical instrument -- South Africa and Australia. Construction of the SKA is expected to start in 2016 and be completed around 2024.\r</p>\n<p>South Africa's bid includes the construction of a sixty-four antenna array named MeerKAT which will itself be a leading radio astronomy instrument until the SKA is completed [2]. KAT7, a seven antenna prototype of MeerKAT is already in place on the MeerKAT site.\r</p>\n<p>Many important parts of the KAT7 system use Python, including::\r</p>\n<ul>\n<li>monitoring of the entire system\r</li>\n<li>simulators for the entire system\r</li>\n<li>all low-level devices except the correlator and antenna motor controller\r</li>\n<li>control of antenna positions\r</li>\n<li>control of all ancillary devices\r</li>\n<li>generation and presentation of data for user displays\r</li>\n<li>post-processing of data\r</li>\n<li>analysis of data (via NumPy, SciPy and CASA)\r</li>\n</ul>\n<p>A number of Python libraries have been released by the project under open source licenses::\r</p>\n<ul>\n<li>PySPEAD (the correlator data transfer protocol) [3]\r</li>\n<li>KATCP (the monitoring and control protocol) [4]\r</li>\n<li>an HTML5 backend for matplotlib [5]\r</li>\n<li>CASPER correlator interface utilities [6]\r</li>\n</ul>\n<p>[1] <a href=\"http://en.wikipedia.org/wiki/Square_Kilometre_Array\">http://en.wikipedia.org/wiki/Square_Kilometre_Array</a>\r [2] <a href=\"http://en.wikipedia.org/wiki/MeerKAT\">http://en.wikipedia.org/wiki/MeerKAT</a>\r [3] <a href=\"http://github.com/sratcliffe/PySPEAD\">http://github.com/sratcliffe/PySPEAD</a>\r [4] <a href=\"http://pypi.python.org/pypi/katcp/0.3.0\">http://pypi.python.org/pypi/katcp/0.3.0</a>\r [5] <a href=\"http://code.google.com/p/mplh5canvas/\">http://code.google.com/p/mplh5canvas/</a>\r [6] <a href=\"http://pypi.python.org/pypi/corr/0.5.1\">http://pypi.python.org/pypi/corr/0.5.1</a>\r</p>\n", 
            "speaker": 39, 
            "submitted": "2010-11-01 04:10:36", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 160, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "PyPy is a virtual machine for Python, featuring an advanced just in time compiler, which can deliver exceptional performance.  This talk is going to be a deep dive into what exactly makes Python such a hard language to optimize, how PyPy is organized, and what optimizations our JIT can do (and what it can't do) for your code.\r\n", 
            "additional_speakers": [
                5
            ], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The talk will detail how a python interpreter works internally and why some operations are costly. We'll go through several python features, how they work, why they're slow in CPython and how we're fixing it.\r\n\r\nThe list of mentioned features is not exhaustive, however we will try to focus at least on the following:\r\n\r\n* Dynamic language - In Python code we have no known types, like a statically typed language.  Even operations like \"a + b\" can do anything, unless we know more about the code, and the types it is operating on.\r\n\r\n* Frame introspection - Frame objects need to be allocated for every function call, and all local variables are stored on the frame, and must be accessible from further down the call stack.\r\n\r\nPyPy uses a novel approach called \"virtualizables\" which makes it possible to avoid frame allocation in most common cases.\r\n\r\n* Object model - All user defined Python objects have a dictionary which stores their attributes, as does every type.  When Python does an attribute lookup this requires at least two dictionary lookups.\r\n\r\nIn PyPy we use an approach similar to the one used by V8 with hidden classes (except more PyPy specific) called map dictionaries and other optimizations.\r\n\r\n* FFI calls - Calling C from Python is costly and hard to optimize. In PyPy we expose C APIs to Python code via ctypes. This part explains how we can optimize ctypes calls.\r\n\r\n* `array` module - Users of CPython's array module probably know it can save them quite a bit of memory, however it's also slower than using a list, due to the overhead of boxing and unboxing on every operations. Here we will tie everything together and describe how the ``array`` module is much faster with PyPy's JIT, combining our optimizations to: unbox values, remove the dynamicism within traces, and deliver great performance.\r\n", 
            "title": "Why is Python slow and how PyPy can help?", 
            "plenary": false, 
            "abstract_html": "<p>The talk will detail how a python interpreter works internally and why some operations are costly. We'll go through several python features, how they work, why they're slow in CPython and how we're fixing it.\r</p>\n<p>The list of mentioned features is not exhaustive, however we will try to focus at least on the following:\r</p>\n<ul>\n<li>Dynamic language - In Python code we have no known types, like a statically typed language.  Even operations like \"a + b\" can do anything, unless we know more about the code, and the types it is operating on.\r</li>\n</ul>\n<ul>\n<li>Frame introspection - Frame objects need to be allocated for every function call, and all local variables are stored on the frame, and must be accessible from further down the call stack.\r</li>\n</ul>\n<p>PyPy uses a novel approach called \"virtualizables\" which makes it possible to avoid frame allocation in most common cases.\r</p>\n<ul>\n<li>Object model - All user defined Python objects have a dictionary which stores their attributes, as does every type.  When Python does an attribute lookup this requires at least two dictionary lookups.\r</li>\n</ul>\n<p>In PyPy we use an approach similar to the one used by V8 with hidden classes (except more PyPy specific) called map dictionaries and other optimizations.\r</p>\n<ul>\n<li>FFI calls - Calling C from Python is costly and hard to optimize. In PyPy we expose C APIs to Python code via ctypes. This part explains how we can optimize ctypes calls.\r</li>\n</ul>\n<ul>\n<li>`array` module - Users of CPython's array module probably know it can save them quite a bit of memory, however it's also slower than using a list, due to the overhead of boxing and unboxing on every operations. Here we will tie everything together and describe how the ``array`` module is much faster with PyPy's JIT, combining our optimizations to: unbox values, remove the dynamicism within traces, and deliver great performance.\r</li>\n</ul>\n", 
            "speaker": 39, 
            "submitted": "2010-11-01 05:10:20", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 165, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk described using zc.buildout for application deployment to\r\nproduction environments.  It presents building self-contained source\r\nreleases, and using these to create RPM distributions.  It shows how\r\nto use buildout to configure services, including web servers, cron\r\njobs, monitoring and so on. Finally, it presents ongoing efforts to\r\ndeploy applications that span many machines.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "We build and deploy large Python applications for our customers.\r\nThese applications are built from many component parts including\r\nPython packages and non-python applications and tools.  Assembling\r\nthese pieces can be a tedious and error-prone process.  The\r\nzc.buildout (Buildout) package was developed to automate this process.\r\n\r\nAs our use of buildout has matured, we've integrated it with system\r\npackaging tools and developed techniques for managing software deployemnt\r\nand service configuration. I'll provide a detailed description of\r\nthe techniques and tools used.\r\n\r\nOutline:\r\n\r\n* Buildout\r\n** Motivation\r\n** History\r\n** Configuration files\r\n** Recipes\r\n\r\n* Deployment pholisophy:\r\n  keeping software and service configuration separate\r\n\r\n* System Packaging\r\n** Making self-contained source releases (tar balls)\r\n** Creating system packages from source releases with RPM\r\n\r\n* Service configuration -- system build outs\r\n** Scope: Python processes, cron, log rotation, run scripts, monitoring, etc.\r\n** Place files in \"standard\" locations.\r\n** Run by root\r\n** examples\r\n\r\n* Meta recipes\r\n** Goal: provide only essential information.\r\n** Recipes provide basic level of abstraction.\r\n** Buildout provides basic tools to build on these abstractions, but these tools only scale so far.\r\n** Buildout configuration language is *not* a programming language.\r\n** Meta-recipes provide a much more powerful way to build high-level abstractions over basic recipes.\r\n\r\n* Next step: Make me a ...\r\n** Model based definition of complete systems spanning multiple hosts with interlocking services\r\n** Automatic management of resources\r\n** Implemented with ssh, system packaging tools (e.g. yum) and buildout-based tools.\r\n** Four levels of abstraction\r\n** Current status\r\n", 
            "title": "Deploying Applications with zc.buildout", 
            "plenary": false, 
            "abstract_html": "<p>We build and deploy large Python applications for our customers.\r These applications are built from many component parts including\r Python packages and non-python applications and tools.  Assembling\r these pieces can be a tedious and error-prone process.  The\r zc.buildout (Buildout) package was developed to automate this process.\r</p>\n<p>As our use of buildout has matured, we've integrated it with system\r packaging tools and developed techniques for managing software deployemnt\r and service configuration. I'll provide a detailed description of\r the techniques and tools used.\r</p>\n<p>Outline:\r</p>\n<ul>\n<li>Buildout\r<ul>\n<li>Motivation\r</li>\n<li>History\r</li>\n<li>Configuration files\r</li>\n<li>Recipes\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Deployment pholisophy:\r   keeping software and service configuration separate\r</li>\n</ul>\n<ul>\n<li>System Packaging\r<ul>\n<li>Making self-contained source releases (tar balls)\r</li>\n<li>Creating system packages from source releases with RPM\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Service configuration -- system build outs\r<ul>\n<li>Scope: Python processes, cron, log rotation, run scripts, monitoring, etc.\r</li>\n<li>Place files in \"standard\" locations.\r</li>\n<li>Run by root\r</li>\n<li>examples\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Meta recipes\r<ul>\n<li>Goal: provide only essential information.\r</li>\n<li>Recipes provide basic level of abstraction.\r</li>\n<li>Buildout provides basic tools to build on these abstractions, but these tools only scale so far.\r</li>\n<li>Buildout configuration language is *not* a programming language.\r</li>\n<li>Meta-recipes provide a much more powerful way to build high-level abstractions over basic recipes.\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Next step: Make me a ...\r<ul>\n<li>Model based definition of complete systems spanning multiple hosts with interlocking services\r</li>\n<li>Automatic management of resources\r</li>\n<li>Implemented with ssh, system packaging tools (e.g. yum) and buildout-based tools.\r</li>\n<li>Four levels of abstraction\r</li>\n<li>Current status\r</li>\n</ul>\n</li>\n</ul>\n", 
            "speaker": 176, 
            "submitted": "2010-11-01 06:53:16", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 169, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Finding the right piece of \"prior art\" - technical documentation that described a patented piece of technology before the patent was filed - is like finding a needle in a very big haystack. This session will talk about how I am making that process faster and more accurate through the use of natural language processing, graph theory, machine learning, and lots of Python.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "From my work consulting on a number of patent cases, I am frequently asked to find \"prior art\" - patents and publications that describe a technology before a certain date. The problem is that the indexing mechanisms for patents and publications are not as good as they could be, making good prior art searching more of an art than a science. When I decided to do better, I reached for Python. \r\n\r\n*Part I (5 mins): The USPTO as a data source.*\r\nThe full-text of each patent is available from the USPTO (and now from Google.) What does this data look like? How can it be harvested and normalized to create data structures that we can work with?\r\n\r\n*Part II (15 mins, in two parts):* \r\nOnce the patents have been cleaned and normalized, they can be turned into data structures that we can use to evaluate their relationship to other documents. This is done in two ways - by modeling each patent as a document vector and a graph node. \r\n\r\n*Part IIA (7 mins): Patents as document vectors.* \r\nOnce we have a patent as a data structure, we can treat the patent as a vector in an n-dimensional space. In moving from a document into a vector space, we will touch on normalization, stemming, TF/IDF, Latent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA). \r\n\r\n*Part IIB (7 mins): Patents as technology graphs.* \r\nThis will show building graph structures using the connections between patents - both the built-in connections in the patents themselves as well as the connections discovered while working with the patents as vectors. We apply some social network analysis to partition the patent graph and find other documents in the same technology space.\r\n\r\n*Part III (5 mins): What have we built?*\r\nNow that we have done all this analysis, we can see some interesting things about the patent database as a whole. How does the patent database act as a map to the world of technology? And how has this helped with the original problem - finding better prior art?", 
            "title": "How to kill a patent with Python", 
            "plenary": false, 
            "abstract_html": "<p>From my work consulting on a number of patent cases, I am frequently asked to find \"prior art\" - patents and publications that describe a technology before a certain date. The problem is that the indexing mechanisms for patents and publications are not as good as they could be, making good prior art searching more of an art than a science. When I decided to do better, I reached for Python. \r</p>\n<ul>\n<li>Part I (5 mins): The USPTO as a data source.*\r The full-text of each patent is available from the USPTO (and now from Google.) What does this data look like? How can it be harvested and normalized to create data structures that we can work with?\r</li>\n</ul>\n<ul>\n<li>Part II (15 mins, in two parts):* \r Once the patents have been cleaned and normalized, they can be turned into data structures that we can use to evaluate their relationship to other documents. This is done in two ways - by modeling each patent as a document vector and a graph node. \r</li>\n</ul>\n<ul>\n<li>Part IIA (7 mins): Patents as document vectors.* \r Once we have a patent as a data structure, we can treat the patent as a vector in an n-dimensional space. In moving from a document into a vector space, we will touch on normalization, stemming, TF/IDF, Latent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA). \r</li>\n</ul>\n<ul>\n<li>Part IIB (7 mins): Patents as technology graphs.* \r This will show building graph structures using the connections between patents - both the built-in connections in the patents themselves as well as the connections discovered while working with the patents as vectors. We apply some social network analysis to partition the patent graph and find other documents in the same technology space.\r</li>\n</ul>\n<ul>\n<li>Part III (5 mins): What have we built?*\r Now that we have done all this analysis, we can see some interesting things about the patent database as a whole. How does the patent database act as a map to the world of technology? And how has this helped with the original problem - finding better prior art?</li>\n</ul>\n", 
            "speaker": 251, 
            "submitted": "2010-11-01 11:27:29", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 170, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "We'll fly through the most clever bits of BitBacker, an online backup app developed as a startup for three years and eventually abandoned. Highlights: a hacked-up httplib/asyncore HTTP client; a real-life, HATEOAS-respecting RESTful API, and an encryption scheme that can quickly diff a file system against the server while leaking no information \u2013\u00a0not even file timestamps.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This is the story of a solution to a huge problem: fast, secure online backup. A single client generates a hundred gigabytes, millions of data chunks, and thousands of file system snapshots. To appreciate the problem's scale, consider that a Python array holding content hashes for 1,000,000 files consumes 100 MB of memory. File hashes are only a portion of the required per-file metadata, and that's only one for snapshot of thousands.\r\n\r\nWe'll tour the hard parts of this system with no apology for their difficulty. The httplib/asyncore hybrid monster that served millions of parallel requests, transparently retrying on failures and timeouts, with only 300 lines of python. The RESTful API \u2013\u00a0fully respecting hypertext, with every request safely repeatable, even POSTs, and not a single hard-coded URL in the client. The encryption scheme that leaked nothing \u2013\u00a0not even modification times \u2013 but could quickly diff local file systems against the server. And, that one time that a client accidentally requested a 4.76 megabyte URL in production.", 
            "title": "Backup Is Hard; Let's Go Shopping", 
            "plenary": false, 
            "abstract_html": "<p>This is the story of a solution to a huge problem: fast, secure online backup. A single client generates a hundred gigabytes, millions of data chunks, and thousands of file system snapshots. To appreciate the problem's scale, consider that a Python array holding content hashes for 1,000,000 files consumes 100 MB of memory. File hashes are only a portion of the required per-file metadata, and that's only one for snapshot of thousands.\r</p>\n<p>We'll tour the hard parts of this system with no apology for their difficulty. The httplib/asyncore hybrid monster that served millions of parallel requests, transparently retrying on failures and timeouts, with only 300 lines of python. The RESTful API \u2013\u00a0fully respecting hypertext, with every request safely repeatable, even POSTs, and not a single hard-coded URL in the client. The encryption scheme that leaked nothing \u2013\u00a0not even modification times \u2013 but could quickly diff local file systems against the server. And, that one time that a client accidentally requested a 4.76 megabyte URL in production.</p>\n", 
            "speaker": 179, 
            "submitted": "2010-11-01 11:28:31", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 161, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "Although Python programs may be slow for certain types of tasks, there are\r\nmany different ways to improve performance. This tutorial will introduce\r\noptimization strategies and demonstrate techniques to implement them. \r\nAfter the coourse participants will be able to decide what might be the\r\noptimal solution for a certain performance problem.\r\nPlease bring your laptops to work along.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "= Intended Audience =\r\n\r\nPython programmers with intermediate knowledge.\r\n\r\n= Tutorial Format =\r\n\r\n**Class**\r\n\r\nThis is a hands-on tutorial. Each topic is introduced through a short lecture. There are numerous exercises for nearly all points of the outline. All source codes are provided on CD before the course. Questions are encouraged throughout the course. There is a comprehensive handout detailing all presented topics including in-depth discussions of all code examples.\r\n\r\n= Class Size =\r\n\r\nThis tutorials has been successfully given to 70+ people at PyCon 2010. While this might not be the ideal size for a class, it still worked reasonably well.\r\n\r\n\r\n= Requirements =\r\n\r\nAll participants should bring laptops with Linux, Windows, or Mac OS. Python 2.6 or 2.5 as well as an editor or IDE will need to be installed. It seems unlikey that Python 2.7 will work at the time of the tutorial. So far none of the packages listed below is availbale as a release for this version.\r\n\r\nThe following third-party packages are needed:\r\n\r\n* [[http://psyco.sourceforge.net|psyco]] (version 1.5.2 or higher)\r\n* [[http://numpy.scipy.org|NumPy]] (version 1.2 or higher)\r\n* [[http://pyprocessing.berlios.de|pyprocessing]] (2.5 or lower only)\r\n* [[http://guppy-pe.sourceforge.net|Guppy_PE framework]]\r\n\r\n\r\n== Testscript ==\r\n\r\nA test script will be provided by the instructor. If it runs through without complaining all necessary packages are installed. Otherwise it will prompt to install the missing package(s).\r\n\r\n= Notes for Reviewers =\r\n\r\nThis tutorial builds on a tutorial I gave from 2007 to 2010 at PyCon. Every year I rework it thoroughly and incorporated suggestions from the tutorial participants. I've alos given this tutorial at PyCon Asia-Pacific 2010 in Singapore as well at OSCON 2010 in Portland.\r\n\r\nThe tutorial was always very well filled, often the biggest none-Django one. Somtimes pretty close to Django.\r\n\r\nThere still seems to be demand for it.\r\n\r\n\r\n= Outline for Review =\r\n\r\n* How Fast is Fast Enough? (5 min)\r\n** Short intro\r\n** Development speed vs. execution speed\r\n** Resources\r\n* Optimization Guidelines (15 min)\r\n** Premature optimization\r\n** Optimization rules\r\n** Seven steps for incremental optimization\r\n* Optimization strategy (20 min)\r\n** Measuring in stones\r\n** Profiling CPU usage\r\n** Profiling memory usage\r\n* Algorithms and Anti-patterns (35 min)\r\n** String Concatenation\r\n*** Constructing a large string from substrings with `+=` and a list\r\n*** Exercise\r\n** List and Generator Comprehensions\r\n*** Intro to list and generator comprehensions with examples\r\n*** Exercise\r\n** The Right Data Structure\r\n*** {{{list}}} vs. {{{set}}}\r\n*** {{{list}}} vs. {{{deque}}}\r\n*** {{{dict}}} vs. {{{defaultdict}}}\r\n*** Big-O notation and data structures\r\n*** Exercise\r\n** Caching\r\n*** Deterministic caching\r\n*** Non-deterministic caching\r\n*** Memcachaed\r\n* The Example (10 min)\r\n** Calculation of pi with the Monte Carlo method\r\n* Testing Speed (10 min)\r\n** Small speed testing program for the course based on `timeit`\r\n** Explanation of source code\r\n* Pure Python (15 min)\r\n** Two implementations for the example with just the standard library\r\n** Exercise\r\n* Meet Psyco, the JIT (15 min)\r\n** Intro of Psyco using `full`, `log`, `profile`, and `bind` with examples\r\n** Exercise\r\n* Numpy for Numeric Arrays (20 min)\r\n** Short intro to Numpy\r\n** Using Numpy for our example\r\n** Exercise\r\n* Using multiple CPUs with pyprocessing/multiprocessing (20 min)\r\n** Short intro to pyprocessing/multiprocessing\r\n** Using pyprocessing/multiprocessing for our example\r\n** Exercise\r\n* Combination of optimization strategies (15 min)\r\n** Psyco and Numpy\r\n** Psyco and pyprocessing/multiprocessing\r\n** Psyco and numpy and pyprocessing/multiprocessing\r\n* Results of Different Example Implementations (10 min)\r\n** Compilation of all speed measuring results\r\n** Discussion of the ranking\r\n** Exercise\r\n\r\n\r\n= Outline for Website =\r\n\r\n* How Fast is Fast Enough?\r\n* Optimization Guidelines\r\n** Premature optimization\r\n** Optimization rules\r\n** Seven steps for incremental optimization\r\n* Optimization strategy\r\n** Measuring in stones\r\n** Profiling CPU usage\r\n** Profiling memory usage\r\n* Algorithms and Anti-patterns\r\n** String Concatenation\r\n** List and Generator Comprehensions\r\n** The Right Data Structure\r\n** Caching\r\n* The Example\r\n* Testing Speed\r\n* Pure Python\r\n* Meet Psyco, the JIT\r\n* Numpy for Numeric Arrays\r\n* Using multiple CPUs with pyprocessing/multiprocessing\r\n* Combination of optimization strategies\r\n* Results of Different Example Implementations", 
            "title": "Faster Python Programs through Optimization", 
            "plenary": false, 
            "abstract_html": "<h1>Intended Audience</h1>\n<p>Python programmers with intermediate knowledge.\r</p>\n<h1>Tutorial Format</h1>\n<p><b>Class</b>\r</p>\n<p>This is a hands-on tutorial. Each topic is introduced through a short lecture. There are numerous exercises for nearly all points of the outline. All source codes are provided on CD before the course. Questions are encouraged throughout the course. There is a comprehensive handout detailing all presented topics including in-depth discussions of all code examples.\r</p>\n<h1>Class Size</h1>\n<p>This tutorials has been successfully given to 70+ people at PyCon 2010. While this might not be the ideal size for a class, it still worked reasonably well.\r</p>\n<h1>Requirements</h1>\n<p>All participants should bring laptops with Linux, Windows, or Mac OS. Python 2.6 or 2.5 as well as an editor or IDE will need to be installed. It seems unlikey that Python 2.7 will work at the time of the tutorial. So far none of the packages listed below is availbale as a release for this version.\r</p>\n<p>The following third-party packages are needed:\r</p>\n<ul>\n<li><a href=\"http://psyco.sourceforge.net\">psyco</a> (version 1.5.2 or higher)\r</li>\n<li><a href=\"http://numpy.scipy.org\">NumPy</a> (version 1.2 or higher)\r</li>\n<li><a href=\"http://pyprocessing.berlios.de\">pyprocessing</a> (2.5 or lower only)\r</li>\n<li><a href=\"http://guppy-pe.sourceforge.net\">Guppy_PE framework</a>\r</li>\n</ul>\n<h2>Testscript</h2>\n<p>A test script will be provided by the instructor. If it runs through without complaining all necessary packages are installed. Otherwise it will prompt to install the missing package(s).\r</p>\n<h1>Notes for Reviewers</h1>\n<p>This tutorial builds on a tutorial I gave from 2007 to 2010 at PyCon. Every year I rework it thoroughly and incorporated suggestions from the tutorial participants. I've alos given this tutorial at PyCon Asia-Pacific 2010 in Singapore as well at OSCON 2010 in Portland.\r</p>\n<p>The tutorial was always very well filled, often the biggest none-Django one. Somtimes pretty close to Django.\r</p>\n<p>There still seems to be demand for it.\r</p>\n<h1>Outline for Review</h1>\n<ul>\n<li>How Fast is Fast Enough? (5 min)\r<ul>\n<li>Short intro\r</li>\n<li>Development speed vs. execution speed\r</li>\n<li>Resources\r</li>\n</ul>\n</li>\n<li>Optimization Guidelines (15 min)\r<ul>\n<li>Premature optimization\r</li>\n<li>Optimization rules\r</li>\n<li>Seven steps for incremental optimization\r</li>\n</ul>\n</li>\n<li>Optimization strategy (20 min)\r<ul>\n<li>Measuring in stones\r</li>\n<li>Profiling CPU usage\r</li>\n<li>Profiling memory usage\r</li>\n</ul>\n</li>\n<li>Algorithms and Anti-patterns (35 min)\r<ul>\n<li>String Concatenation\r<ul>\n<li>Constructing a large string from substrings with `+=` and a list\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>List and Generator Comprehensions\r<ul>\n<li>Intro to list and generator comprehensions with examples\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>The Right Data Structure\r<ul>\n<li><tt>list</tt> vs. <tt>set</tt>\r</li>\n<li><tt>list</tt> vs. <tt>deque</tt>\r</li>\n<li><tt>dict</tt> vs. <tt>defaultdict</tt>\r</li>\n<li>Big-O notation and data structures\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>Caching\r<ul>\n<li>Deterministic caching\r</li>\n<li>Non-deterministic caching\r</li>\n<li>Memcachaed\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The Example (10 min)\r<ul>\n<li>Calculation of pi with the Monte Carlo method\r</li>\n</ul>\n</li>\n<li>Testing Speed (10 min)\r<ul>\n<li>Small speed testing program for the course based on `timeit`\r</li>\n<li>Explanation of source code\r</li>\n</ul>\n</li>\n<li>Pure Python (15 min)\r<ul>\n<li>Two implementations for the example with just the standard library\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>Meet Psyco, the JIT (15 min)\r<ul>\n<li>Intro of Psyco using `full`, `log`, `profile`, and `bind` with examples\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>Numpy for Numeric Arrays (20 min)\r<ul>\n<li>Short intro to Numpy\r</li>\n<li>Using Numpy for our example\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>Using multiple CPUs with pyprocessing/multiprocessing (20 min)\r<ul>\n<li>Short intro to pyprocessing/multiprocessing\r</li>\n<li>Using pyprocessing/multiprocessing for our example\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n<li>Combination of optimization strategies (15 min)\r<ul>\n<li>Psyco and Numpy\r</li>\n<li>Psyco and pyprocessing/multiprocessing\r</li>\n<li>Psyco and numpy and pyprocessing/multiprocessing\r</li>\n</ul>\n</li>\n<li>Results of Different Example Implementations (10 min)\r<ul>\n<li>Compilation of all speed measuring results\r</li>\n<li>Discussion of the ranking\r</li>\n<li>Exercise\r</li>\n</ul>\n</li>\n</ul>\n<h1>Outline for Website</h1>\n<ul>\n<li>How Fast is Fast Enough?\r</li>\n<li>Optimization Guidelines\r<ul>\n<li>Premature optimization\r</li>\n<li>Optimization rules\r</li>\n<li>Seven steps for incremental optimization\r</li>\n</ul>\n</li>\n<li>Optimization strategy\r<ul>\n<li>Measuring in stones\r</li>\n<li>Profiling CPU usage\r</li>\n<li>Profiling memory usage\r</li>\n</ul>\n</li>\n<li>Algorithms and Anti-patterns\r<ul>\n<li>String Concatenation\r</li>\n<li>List and Generator Comprehensions\r</li>\n<li>The Right Data Structure\r</li>\n<li>Caching\r</li>\n</ul>\n</li>\n<li>The Example\r</li>\n<li>Testing Speed\r</li>\n<li>Pure Python\r</li>\n<li>Meet Psyco, the JIT\r</li>\n<li>Numpy for Numeric Arrays\r</li>\n<li>Using multiple CPUs with pyprocessing/multiprocessing\r</li>\n<li>Combination of optimization strategies\r</li>\n<li>Results of Different Example Implementations</li>\n</ul>\n", 
            "speaker": 135, 
            "submitted": "2010-11-01 05:44:35", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 172, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python's long history of testing has focused primarily on integration- and system-level tests: slow-running tests executing lots of code. These are a great start, but many of them can be transformed into unit-level tests. True unit tests are orders of magnitude faster (about 1ms each), providing quicker feedback and better failure localization. We'll look at why and how to write them.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Python has a wonderful legacy in testing: PyUnit has been in the standard library since March, 2001, and it was already a year old by then. We adopted browser driving quickly, and we do it at huge scale with great test parallelization infrastructure.\r\n\r\nBig tests aren't everything, though. In the Python world, true unit tests are somewhat rare, and even most tests written with the unittest library are integration tests. These tests are slow to execute and don't localize failure as well as smaller, focused tests. They leave us with two options: either run them rarely, sacrificing feedback, or run them often, sacrificing speed.\r\n\r\nWriting true unit tests removes that particular trade-off. When your tests execute in a millisecond each, you can afford to run a thousand of them every time you save a source file. This talk will discuss what unit tests really are, why they matter, and how to write them in Python.", 
            "title": "Units Need Testing Too", 
            "plenary": false, 
            "abstract_html": "<p>Python has a wonderful legacy in testing: PyUnit has been in the standard library since March, 2001, and it was already a year old by then. We adopted browser driving quickly, and we do it at huge scale with great test parallelization infrastructure.\r</p>\n<p>Big tests aren't everything, though. In the Python world, true unit tests are somewhat rare, and even most tests written with the unittest library are integration tests. These tests are slow to execute and don't localize failure as well as smaller, focused tests. They leave us with two options: either run them rarely, sacrificing feedback, or run them often, sacrificing speed.\r</p>\n<p>Writing true unit tests removes that particular trade-off. When your tests execute in a millisecond each, you can afford to run a thousand of them every time you save a source file. This talk will discuss what unit tests really are, why they matter, and how to write them in Python.</p>\n", 
            "speaker": 179, 
            "submitted": "2010-11-01 12:02:39", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 175, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Are you starting a moderate to large sized Django project? Do you need to plan ahead and build an application that will react to unanticipated needs? This talk covers some techniques and pitfalls I encountered in writing my first reasonably large Django site, and what I did differently the second time I started a project.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "When working on a company product, especially one where developers don't always have full control over the scope and needs of the application, it's important to plan ahead for unanticipated needs.\r\n\r\nThis talk will cover simple tricks and methods that are a small amount of work up front, but can save you lots of time later.\r\n\r\n===\r\n\r\nPyCon Talk Outline\r\n\r\n# Introduction (5m)\r\n** Me!\r\n# Making Mistakes\r\n** It happens. \"Code quality can be measured by the number of WTFs per minute in the code review.\"\r\n** When dealing with a big, expansive framework like Django, sometimes you just don't know that something is there. Good docs don't completely solve this...there's always going to be the thing you don't find. Similarly, sometimes you don't realize how to leverage something that you do know about until much later.\\\\\r\n\\\\\r\nMy regrets with my current project aren't sweeping architectural issues. I did most of the big stuff right. My regrets are mostly small things that, because it was my first big project, there was this piece or that piece that I didn't see or didn't fully appreciate, and so now I have little blocks of code that are tougher to maintain than they need to be. End of the world? No. Worth thinking through for next time? Yes.\r\n# Some trivial things (10m)\r\n** Preface: Yeah, some of these are dumb.\r\n** Beginning at the beginning: Project Setup\r\n*** I had sys.path pointing to the directory above the project root, like the tutorial does. I wish I hadn't done that.\r\n*** Need to run two instances on the same box that don't share the actual codebase (e.g. a staging server)? You still can, but it's more awkward. Better to set sys.path at your project root.\r\n** Dude, where's my Media class?\r\n*** How did I do it? First I had a magic template variable. Then I copied Form.Media\r\n*** Then, on a later project, I realized a block works just fine.\r\n** My boss wants ____ available on every page!\r\n*** How did I do it? I had a method we called everywhere that took arbitrary keyword arguments...\r\n*** Oh, there's TEMPLATE_CONTEXT_PROCESSORS...\r\n**** ...if you manually use RequestContext every time! So, just do that. Always. Even if you don't need it.\r\n**** I want .select_related('something') every time!\r\n**** ...so I typed it! A lot.\r\n**** Oh, that can be done by overriding def queryset on the manager class? That's easier to maintain...\r\n***** ...but make sure you set the flag to use it on related fields!\r\n** We need sample data for so-and-so, such-and-such...\r\n*** Disclaimer: This one actually isn't mine; my boss did it. But, it's amusing, and worth mentioning.\r\n*** We needed sample data so my boss could preview themes...so he set up a second database, put in fake data, and hard-coded it in the app-wide (not server-specific) settings.py.\r\n**** Copied the entire DB structure...at the time. But it changes.\r\n**** Oh, and the unit testing framework didn't appreciate it, either.\r\n*** Fixtures are the right way (and sooner or later I'll get this fixed...it's still there).\r\n* (space reserved for my stumbling upon something else silly, and hopefully humorous, that I did wrong)\r\n# How to avoid missing trivial things?\r\n** Read the documentation. Over and over.\r\n** Become familiar with the Django code.\r\n# A non-trivial thing: Forms (10m)\r\n** Django forms can do anything...given sufficient shenanigans. Always do it the Django forms way; your life will be easier.\r\n** Forms and ModelForms are static, and I needed dynamic choices on a form...\r\n*** ...so I just ditched newforms\r\n*** But wait, this is Python. A trivial function that calls the metaclass can solve this problem!\r\n**** This looks complicated, but it's not. Walk through how to do it.\r\n**** It's quite maintainable, and you get all the other bells and whistles.\r\n# Questions? (5m)", 
            "title": "Django: Pitfalls I Encountered and How to Avoid Them", 
            "plenary": false, 
            "abstract_html": "<p>When working on a company product, especially one where developers don't always have full control over the scope and needs of the application, it's important to plan ahead for unanticipated needs.\r</p>\n<p>This talk will cover simple tricks and methods that are a small amount of work up front, but can save you lots of time later.\r</p>\n<h3>PyCon Talk Outline</h3>\n<ol>\n<li>Introduction (5m)\r<ul>\n<li>Me!\r</li>\n</ul>\n</li>\n<li>Making Mistakes\r<ul>\n<li>It happens. \"Code quality can be measured by the number of WTFs per minute in the code review.\"\r</li>\n<li>When dealing with a big, expansive framework like Django, sometimes you just don't know that something is there. Good docs don't completely solve this...there's always going to be the thing you don't find. Similarly, sometimes you don't realize how to leverage something that you do know about until much later.<br>\r <br>\r My regrets with my current project aren't sweeping architectural issues. I did most of the big stuff right. My regrets are mostly small things that, because it was my first big project, there was this piece or that piece that I didn't see or didn't fully appreciate, and so now I have little blocks of code that are tougher to maintain than they need to be. End of the world? No. Worth thinking through for next time? Yes.\r</li>\n</ul>\n</li>\n<li>Some trivial things (10m)\r<ul>\n<li>Preface: Yeah, some of these are dumb.\r</li>\n<li>Beginning at the beginning: Project Setup\r<ul>\n<li>I had sys.path pointing to the directory above the project root, like the tutorial does. I wish I hadn't done that.\r</li>\n<li>Need to run two instances on the same box that don't share the actual codebase (e.g. a staging server)? You still can, but it's more awkward. Better to set sys.path at your project root.\r</li>\n</ul>\n</li>\n<li>Dude, where's my Media class?\r<ul>\n<li>How did I do it? First I had a magic template variable. Then I copied Form.Media\r</li>\n<li>Then, on a later project, I realized a block works just fine.\r</li>\n</ul>\n</li>\n<li>My boss wants ____ available on every page!\r<ul>\n<li>How did I do it? I had a method we called everywhere that took arbitrary keyword arguments...\r</li>\n<li>Oh, there's TEMPLATE_CONTEXT_PROCESSORS...\r<ul>\n<li>...if you manually use RequestContext every time! So, just do that. Always. Even if you don't need it.\r</li>\n<li>I want .select_related('something') every time!\r</li>\n<li>...so I typed it! A lot.\r</li>\n<li>Oh, that can be done by overriding def queryset on the manager class? That's easier to maintain...\r<ul>\n<li>...but make sure you set the flag to use it on related fields!\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>We need sample data for so-and-so, such-and-such...\r<ul>\n<li>Disclaimer: This one actually isn't mine; my boss did it. But, it's amusing, and worth mentioning.\r</li>\n<li>We needed sample data so my boss could preview themes...so he set up a second database, put in fake data, and hard-coded it in the app-wide (not server-specific) settings.py.\r<ul>\n<li>Copied the entire DB structure...at the time. But it changes.\r</li>\n<li>Oh, and the unit testing framework didn't appreciate it, either.\r</li>\n</ul>\n</li>\n<li>Fixtures are the right way (and sooner or later I'll get this fixed...it's still there).\r<ul>\n<li>(space reserved for my stumbling upon something else silly, and hopefully humorous, that I did wrong)\r<ol>\n<li>How to avoid missing trivial things?\r</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Read the documentation. Over and over.\r</li>\n<li>Become familiar with the Django code.\r</li>\n</ul>\n</li>\n<li>A non-trivial thing: Forms (10m)\r<ul>\n<li>Django forms can do anything...given sufficient shenanigans. Always do it the Django forms way; your life will be easier.\r</li>\n<li>Forms and ModelForms are static, and I needed dynamic choices on a form...\r<ul>\n<li>...so I just ditched newforms\r</li>\n<li>But wait, this is Python. A trivial function that calls the metaclass can solve this problem!\r<ul>\n<li>This looks complicated, but it's not. Walk through how to do it.\r</li>\n<li>It's quite maintainable, and you get all the other bells and whistles.\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Questions? (5m)</li>\n</ol>\n", 
            "speaker": 183, 
            "submitted": "2010-11-01 13:00:32", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 178, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Any Python programmer knows about the major builtin data strcutres, lists, dicts, tuples, but do you always remember when you're supposed to use them? Do you know about all the cool data structures hidden in the standard library? This talk will be a review of the characteristics of the different data structures, and a tour of idiomatic ways to use some of the structures in the standard library.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "First, as a note this talk borders between survey and discuss in depth.  For each data structure I want to cover their implementation, performance characteristics, and idiomatic usage (e.g. tuples vs. lists), a lot of them have similar implementations so idiomatic usage will dominate for some of them.\r\n\r\n* The builtins (10 minutes)\r\n** lists\r\n*** Ordered collections of any type of objects\r\n*** Mutable\r\n*** Implemented as an array of pointers\r\n** tuples\r\n*** Ordered collections of any type of objects\r\n*** Immutable*\r\n*** Implemented as a fixed-length array of pointers\r\n** dicts\r\n*** Unordered mapping of hashable objects to any objects\r\n*** Mutable\r\n**** Why no immutable variant\r\n*** Implemented as an open-addressed hash table.\r\n** sets\r\n*** Unordered collection of hashable objects\r\n*** Mutable\r\n**** frozenset\r\n*** Implemented as an open-addressed hash table.\r\n* The Standard Library (10 minutes)\r\n** OrderedDict\r\n*** Ordered mapping of hashable objects to any objects\r\n*** Mutable\r\n*** Implemented as a dict with a doubly-linked list running through it.\r\n** deque\r\n*** Ordered collection of any type of objects\r\n*** Mutable\r\n*** Implemented as an unrolled, doubly-linked list\r\n** namedtuple\r\n*** Ordered collection of any type of objects, *also* addressable by name.\r\n*** Immutable\r\n*** Implemented as a tuple with extra properties\r\n** array\r\n*** Like a list... but limited to \"primitve\" types.\r\n* Performance characteristics.\r\n* Writing your own (5 minutes)\r\n** Abstract Base Classes\r\n*** Duck typing\r\n**** Why would you want to use them!\r\n*** What's available.\r\n** OrderedSet\r\n*** An ordered collection of hashable objects\r\n*** Mutable\r\n*** Implemented as a set with a doubly-linked list running through it.\r\n* Questions (5 minutes)\r\n\r\n", 
            "title": "The Data Structures of Python", 
            "plenary": false, 
            "abstract_html": "<p>First, as a note this talk borders between survey and discuss in depth.  For each data structure I want to cover their implementation, performance characteristics, and idiomatic usage (e.g. tuples vs. lists), a lot of them have similar implementations so idiomatic usage will dominate for some of them.\r</p>\n<ul>\n<li>The builtins (10 minutes)\r<ul>\n<li>lists\r<ul>\n<li>Ordered collections of any type of objects\r</li>\n<li>Mutable\r</li>\n<li>Implemented as an array of pointers\r</li>\n</ul>\n</li>\n<li>tuples\r<ul>\n<li>Ordered collections of any type of objects\r</li>\n<li>Immutable*\r</li>\n<li>Implemented as a fixed-length array of pointers\r</li>\n</ul>\n</li>\n<li>dicts\r<ul>\n<li>Unordered mapping of hashable objects to any objects\r</li>\n<li>Mutable\r<ul>\n<li>Why no immutable variant\r</li>\n</ul>\n</li>\n<li>Implemented as an open-addressed hash table.\r</li>\n</ul>\n</li>\n<li>sets\r<ul>\n<li>Unordered collection of hashable objects\r</li>\n<li>Mutable\r<ul>\n<li>frozenset\r</li>\n</ul>\n</li>\n<li>Implemented as an open-addressed hash table.\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The Standard Library (10 minutes)\r<ul>\n<li>OrderedDict\r<ul>\n<li>Ordered mapping of hashable objects to any objects\r</li>\n<li>Mutable\r</li>\n<li>Implemented as a dict with a doubly-linked list running through it.\r</li>\n</ul>\n</li>\n<li>deque\r<ul>\n<li>Ordered collection of any type of objects\r</li>\n<li>Mutable\r</li>\n<li>Implemented as an unrolled, doubly-linked list\r</li>\n</ul>\n</li>\n<li>namedtuple\r<ul>\n<li>Ordered collection of any type of objects, *also* addressable by name.\r</li>\n<li>Immutable\r</li>\n<li>Implemented as a tuple with extra properties\r</li>\n</ul>\n</li>\n<li>array\r<ul>\n<li>Like a list... but limited to \"primitve\" types.\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Performance characteristics.\r</li>\n<li>Writing your own (5 minutes)\r<ul>\n<li>Abstract Base Classes\r<ul>\n<li>Duck typing\r<ul>\n<li>Why would you want to use them!\r</li>\n</ul>\n</li>\n<li>What's available.\r</li>\n</ul>\n</li>\n<li>OrderedSet\r<ul>\n<li>An ordered collection of hashable objects\r</li>\n<li>Mutable\r</li>\n<li>Implemented as a set with a doubly-linked list running through it.\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Questions (5 minutes)\r</li>\n</ul>\n", 
            "speaker": 5, 
            "submitted": "2010-11-01 13:59:47", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 184, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The ast module in the Python (>= 2.6) standard library provides a representation of python code in a python data structure. We'll begin with a discussion about what an abstract syntax tree is and why it's useful. We can then talk about what's available in the ast module, how it works, and how you can use it. This will be a practical session built around examples examining and modifying live ASTs.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "I would prefer to make this a 45 minute talk with examination of code samples. I could\r\n\r\nPython 2.6 introduced a new module in the standard library, ast. The first line of the ast documentation is, \"The ast module helps Python applications to process trees of the Python abstract syntax grammar.\" What this means is not obvious and many, if not most, python programmers won't know what this means. I will begin by talking about the idea of syntax tree and how it fits into the python execution lifecycle. I will also talk about the contents of the ast module. I will cover the available ast.Node subclasses and the provided helper functions, including the NodeVisitor and NodeTransformer. I will finish by talking about how the ast module can be used to analyze Python code and how it can be used to generate new code.\r\n\r\nI expect the time to break down roughly like this:\r\n\r\nIntroduction ( 5m )\r\n* Capacitor joke\r\n* What is an abstract syntax tree?\r\n* How they are used by the Python interpreter\r\n\r\n\r\nThe contents of the ast module (20 m)\r\n * The node subclasses and the ast ( 10m )\r\n ** How you get an ast.\r\n *** code examples\r\n ** ast.stmt vs. ast.expr\r\n ** peculiarities\r\n *** code examples\r\n **** elif as syntactic sugar for \"if: else: if:\"\r\n **** comparison operators\r\n ** Why this is useful.\r\n *** the ast is the \"truth\" of the program\r\n **** code examples\r\n **** tricky code\r\n * The ast module helpers ( 10m )\r\n ** visitor pattern\r\n ** NodeVisitor\r\n ** NodeTransformer\r\n ** code examples\r\n\r\n\r\nWhat you do with an ast ( 15m )\r\n * Walking an ast\r\n ** code examples\r\n *** a simple visitor to gather variables by scope\r\n * Creating/Modifying an ast\r\n ** code examples\r\n *** rearrange imports transformer\r\n *** naive \"rename all instances\" transformer\r\n *** naive macro expansion transformer\r\n\r\n\r\nConclusion ( 5m )\r\n  * Practical Applications\r\n  ** existing projects\r\n  *** visitors\r\n  **** checkers (pylint, pyflakes)\r\n  *** transformers\r\n  **** refactoring tools (rope)\r\n  * When is it a good idea to use ast?\r\n", 
            "title": "What would you do with an ast?", 
            "plenary": false, 
            "abstract_html": "<p>I would prefer to make this a 45 minute talk with examination of code samples. I could\r</p>\n<p>Python 2.6 introduced a new module in the standard library, ast. The first line of the ast documentation is, \"The ast module helps Python applications to process trees of the Python abstract syntax grammar.\" What this means is not obvious and many, if not most, python programmers won't know what this means. I will begin by talking about the idea of syntax tree and how it fits into the python execution lifecycle. I will also talk about the contents of the ast module. I will cover the available ast.Node subclasses and the provided helper functions, including the NodeVisitor and NodeTransformer. I will finish by talking about how the ast module can be used to analyze Python code and how it can be used to generate new code.\r</p>\n<p>I expect the time to break down roughly like this:\r</p>\n<p>Introduction ( 5m )\r</p>\n<ul>\n<li>Capacitor joke\r</li>\n<li>What is an abstract syntax tree?\r</li>\n<li>How they are used by the Python interpreter\r</li>\n</ul>\n<p>The contents of the ast module (20 m)\r</p>\n<ul>\n<li>The node subclasses and the ast ( 10m )\r<ul>\n<li>How you get an ast.\r<ul>\n<li>code examples\r</li>\n</ul>\n</li>\n<li>ast.stmt vs. ast.expr\r</li>\n<li>peculiarities\r<ul>\n<li>code examples\r<ul>\n<li>elif as syntactic sugar for \"if: else: if:\"\r</li>\n<li>comparison operators\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Why this is useful.\r<ul>\n<li>the ast is the \"truth\" of the program\r<ul>\n<li>code examples\r</li>\n<li>tricky code\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The ast module helpers ( 10m )\r<ul>\n<li>visitor pattern\r</li>\n<li>NodeVisitor\r</li>\n<li>NodeTransformer\r</li>\n<li>code examples\r</li>\n</ul>\n</li>\n</ul>\n<p>What you do with an ast ( 15m )\r</p>\n<ul>\n<li>Walking an ast\r<ul>\n<li>code examples\r<ul>\n<li>a simple visitor to gather variables by scope\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Creating/Modifying an ast\r<ul>\n<li>code examples\r<ul>\n<li>rearrange imports transformer\r</li>\n<li>naive \"rename all instances\" transformer\r</li>\n<li>naive macro expansion transformer\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Conclusion ( 5m )\r</p>\n<ul>\n<li>Practical Applications\r<ul>\n<li>existing projects\r<ul>\n<li>visitors\r<ul>\n<li>checkers (pylint, pyflakes)\r</li>\n</ul>\n</li>\n<li>transformers\r<ul>\n<li>refactoring tools (rope)\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>When is it a good idea to use ast?\r</li>\n</ul>\n", 
            "speaker": 132, 
            "submitted": "2010-11-01 15:59:21", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 186, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The OpenStack project is an open source, standards-based, cloud computing platform that is, of course, written in Python. Creating such a distributed, scalable solution involved solving many problems that dealt with concurrency of both external requests and internal processing. In this talk we'll discuss several of these issues and the solutions we implemented for them. ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Creating both the Compute and Object Storage parts of the **[[http://openstack.org|OpenStack Cloud]]** involved solving many issues that dealt with concurrency, which can be problematic in Python due to the GIL. We considered several approaches to these problems, and eventually came up with solutions that worked best in each case. \r\n\r\nSome issues, such as handling thousands of simultaneous API connections, were originally handled with **Twisted**, but we changed that code to use **Eventlet** instead, as it simplified a good deal of the code while providing the same ability to avoid blocking I/O. Internally, a lot of the problems with concurrency were solved by coding in a message-based asynchronous style instead of using synchronous calls.\r\n\r\nThe talk will include several examples of the different types of problems that were encountered, and the solutions we came up with for each, and an explanation as to why one approach was chosen over another. It will be informative for developers new to asynchronous programming as well as those who have experience with these issues.", 
            "title": "Dealing with Concurrency in Large-Scale Systems", 
            "plenary": false, 
            "abstract_html": "<p>Creating both the Compute and Object Storage parts of the <b><a href=\"http://openstack.org\">OpenStack Cloud</a></b> involved solving many issues that dealt with concurrency, which can be problematic in Python due to the GIL. We considered several approaches to these problems, and eventually came up with solutions that worked best in each case. \r</p>\n<p>Some issues, such as handling thousands of simultaneous API connections, were originally handled with <b>Twisted</b>, but we changed that code to use <b>Eventlet</b> instead, as it simplified a good deal of the code while providing the same ability to avoid blocking I/O. Internally, a lot of the problems with concurrency were solved by coding in a message-based asynchronous style instead of using synchronous calls.\r</p>\n<p>The talk will include several examples of the different types of problems that were encountered, and the solutions we came up with for each, and an explanation as to why one approach was chosen over another. It will be informative for developers new to asynchronous programming as well as those who have experience with these issues.</p>\n", 
            "speaker": 124, 
            "submitted": "2010-11-01 16:25:57", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 173, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "So you've written a web site... now what? Writing the application is just the\r\nbeginning; now you've got to put it into production! Luckily, deploying Python web applications is pretty awesome these days, with a number of\r\nstrong choices. This hands-on workshop walks through the creation of a simple deployment environment for a Django or Python WSGI application.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "=== Course description\r\n\r\nSo you've written a web site... now what? Writing the application is just the\r\nbeginning; now you've got to put it into production! Luckily, the WSGI standard\r\nmeans that deploying Python web applications is pretty awesome, with a number of\r\nstrong choices.\r\n\r\nIn this hands-on workshop we'll walk through the creation of a simple Python\r\nWSGI deployment environment. We'll cover a couple of options for application\r\nservers (mod_wsgi and Gunicorn), some automation technologies (Fabric), and some\r\nsolutions to dealing with scaling up (nginx). By the end of the\r\nclass, each student will have created a simple production environment featuring\r\nload-balanced, redundant web servers. Though fairly simple, this production\r\nenvironment could easily serve most small-to-medium apps.\r\n\r\nThe example application used in this class with be a Django site, and the class\r\nassumes at least basic exposure to Django. However, the tools and techniques\r\nexplained apply to any WSGI-compliant Python web framework -- thats all of the\r\npopular ones and most of the others, too -- so developers using other\r\ntechnologies are welcome!\r\n\r\n=== Format\r\n\r\nThis is a hands-on workshop. If students want to follow along, they'll need:\r\n\r\n    * Access to at least one -- and preferably as many as four -- machines\r\n      running Ubuntu 10.04. I recommend four EC2 or Rackspace Cloud servers, but\r\n      a local VM or machine will also work. I'll send out information to\r\n      students about creating a VM a couple weeks before the class.\r\n      \r\n    * A copy of the class-provided Django app to deploy. This'll also be\r\n      sent out a couple weeks before the class.\r\n      Students may bring their own Django or Python apps to deploy, but I'll\r\n      only be able to provide very limited support for these apps.\r\n\r\n=== Outline\r\n\r\n* Getting started\r\n    ** Introducing our example application.\r\n    ** Overview of where we're going.\r\n\r\n* Application servers\r\n    ** What's an application server?\r\n    ** What's WSGI?\r\n    ** Overview of Python WSGI servers\r\n    \r\n* Introducing mod_wsgi\r\n    * Configuring Apache and mod_wsgi\r\n    * Exercise: deploy the application under mod_wsgi.\r\n    * Exercise: initial load test.\r\n\r\n* Introducing gunicorn\r\n    ** Configuring gunicorn\r\n    ** Hints for running gunicorn in production\r\n    ** Exercise: deploy the application under gunicorn\r\n    ** Exercise: compare load tests\r\n\r\n* Database server: PostgreSQL\r\n    ** Why a separate database server?\r\n    ** Configuring PostgreSQL\r\n    ** Exercise: split out the database server.\r\n\r\n* Introducing Fabric\r\n    ** What's Fabric?\r\n    ** Writing fabfiles.\r\n    ** Integrating fabfiles into Django applications.\r\n    ** Exercise: deploy using Fabric\r\n    \r\n* Load balancing and multiple web servers\r\n    ** Why multiple web servers?\r\n    ** \"Shared nothing\" and multiple servers\r\n    ** What's a load balancer?\r\n    ** Introducing nginx\r\n    ** Exercise: deploy nginx.\r\n\r\n* Final load test: how'd we do?\r\n\r\n\r\n", 
            "title": "Python/Django deployment workshop", 
            "plenary": false, 
            "abstract_html": "<h3>Course description</h3>\n<p>So you've written a web site... now what? Writing the application is just the\r beginning; now you've got to put it into production! Luckily, the WSGI standard\r means that deploying Python web applications is pretty awesome, with a number of\r strong choices.\r</p>\n<p>In this hands-on workshop we'll walk through the creation of a simple Python\r WSGI deployment environment. We'll cover a couple of options for application\r servers (mod_wsgi and Gunicorn), some automation technologies (Fabric), and some\r solutions to dealing with scaling up (nginx). By the end of the\r class, each student will have created a simple production environment featuring\r load-balanced, redundant web servers. Though fairly simple, this production\r environment could easily serve most small-to-medium apps.\r</p>\n<p>The example application used in this class with be a Django site, and the class\r assumes at least basic exposure to Django. However, the tools and techniques\r explained apply to any WSGI-compliant Python web framework -- thats all of the\r popular ones and most of the others, too -- so developers using other\r technologies are welcome!\r</p>\n<h3>Format</h3>\n<p>This is a hands-on workshop. If students want to follow along, they'll need:\r</p>\n<ul>\n<li>Access to at least one -- and preferably as many as four -- machines\r       running Ubuntu 10.04. I recommend four EC2 or Rackspace Cloud servers, but\r       a local VM or machine will also work. I'll send out information to\r       students about creating a VM a couple weeks before the class.\r</li>\n</ul>\n<ul>\n<li>A copy of the class-provided Django app to deploy. This'll also be\r       sent out a couple weeks before the class.\r       Students may bring their own Django or Python apps to deploy, but I'll\r       only be able to provide very limited support for these apps.\r</li>\n</ul>\n<h3>Outline</h3>\n<ul>\n<li>Getting started\r<ul>\n<li>Introducing our example application.\r</li>\n<li>Overview of where we're going.\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Application servers\r<ul>\n<li>What's an application server?\r</li>\n<li>What's WSGI?\r</li>\n<li>Overview of Python WSGI servers\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Introducing mod_wsgi\r</li>\n<li>Configuring Apache and mod_wsgi\r</li>\n<li>Exercise: deploy the application under mod_wsgi.\r</li>\n<li>Exercise: initial load test.\r</li>\n</ul>\n<ul>\n<li>Introducing gunicorn\r<ul>\n<li>Configuring gunicorn\r</li>\n<li>Hints for running gunicorn in production\r</li>\n<li>Exercise: deploy the application under gunicorn\r</li>\n<li>Exercise: compare load tests\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Database server: PostgreSQL\r<ul>\n<li>Why a separate database server?\r</li>\n<li>Configuring PostgreSQL\r</li>\n<li>Exercise: split out the database server.\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Introducing Fabric\r<ul>\n<li>What's Fabric?\r</li>\n<li>Writing fabfiles.\r</li>\n<li>Integrating fabfiles into Django applications.\r</li>\n<li>Exercise: deploy using Fabric\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Load balancing and multiple web servers\r<ul>\n<li>Why multiple web servers?\r</li>\n<li>\"Shared nothing\" and multiple servers\r</li>\n<li>What's a load balancer?\r</li>\n<li>Introducing nginx\r</li>\n<li>Exercise: deploy nginx.\r</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Final load test: how'd we do?\r</li>\n</ul>\n", 
            "speaker": 24, 
            "submitted": "2010-11-01 12:52:16", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 191, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The goal of this talk is to give a state-of-the-art overview of machine learning algorithms applied to text classification tasks ranging from language and topic detection in tweets and web pages to sentiment analysis in consumer products reviews.\r\n\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Unstructured or semi-structured text data is ubiquitous thanks to the read-write nature of the web. However human authors are often lazy and don't fill-in structured metadata forms in web applications. It is however possible to automate some structured knowledge extraction with simple and scalable statistical learning tools implemented in python. For instance:\r\n\r\n * guessing the language and topic of tweets and web pages\r\n * analyze the sentiment (positive or negative) in consumer products reviews in blogs or customer emails\r\n\r\nThis talk will introduce the main operational steps of supervised learning:\r\n\r\n * extracting the relevant features from text documents\r\n * selecting the right machine learning algorithm to train a model for the task at hand\r\n * using the trained model on previously unseen documents\r\n * evaluating the predictive accuracy of the trained model\r\n\r\nWe will also demonstrate the results obtained for above tasks using the [[http://scikit-learn.sourceforge.net|scikit-learn]] package and compare it to other implementations such as [[http://nltk.org|nltk]] and the [[http://code.google.com/apis/predict/|Google Prediction API]]", 
            "title": "Statistical machine learning for text classification with scikit-learn", 
            "plenary": false, 
            "abstract_html": "<p>Unstructured or semi-structured text data is ubiquitous thanks to the read-write nature of the web. However human authors are often lazy and don't fill-in structured metadata forms in web applications. It is however possible to automate some structured knowledge extraction with simple and scalable statistical learning tools implemented in python. For instance:\r</p>\n<ul>\n<li>guessing the language and topic of tweets and web pages\r</li>\n<li>analyze the sentiment (positive or negative) in consumer products reviews in blogs or customer emails\r</li>\n</ul>\n<p>This talk will introduce the main operational steps of supervised learning:\r</p>\n<ul>\n<li>extracting the relevant features from text documents\r</li>\n<li>selecting the right machine learning algorithm to train a model for the task at hand\r</li>\n<li>using the trained model on previously unseen documents\r</li>\n<li>evaluating the predictive accuracy of the trained model\r</li>\n</ul>\n<p>We will also demonstrate the results obtained for above tasks using the <a href=\"http://scikit-learn.sourceforge.net\">scikit-learn</a> package and compare it to other implementations such as <a href=\"http://nltk.org\">nltk</a> and the <a href=\"http://code.google.com/apis/predict/\">Google Prediction API</a></p>\n", 
            "speaker": 189, 
            "submitted": "2010-11-01 17:32:58", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 194, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Groups like the Fedora Design Team, Dreamwidth, SF Ruby, and OpenHatch have discovered the power of outreach to bring in new contributors. In the past year, SF Ruby grew in numbers as well as in diversity, moving from 3% women to 18% women.\r\n\r\nBecause most projects need ongoing help, this talk discusses effective strategies for bringing in contributors who stick around for the long haul.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk is targeted at anyone involved in an open source project who wants to find more contributors.\r\n\r\nPrograms like Google Summer of Code often provide excited students who disappear after a summer's work. Meanwhile, request for help emails on development lists are typically met with silence. Hackathons create a flurry of commits, but then we never hear from the participants again. Expanding your team //is// possible, and it requires care in terms of outreach, expectation management, and mentorship.\r\n\r\nWe will discuss three major forms of outreach:\r\n\r\n* One-on-one check-ins with participants,\r\n* Periodic drives to bring in new contributors, and\r\n* In-person teaching events.\r\n\r\nEach one has \"do\"s and \"don't\"s associated with it. This talk digests the experience of effective outreach into practical strategies that you can re-use within your project.", 
            "title": "Get new contributors (and diversity) through outreach", 
            "plenary": false, 
            "abstract_html": "<p>This talk is targeted at anyone involved in an open source project who wants to find more contributors.\r</p>\n<p>Programs like Google Summer of Code often provide excited students who disappear after a summer's work. Meanwhile, request for help emails on development lists are typically met with silence. Hackathons create a flurry of commits, but then we never hear from the participants again. Expanding your team <i>is</i> possible, and it requires care in terms of outreach, expectation management, and mentorship.\r</p>\n<p>We will discuss three major forms of outreach:\r</p>\n<ul>\n<li>One-on-one check-ins with participants,\r</li>\n<li>Periodic drives to bring in new contributors, and\r</li>\n<li>In-person teaching events.\r</li>\n</ul>\n<p>Each one has \"do\"s and \"don't\"s associated with it. This talk digests the experience of effective outreach into practical strategies that you can re-use within your project.</p>\n", 
            "speaker": 191, 
            "submitted": "2010-11-01 17:41:21", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 197, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "TRAPPIST is a BioPython-based package that performs detailed comparisons of related genomic regions and produces publication-quality vector PDF figures for clear visualization of analysis results. ", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "Recent developments in genome sequencing technology have led to an outpouring of raw sequence data, which represents both a great opportunity and a daunting challenge as biologists struggle to make sense of this enormous amount of information. There are standard tools available to process genomic data (for tools in Python, look up the BioPython Project at http://biopython.org/) but there is an unfulfilled need for applications and pipelines to address specific biological questions. \r\n\r\nMy work on the genomic evolution and functional modularity of large bacterial plasmids (extrachromosomal DNA molecules which usually confer genetic properties that are non-essential but enhance survival of the host cell, such as antibiotic resistance and virulence) has led me to develop a set of tools (TRAPPIST) that are tailored for the study of plasmids but can in fact be used for any type of genomic region.\r\n\r\nTRAPPIST is a Python package that performs detailed comparisons of related genomic regions and produces publication-quality vector PDF figures for clear visualization of analysis results. It is built as a series of functional modules that can be run separately or in pipelines. Several pre-set pipeline scripts are provided for automated start-to-finish processing of tasks that combine analysis and visualization, such as producing figures of multiple alignments with detailed similarity heat maps, identifying conserved genetic backbones or reconstructing the differential phylogeny of mosaic genome regions. Sequence handling, comparisons and alignments are done using BioPython and external calls to standard tools such as ClustalW, MUSCLE and/or BLAST using their respective BioPython wrappers. Figure generation is done using the ReportLab Toolkit. \r\n\r\nThis poster is aimed at bionformaticists who are interested in genomic analysis and visualization as well as Python developers who are interested in developing packages for scientific research. I'm looking for discussion, potential users and development collaboration opportunities.\r\n\r\nPoster content / discussion points\r\n- context: genomic research\r\n- overview of TRAPPIST features:\r\n\t- versatility of alignment functions\r\n\t- improved visualization of alignment data\r\n\t- identification of genetic backbones\r\n\t- handling differential phylogeny\r\n- assessment of current performance\r\n- future developments", 
            "title": "TRAPPIST : A toolkit for comparative analysis and visualization of genomic regions", 
            "plenary": false, 
            "abstract_html": "<p>Recent developments in genome sequencing technology have led to an outpouring of raw sequence data, which represents both a great opportunity and a daunting challenge as biologists struggle to make sense of this enormous amount of information. There are standard tools available to process genomic data (for tools in Python, look up the BioPython Project at <a href=\"http://biopython.org/\">http://biopython.org/</a>) but there is an unfulfilled need for applications and pipelines to address specific biological questions. \r</p>\n<p>My work on the genomic evolution and functional modularity of large bacterial plasmids (extrachromosomal DNA molecules which usually confer genetic properties that are non-essential but enhance survival of the host cell, such as antibiotic resistance and virulence) has led me to develop a set of tools (TRAPPIST) that are tailored for the study of plasmids but can in fact be used for any type of genomic region.\r</p>\n<p>TRAPPIST is a Python package that performs detailed comparisons of related genomic regions and produces publication-quality vector PDF figures for clear visualization of analysis results. It is built as a series of functional modules that can be run separately or in pipelines. Several pre-set pipeline scripts are provided for automated start-to-finish processing of tasks that combine analysis and visualization, such as producing figures of multiple alignments with detailed similarity heat maps, identifying conserved genetic backbones or reconstructing the differential phylogeny of mosaic genome regions. Sequence handling, comparisons and alignments are done using BioPython and external calls to standard tools such as ClustalW, MUSCLE and/or BLAST using their respective BioPython wrappers. Figure generation is done using the ReportLab Toolkit. \r</p>\n<p>This poster is aimed at bionformaticists who are interested in genomic analysis and visualization as well as Python developers who are interested in developing packages for scientific research. I'm looking for discussion, potential users and development collaboration opportunities.\r</p>\n<p>Poster content / discussion points\r - context: genomic research\r - overview of TRAPPIST features:\r \t- versatility of alignment functions\r \t- improved visualization of alignment data\r \t- identification of genetic backbones\r \t- handling differential phylogeny\r - assessment of current performance\r - future developments</p>\n", 
            "speaker": 195, 
            "submitted": "2010-11-01 18:06:14", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 198, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Pip and virtualenv: many use them; not so many understand just how they work their magic. If you're a pip/virtualenv user but haven't yet dared crack the lid (or you have, and found it a bit difficult to follow), come along for a fast-paced guided tour. Knowing these tools will help you make more effective use of them, and might also turn you into a contributor.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Pip and virtualenv are widely used in the Python world, but for the size of their user base don't receive many code contributions, and many users have misconceptions about how they actually work.\r\n\r\nThis talk will cover a bit of advanced use of pip and virtualenv, but mostly we'll dive into the source code, mapping it out with a high-level view and diving into the guts of particularly interesting bits. By the end of the talk, you'll have a good idea exactly how pip and virtualenv do their magic, and where to go looking in the source for particular behaviors or bug fixes. We'll walk through the creation of a virtualenv step-by-step, and trace a typical \"pip install -r requirements.txt\" and \"pip uninstall\" through the code paths they follow.\r\n\r\nI'll know the talk was a success when I see the pull requests!", 
            "title": "Reverse-engineering Ian Bicking's brain: inside pip and virtualenv", 
            "plenary": false, 
            "abstract_html": "<p>Pip and virtualenv are widely used in the Python world, but for the size of their user base don't receive many code contributions, and many users have misconceptions about how they actually work.\r</p>\n<p>This talk will cover a bit of advanced use of pip and virtualenv, but mostly we'll dive into the source code, mapping it out with a high-level view and diving into the guts of particularly interesting bits. By the end of the talk, you'll have a good idea exactly how pip and virtualenv do their magic, and where to go looking in the source for particular behaviors or bug fixes. We'll walk through the creation of a virtualenv step-by-step, and trace a typical \"pip install -r requirements.txt\" and \"pip uninstall\" through the code paths they follow.\r</p>\n<p>I'll know the talk was a success when I see the pull requests!</p>\n", 
            "speaker": 196, 
            "submitted": "2010-11-01 18:11:21", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 204, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Advances in genome sequencing has enabled large-scale projects such as the 1000 Genomes Project to sequence genomes across diverse populations around the world, resulting in very large data sets. I use Python for rapid development of algorithms for processing & analyzing genomes and discovering thousands of new variants, including \"Mobile Elements\" that copy&paste themselves across the genome.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Recent advances in high-throughput sequencing now enables accurate sequencing human genomes at a low cost & high speed.  This technology is now used to initiate projects involving large-scale sequencing of many genomes. The 1000 Genomes project aims to sequence 2500 genomes across 27 world populations, and has initially completed its Pilot phase.  The aim of the project is to discover & characterize novel variants. These variants enable association studies that investigate the link between genomic variation & phenotypes, including disease. \r\n\r\nA class of variants, known as \"Structural Variants\" represent a heterogenous class of larger variants, such as inversions, duplications, deletions, and various kinds of insertions. \r\n\r\nI use Python to for rapid development of algorithms to process, analyze, and annotate very large data sets. In particular,  I focus on Mobile Elements, pieces of DNA that copy&paste across the genome.  These elements constitute roughly half of the genome,  whereas protein-coding genes account for roughly 1.5 % of the genome. \r\n\r\nI will discuss distributed computing, genomics, and big data within the context of Python. ", 
            "title": "Rapid Python used on Big Data to Discover Human Genetic Variation", 
            "plenary": false, 
            "abstract_html": "<p>Recent advances in high-throughput sequencing now enables accurate sequencing human genomes at a low cost &amp; high speed.  This technology is now used to initiate projects involving large-scale sequencing of many genomes. The 1000 Genomes project aims to sequence 2500 genomes across 27 world populations, and has initially completed its Pilot phase.  The aim of the project is to discover &amp; characterize novel variants. These variants enable association studies that investigate the link between genomic variation &amp; phenotypes, including disease. \r</p>\n<p>A class of variants, known as \"Structural Variants\" represent a heterogenous class of larger variants, such as inversions, duplications, deletions, and various kinds of insertions. \r</p>\n<p>I use Python to for rapid development of algorithms to process, analyze, and annotate very large data sets. In particular,  I focus on Mobile Elements, pieces of DNA that copy&amp;paste across the genome.  These elements constitute roughly half of the genome,  whereas protein-coding genes account for roughly 1.5 % of the genome. \r</p>\n<p>I will discuss distributed computing, genomics, and big data within the context of Python. </p>\n", 
            "speaker": 205, 
            "submitted": "2010-11-01 19:51:58", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 205, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "From an attacker's point of view there are few entry points with as much to offer as a vulnerable software updater, yet history tells us that such vulnerabilities are common. In this talk we'll demonstrate a number of attacks, explain how common approaches fail to defend against them, and demonstrate a pure Python library (TUF) that provides both robust protection and extreme ease of use.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Vulnerabilities in software update systems expose users to huge range of potential security risks, including:\r\n\r\n* Freeze attacks,\r\n* Mix-and-match attacks,\r\n* Rollback attacks, and\r\n* Endless data attacks\r\n\r\nIn the first part of this talk, we'll demonstrate each of these against real-world software updaters and explain how commonly used countermeasures fail in application. We'll then move on to the second part of the talk, demonstrating TUF, its internals, and the mechanisms it uses to additionally defend against key compromise. Finally, we'll demonstrate how easy it is to integrate TUF into your application and its lifecycle.\r\n", 
            "title": "TUF: Secure Software Updates in Python", 
            "plenary": false, 
            "abstract_html": "<p>Vulnerabilities in software update systems expose users to huge range of potential security risks, including:\r</p>\n<ul>\n<li>Freeze attacks,\r</li>\n<li>Mix-and-match attacks,\r</li>\n<li>Rollback attacks, and\r</li>\n<li>Endless data attacks\r</li>\n</ul>\n<p>In the first part of this talk, we'll demonstrate each of these against real-world software updaters and explain how commonly used countermeasures fail in application. We'll then move on to the second part of the talk, demonstrating TUF, its internals, and the mechanisms it uses to additionally defend against key compromise. Finally, we'll demonstrate how easy it is to integrate TUF into your application and its lifecycle.\r</p>\n", 
            "speaker": 8, 
            "submitted": "2010-11-01 19:53:53", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 208, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The Twisted event-driven networking engine is well-known in the Python community.  However, only a few of its features are widely understood.  This talk will be a brief conceptual introduction to Twisted, followed by a survey of its features, their status, and how development has been proceeding over the years, with a special focus on the last two years of sponsored development.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk will begin with a brief introduction to Twisted architectural concepts; a description of the event loop, connections, and timers.  It will then segue into the many different features that Twisted offers, including command-line tools for running an out-of-the-box zero-configuration HTTP server, DNS server, IRC server, and SMTP server.  This will also present the relative maturity and stability of each of these areas of the code, with a special emphasis on what level of expertise a developer should have before attempting to use them.  Finally, I will describe some of the features that have been added to Twisted along the way, including some new and exciting developments that have been happening recently.", 
            "title": "Ten Years of Twisted", 
            "plenary": false, 
            "abstract_html": "<p>This talk will begin with a brief introduction to Twisted architectural concepts; a description of the event loop, connections, and timers.  It will then segue into the many different features that Twisted offers, including command-line tools for running an out-of-the-box zero-configuration HTTP server, DNS server, IRC server, and SMTP server.  This will also present the relative maturity and stability of each of these areas of the code, with a special emphasis on what level of expertise a developer should have before attempting to use them.  Finally, I will describe some of the features that have been added to Twisted along the way, including some new and exciting developments that have been happening recently.</p>\n", 
            "speaker": 208, 
            "submitted": "2010-11-01 20:46:16", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 207, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "This tutorial is intended for Python programmers with no GUI programming experience with PyQt. The course will assist the programmer with the installation of the necessary tools and libraries to begin Qt development with Python. By the end of the course students have an understanding of the Qt library and tools and be able to create simple but useful GUIs in Python.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "{{{\r\nBelow is an outline of the material to be presented during the class.  The\r\nexamples listed (unless otherwise noted) are developed while in class to show\r\nthe process and progression of GUI development.\r\n\r\n\r\n  - Installation Summary (10 min)\r\n\r\n    - Reference to detailed instructions provided before the class began\r\n\r\n    - Supported platforms\r\n\r\n      - Windows\r\n      - Linux\r\n      - Mac\r\n\r\n  - Introduction (25 min)\r\n\r\n    - Motivations for choosing Qt\r\n    - The licensing of Qt and PyQt\r\n    - The alternatives to Qt\r\n    - The PySide library\r\n    - The developer tools provided by Nokia\r\n\r\n      - Qt help system\r\n      - GUI Designer\r\n      - Internationalization support\r\n\r\n    - Developing for non-Desktop platforms\r\n    - Nokia-provided examples and demos\r\n\r\n  - GUI Programming (10 min)\r\n\r\n    - The event loop\r\n    - Using GUI code generators vs. hand coding\r\n    - Mixing application logic with GUI logic; good or bad?\r\n\r\n  - Using the API (20 min)\r\n\r\n    - Issues with interfacing to a C++ library\r\n\r\n      - Reading C++ prototypes and translating them to Python calls\r\n      - Getters and setters\r\n      - What you need to know about type conversions\r\n      - When not to use a Qt type\r\n\r\n    - Navigating the documentation\r\n    - Qt widgets summary and their respective classes\r\n    - Importing from the Qt modules\r\n\r\n  - Writing a simple GUI (15 min)\r\n\r\n    - Example 1: Dialog with QLabel\r\n    - Layout managers QHBoxLayout and QVBoxlayout\r\n    - Modified example 1 with the QHBoxLayout layout\r\n    - Example 2: Dialog with QLabel and QSpinbox\r\n\r\n  - Break (20 min)\r\n\r\n  - The Qt signals and slots (20 min)\r\n\r\n    - Qt's signaling system\r\n    - Modified example 2 with QSpinbox value updating QLabel text\r\n    - When to use multiple layout managers\r\n    - Example 3: Dialog with QLabel, QSpinbox, and non-functional\r\n      QPushButton\r\n    - The slots of QDialog\r\n    - Modified example 3 with QPushButton closing the application\r\n    - Modified example 3 with close button right justified\r\n    - Platform-specific layouts abstracted by Qt\r\n    - Modified example 3 with close button provided by QButtonBox\r\n\r\n  - Customizing Qt widgets through inheritance (10 min)\r\n\r\n    - Extending the default Qt classes for modified functionality\r\n    - A detailed look at QSpinBox\r\n    - Example 4: A simple hexadecimal adder with two QLineEdit, two\r\n      HexSpinBox, and one \"ok\" QButtonBox widgets with a\r\n      popup popup result using QMessageBox\r\n\r\n  - The GUI Designer (20 min)\r\n\r\n    - Capabilities of the Designer\r\n    - Why use it?\r\n    - Recreating Example 3 dialog with the Designer\r\n    - Running pyuic\r\n    - Examining the code produced by pyuic\r\n    - Creating a simple Makefile to run pyuic\r\n    - Example 5: Super simple calculator with 4 radio-button operations\r\n      and two inputs.  Full equation with result is displayed\r\n      at the time of any UI changes.  Close button stops the\r\n      application.\r\n\r\n  - Final Example (30 min)\r\n\r\n    - Implement a dialog that asks the user to select a .bmp or .png\r\n      file using the QFileDialog widget.  Once selected, the application\r\n      will alert the user to any errors prohibiting its processing the file.\r\n      A preview of the file's image will be added to the dialog along with\r\n      information about the file (type, size, image size).\r\n    \r\n    - The example will require subclassing of QDialog in order for the\r\n      image to scale properly as the dialog is scaled.  Additional\r\n      concepts of size policy will also be incorporated.\r\n\r\n  - Summary\r\n}}}", 
            "title": "Creating GUI Applications in Python using Qt I", 
            "plenary": false, 
            "abstract_html": "<pre>Below is an outline of the material to be presented during the class.  The\r\nexamples listed (unless otherwise noted) are developed while in class to show\r\nthe process and progression of GUI development.\r\n\r\n\r\n  - Installation Summary (10 min)\r\n\r\n    - Reference to detailed instructions provided before the class began\r\n\r\n    - Supported platforms\r\n\r\n      - Windows\r\n      - Linux\r\n      - Mac\r\n\r\n  - Introduction (25 min)\r\n\r\n    - Motivations for choosing Qt\r\n    - The licensing of Qt and PyQt\r\n    - The alternatives to Qt\r\n    - The PySide library\r\n    - The developer tools provided by Nokia\r\n\r\n      - Qt help system\r\n      - GUI Designer\r\n      - Internationalization support\r\n\r\n    - Developing for non-Desktop platforms\r\n    - Nokia-provided examples and demos\r\n\r\n  - GUI Programming (10 min)\r\n\r\n    - The event loop\r\n    - Using GUI code generators vs. hand coding\r\n    - Mixing application logic with GUI logic; good or bad?\r\n\r\n  - Using the API (20 min)\r\n\r\n    - Issues with interfacing to a C++ library\r\n\r\n      - Reading C++ prototypes and translating them to Python calls\r\n      - Getters and setters\r\n      - What you need to know about type conversions\r\n      - When not to use a Qt type\r\n\r\n    - Navigating the documentation\r\n    - Qt widgets summary and their respective classes\r\n    - Importing from the Qt modules\r\n\r\n  - Writing a simple GUI (15 min)\r\n\r\n    - Example 1: Dialog with QLabel\r\n    - Layout managers QHBoxLayout and QVBoxlayout\r\n    - Modified example 1 with the QHBoxLayout layout\r\n    - Example 2: Dialog with QLabel and QSpinbox\r\n\r\n  - Break (20 min)\r\n\r\n  - The Qt signals and slots (20 min)\r\n\r\n    - Qt's signaling system\r\n    - Modified example 2 with QSpinbox value updating QLabel text\r\n    - When to use multiple layout managers\r\n    - Example 3: Dialog with QLabel, QSpinbox, and non-functional\r\n      QPushButton\r\n    - The slots of QDialog\r\n    - Modified example 3 with QPushButton closing the application\r\n    - Modified example 3 with close button right justified\r\n    - Platform-specific layouts abstracted by Qt\r\n    - Modified example 3 with close button provided by QButtonBox\r\n\r\n  - Customizing Qt widgets through inheritance (10 min)\r\n\r\n    - Extending the default Qt classes for modified functionality\r\n    - A detailed look at QSpinBox\r\n    - Example 4: A simple hexadecimal adder with two QLineEdit, two\r\n      HexSpinBox, and one \"ok\" QButtonBox widgets with a\r\n      popup popup result using QMessageBox\r\n\r\n  - The GUI Designer (20 min)\r\n\r\n    - Capabilities of the Designer\r\n    - Why use it?\r\n    - Recreating Example 3 dialog with the Designer\r\n    - Running pyuic\r\n    - Examining the code produced by pyuic\r\n    - Creating a simple Makefile to run pyuic\r\n    - Example 5: Super simple calculator with 4 radio-button operations\r\n      and two inputs.  Full equation with result is displayed\r\n      at the time of any UI changes.  Close button stops the\r\n      application.\r\n\r\n  - Final Example (30 min)\r\n\r\n    - Implement a dialog that asks the user to select a .bmp or .png\r\n      file using the QFileDialog widget.  Once selected, the application\r\n      will alert the user to any errors prohibiting its processing the file.\r\n      A preview of the file's image will be added to the dialog along with\r\n      information about the file (type, size, image size).\r\n    \r\n    - The example will require subclassing of QDialog in order for the\r\n      image to scale properly as the dialog is scaled.  Additional\r\n      concepts of size policy will also be incorporated.\r\n\r\n  - Summary\r</pre>", 
            "speaker": 193, 
            "submitted": "2010-11-01 20:37:39", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 215, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "This tutorial is intended for Python programmers with limited GUI programming experience with PyQt. The course is designed as a follow-on course. By the end of the course students will have an understanding of building main GUI applications, creating tables and lists widgets, using the Qt MVC for complex tables and lists, and using the item-based graphics.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "{{{\r\nBelow is an outline of the material to be presented during the class.  The\r\nexamples listed (unless otherwise noted) are developed while in class to show\r\nthe process and progression of GUI development.\r\n\r\n- QListWidget Example (15 min)\r\n\r\n  - Creating a simple GUI presenting a directory list with unique icons for\r\n    files and directories.\r\n\r\n- QTableWidget Example (15 min)\r\n\r\n  - Converting the QListWidget example into a table with columns for the file\r\n    name, attributes, and size.\r\n  - Modify the example to support column sorting\r\n  - Discuss limitations of the widget (no commas in the file size, no color\r\n    coded rows, no validation logic for editable fields)\r\n\r\n- QTableView Example (20 min)\r\n\r\n  - Discussion of Qt's approach to MVC\r\n\r\n    - QTableView\r\n    - QListView\r\n    - QTreeView\r\n\r\n  - Rewrite the QTableWidget but provide column sorting and row highlighting.\r\n    Include radio buttons to color rows greater than 1K, 10K, 100K, or 1M.\r\n\r\n- QTreeView Example (25 min)\r\n\r\n  - Discussion of the non-MVC, QTreeWidget class.\r\n  - Present and walk through completed example\r\n  - Discuss the problems of implementing a file dialog as a tree using the\r\n    QTreeWidget class.  The entire structure must be loaded into memory.\r\n  - Rewrite the QTableView example but not restrict the data to a single\r\n    directory.  Basically, we will create a file dialog common on most GUI\r\n    platforms.\r\n\r\n- Break (20 min)\r\n\r\n- Introduction of final example (5 min)\r\n\r\n  - The final example we will develop an application that permits the user\r\n    to load a .png or .jpg image and determine the RGB value and location of\r\n    a specific pixel within the image.\r\n\r\n- A discussion of QObject and events (5 min)\r\n\r\n  - How will QGraphicsRectItem receive slot events to move itself if it doesn't\r\n    inherit from QObject?\r\n\r\n- Image inspector design using Designer (10 min)\r\n\r\n  - Design with the class a dialog which will contain a QGraphicsView for the\r\n    main image, a QSpinBox for zoom control, a QLabel for the zoomed image, and\r\n    a QGroupBox to contain and RGB field and X/Y position.\r\n\r\n- Implementing the dialog code\r\n\r\n  - Initial functionality (20 min)\r\n\r\n    - Add the code to populate the main QGraphicsView's scene\r\n    - Add the selection box to the main scene\r\n    - Incorporate movement to the selection box\r\n    - Bound the selection box to the dimensions of the scene's image\r\n\r\n  - Creating the zoom QPixmap (20 min)\r\n\r\n    - Copy a portion of the image using the zoom control value which specifies\r\n      the height/width of the selection area\r\n    - Draw an exploded, pixelated, view of the image in the QPixmap\r\n    - Connect the zoom control's signals to a slot controlling the contents of\r\n      the QPixmap\r\n    - Add mouse handlers to highlight the selected pixel and populate its\r\n      RGB and location information\r\n\r\n- Implementing the main application (15 min)\r\n\r\n  - Layout the application menus in Designer\r\n\r\n    - File-->Open menu\r\n    - File-->Exit menu\r\n    - Image-->Pixel inspector menu\r\n    - Help-->About menu\r\n\r\n  - Application functionality\r\n\r\n    - Connect the pixel inspector to the menu signal\r\n    - Create a About popup and connect it to the application\r\n\r\n- Summary\r\n}}}", 
            "title": "Creating GUI Applications in Python using Qt II", 
            "plenary": false, 
            "abstract_html": "<pre>Below is an outline of the material to be presented during the class.  The\r\nexamples listed (unless otherwise noted) are developed while in class to show\r\nthe process and progression of GUI development.\r\n\r\n- QListWidget Example (15 min)\r\n\r\n  - Creating a simple GUI presenting a directory list with unique icons for\r\n    files and directories.\r\n\r\n- QTableWidget Example (15 min)\r\n\r\n  - Converting the QListWidget example into a table with columns for the file\r\n    name, attributes, and size.\r\n  - Modify the example to support column sorting\r\n  - Discuss limitations of the widget (no commas in the file size, no color\r\n    coded rows, no validation logic for editable fields)\r\n\r\n- QTableView Example (20 min)\r\n\r\n  - Discussion of Qt's approach to MVC\r\n\r\n    - QTableView\r\n    - QListView\r\n    - QTreeView\r\n\r\n  - Rewrite the QTableWidget but provide column sorting and row highlighting.\r\n    Include radio buttons to color rows greater than 1K, 10K, 100K, or 1M.\r\n\r\n- QTreeView Example (25 min)\r\n\r\n  - Discussion of the non-MVC, QTreeWidget class.\r\n  - Present and walk through completed example\r\n  - Discuss the problems of implementing a file dialog as a tree using the\r\n    QTreeWidget class.  The entire structure must be loaded into memory.\r\n  - Rewrite the QTableView example but not restrict the data to a single\r\n    directory.  Basically, we will create a file dialog common on most GUI\r\n    platforms.\r\n\r\n- Break (20 min)\r\n\r\n- Introduction of final example (5 min)\r\n\r\n  - The final example we will develop an application that permits the user\r\n    to load a .png or .jpg image and determine the RGB value and location of\r\n    a specific pixel within the image.\r\n\r\n- A discussion of QObject and events (5 min)\r\n\r\n  - How will QGraphicsRectItem receive slot events to move itself if it doesn't\r\n    inherit from QObject?\r\n\r\n- Image inspector design using Designer (10 min)\r\n\r\n  - Design with the class a dialog which will contain a QGraphicsView for the\r\n    main image, a QSpinBox for zoom control, a QLabel for the zoomed image, and\r\n    a QGroupBox to contain and RGB field and X/Y position.\r\n\r\n- Implementing the dialog code\r\n\r\n  - Initial functionality (20 min)\r\n\r\n    - Add the code to populate the main QGraphicsView's scene\r\n    - Add the selection box to the main scene\r\n    - Incorporate movement to the selection box\r\n    - Bound the selection box to the dimensions of the scene's image\r\n\r\n  - Creating the zoom QPixmap (20 min)\r\n\r\n    - Copy a portion of the image using the zoom control value which specifies\r\n      the height/width of the selection area\r\n    - Draw an exploded, pixelated, view of the image in the QPixmap\r\n    - Connect the zoom control's signals to a slot controlling the contents of\r\n      the QPixmap\r\n    - Add mouse handlers to highlight the selected pixel and populate its\r\n      RGB and location information\r\n\r\n- Implementing the main application (15 min)\r\n\r\n  - Layout the application menus in Designer\r\n\r\n    - File--&gt;Open menu\r\n    - File--&gt;Exit menu\r\n    - Image--&gt;Pixel inspector menu\r\n    - Help--&gt;About menu\r\n\r\n  - Application functionality\r\n\r\n    - Connect the pixel inspector to the menu signal\r\n    - Create a About popup and connect it to the application\r\n\r\n- Summary\r</pre>", 
            "speaker": 193, 
            "submitted": "2010-11-01 21:53:20", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 216, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Have tons of data that needs analysis? Now it's as easy as 1-2-3! 1) Sign up for an Amazon Web Services account. 2) Install Yelp's mrjob. 3) Write as few as a dozen lines of Python code. This talk will show you how to use mrjob and Amazon's Elastic MapReduce to easily process lots of data in parallel on a potentially large cluster of computers that you can rent for a dime per computer per hour.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "In their 2004 paper, Google outlined MapReduce - one of the programming models they use to process large data sets. MapReduce is a relatively simple model to develop for that allows the underlying framework to automatically parallelize the job, add fault tolerance, and scale the job to many commodity computers.\r\n\r\nIn 2009, Amazon Web Services introduced their Elastic MapReduce (EMR) product. It layers the Hadoop open source package on top of their Elastic Compute Cloud (EC2) to allow anyone to rent a cluster of computers by the hour, starting at about a dime per computer per hour, in order to run MapReduce jobs.\r\n\r\nSome of the significant issues with Amazon's solution involve starting up machine instances, replicating your code and its dependancies to EMR, running and monitoring the job, and gathering the results.\r\n\r\nSo Yelp developed mrjob, which takes care of these details and lets the developer focus on working with their data. Yelp uses mrjob to power many internal jobs that work with its very large log files, for example:\r\n\r\n* People Who Viewed This Also Viewed...\r\n* A user clicked an ad over and over, but we only want to charge the advertiser once\r\n* We're thinking of a change, but want to simulate how that will affect ad revenue\r\n\r\nNow you can use that same power with just a few lines of Python.\r\n\r\nUseful links:\r\n* Install mrjob: sudo easy_install mrjob\r\n* Documentation: http://packages.python.org/mrjob/\r\n* PyPI: http://pypi.python.org/pypi/mrjob\r\n* Development is hosted at github: http://github.com/Yelp/mrjob", 
            "title": "mrjob: Distributed Computing for Everyone", 
            "plenary": false, 
            "abstract_html": "<p>In their 2004 paper, Google outlined MapReduce - one of the programming models they use to process large data sets. MapReduce is a relatively simple model to develop for that allows the underlying framework to automatically parallelize the job, add fault tolerance, and scale the job to many commodity computers.\r</p>\n<p>In 2009, Amazon Web Services introduced their Elastic MapReduce (EMR) product. It layers the Hadoop open source package on top of their Elastic Compute Cloud (EC2) to allow anyone to rent a cluster of computers by the hour, starting at about a dime per computer per hour, in order to run MapReduce jobs.\r</p>\n<p>Some of the significant issues with Amazon's solution involve starting up machine instances, replicating your code and its dependancies to EMR, running and monitoring the job, and gathering the results.\r</p>\n<p>So Yelp developed mrjob, which takes care of these details and lets the developer focus on working with their data. Yelp uses mrjob to power many internal jobs that work with its very large log files, for example:\r</p>\n<ul>\n<li>People Who Viewed This Also Viewed...\r</li>\n<li>A user clicked an ad over and over, but we only want to charge the advertiser once\r</li>\n<li>We're thinking of a change, but want to simulate how that will affect ad revenue\r</li>\n</ul>\n<p>Now you can use that same power with just a few lines of Python.\r</p>\n<p>Useful links:\r</p>\n<ul>\n<li>Install mrjob: sudo easy_install mrjob\r</li>\n<li>Documentation: <a href=\"http://packages.python.org/mrjob/\">http://packages.python.org/mrjob/</a>\r</li>\n<li>PyPI: <a href=\"http://pypi.python.org/pypi/mrjob\">http://pypi.python.org/pypi/mrjob</a>\r</li>\n<li>Development is hosted at github: <a href=\"http://github.com/Yelp/mrjob\">http://github.com/Yelp/mrjob</a></li>\n</ul>\n", 
            "speaker": 125, 
            "submitted": "2010-11-01 21:53:21", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 222, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Part of my job as a scientist involves playing with rather large amounts of data (200 gb+).  In doing so we stumbled across some neat CS techniques that scale well, and are easy to understand and trivial to implement.  These techniques allow us to make some or many types of data analysis map-reducable.  I'll talk about interesting implementation details, fun science, and neat computer science.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "If an extreme talk, I will talk about interesting details/issues in:\r\n\r\n(1) Python as the backbone for a non-SciPy scientific software package: using Python as a frontend to C++ code, esp for parallelization and testing purposes.\r\n\r\n(2) Implementing probabilistic data structures with one-sided error as pre-filters for data retrieval and analysis, in ways that are generally useful.\r\n\r\n(3) Efficiently breaking down certain types of sparse graph problems using these probabilistic data structures, so that large graphs can be analyzed straightforwardly.  This will be applied to plagiarism detection and/or duplicate code detection.", 
            "title": "Handling ridiculous amounts of data with probabilistic data structures", 
            "plenary": false, 
            "abstract_html": "<p>If an extreme talk, I will talk about interesting details/issues in:\r</p>\n<p>(1) Python as the backbone for a non-SciPy scientific software package: using Python as a frontend to C++ code, esp for parallelization and testing purposes.\r</p>\n<p>(2) Implementing probabilistic data structures with one-sided error as pre-filters for data retrieval and analysis, in ways that are generally useful.\r</p>\n<p>(3) Efficiently breaking down certain types of sparse graph problems using these probabilistic data structures, so that large graphs can be analyzed straightforwardly.  This will be applied to plagiarism detection and/or duplicate code detection.</p>\n", 
            "speaker": 211, 
            "submitted": "2010-11-01 23:47:40", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": true, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 224, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python has two useful conventions for \"I mean it, but only here\" and you can say it with Context Managers and Decorators.  Both give you the power to define a push/pop of a resource for a set period inside a namespace, be it a function or a level of indentation.\r\n\r\nThis talk is a list of patterns that are implemented by one or the other (including some clever functions that are both).", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "* Decorators, formal definition.\r\n* Context Managers, formal definition.\r\n* Informal definition: both have the opportunity to do and then undo.\r\n  - very similar to C++ RIIA \"Resource Acquisition Is Initialization.\"\r\n  - Context Managers were designed to do that but decorators are frequently just as good.\r\n* Which one to use use when is all about namespaces.\r\n  - Context Managers manipulate at the block level.\r\n  - Function Decorators manipulate the function level.\r\n  - Class Decorators manipulate at the class level.\r\n* Recipes on writing decorators and context managers\r\n  - Familiar examples from Django and Mock.", 
            "title": "Useful Namespaces: Context Mangagers and Decorators", 
            "plenary": false, 
            "abstract_html": "<ul>\n<li>Decorators, formal definition.\r</li>\n<li>Context Managers, formal definition.\r</li>\n<li>Informal definition: both have the opportunity to do and then undo.\r   - very similar to C++ RIIA \"Resource Acquisition Is Initialization.\"\r   - Context Managers were designed to do that but decorators are frequently just as good.\r</li>\n<li>Which one to use use when is all about namespaces.\r   - Context Managers manipulate at the block level.\r   - Function Decorators manipulate the function level.\r   - Class Decorators manipulate at the class level.\r</li>\n<li>Recipes on writing decorators and context managers\r   - Familiar examples from Django and Mock.</li>\n</ul>\n", 
            "speaker": 212, 
            "submitted": "2010-11-01 23:54:32", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 226, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python is becoming increasingly popular within the high performance computing community. While it initially gained traction as a scripting language, Python's role has continued to expand with Python applications for science scaling to hundreds of thousands of cores and bindings to high performance libraries becoming commonplace. This talk is meant as an overview of Python's role in the HPC space.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "This talk is focused on raising awareness of Python in the high performance computing space. Specific topics include:\r\n* building the Python interpreter for speed\r\n* an overview of bindings to numerical libraries\r\n* using GPUs and accelerators with Python\r\n* scaling codes with MPI\r\n* issues when scaling on very large systems\r\n* an overview of successful science codes\r\n* a live demonstration of Python running on 163,840 cores", 
            "title": "Python for High Performance Computing", 
            "plenary": false, 
            "abstract_html": "<p>This talk is focused on raising awareness of Python in the high performance computing space. Specific topics include:\r</p>\n<ul>\n<li>building the Python interpreter for speed\r</li>\n<li>an overview of bindings to numerical libraries\r</li>\n<li>using GPUs and accelerators with Python\r</li>\n<li>scaling codes with MPI\r</li>\n<li>issues when scaling on very large systems\r</li>\n<li>an overview of successful science codes\r</li>\n<li>a live demonstration of Python running on 163,840 cores</li>\n</ul>\n", 
            "speaker": 203, 
            "submitted": "2010-11-02 01:24:01", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 245, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "As communities allow more diversity, they draw from a larger talent pool, challenge each other more, and hit a higher bar in terms of ingenuity and work-product. However questions surrounding diversity often seem under-examined. What are the effects of diversity in the community, or lack thereof? I intend to approach this topic from an accessible and entertaining, yet analytical perspective.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Last year there was a photo of Kate Moss shown during a PyCon presentation which raised debate as to its appropriateness. This debate brought up some interesting questions - but what I found most interesting was that while it elicited strong opinions, the issue seemed to be somewhat unexamined. This event sparked a desire for deeper analysis on this topic in a more focussed setting.\r\n\r\nIn this talk, I intend to address some of the core principles underlying this debate. Discussion will include the following questions: Where does responsibility lie in understanding these issues? What are the effects of failing to do so? What are the effects of diversity in the community, or lack thereof? What do we lose by being more homogenous or more diverse? Gain? \r\n\r\nAs communities allow more diversity, they draw from a larger talent pool, challenge each other more, and hit a higher bar in terms of ingenuity and work-product. However, diversity requires awareness and tolerance on both the part of the dominant culture and on the part of the new arrivals to smooth the inevitable rough edges.\r\n\r\nI intend to approach this topic from an accessible, inclusive and entertaining, yet analytical perspective. The broader intent is to raise the level of understanding and community discourse on this topic. It is odd that diversity can so dramatically affect our lives and communities and yet be unexamined, particularly in a community so highly intelligent and educated as that which populates the tech industry.", 
            "title": "Diversity in Tech: Improving our Toolset", 
            "plenary": false, 
            "abstract_html": "<p>Last year there was a photo of Kate Moss shown during a PyCon presentation which raised debate as to its appropriateness. This debate brought up some interesting questions - but what I found most interesting was that while it elicited strong opinions, the issue seemed to be somewhat unexamined. This event sparked a desire for deeper analysis on this topic in a more focussed setting.\r</p>\n<p>In this talk, I intend to address some of the core principles underlying this debate. Discussion will include the following questions: Where does responsibility lie in understanding these issues? What are the effects of failing to do so? What are the effects of diversity in the community, or lack thereof? What do we lose by being more homogenous or more diverse? Gain? \r</p>\n<p>As communities allow more diversity, they draw from a larger talent pool, challenge each other more, and hit a higher bar in terms of ingenuity and work-product. However, diversity requires awareness and tolerance on both the part of the dominant culture and on the part of the new arrivals to smooth the inevitable rough edges.\r</p>\n<p>I intend to approach this topic from an accessible, inclusive and entertaining, yet analytical perspective. The broader intent is to raise the level of understanding and community discourse on this topic. It is odd that diversity can so dramatically affect our lives and communities and yet be unexamined, particularly in a community so highly intelligent and educated as that which populates the tech industry.</p>\n", 
            "speaker": 214, 
            "submitted": "2010-11-02 05:54:56", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 228, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Jython is arguably the best Python implementation to target concurrent code. Jython has no GIL, it leverages the Java platform to provide robust support for concurrency in its runtime, and it enables access to a set of high-level abstractions from Java. This talk will walk through at the extreme level pertinent Jython implementation details and a series of examples, including Java integration.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Jython implements the Python language, but we leverage the underlying\r\nJava platform to provide an opionated alternative to CPython in our\r\nsupport of concurrency.\r\n\r\nBecause of the GIL and related infrastructure, CPython cannot use a\r\nmodel in which threads perform concurrent computation defined in\r\nPython on shared objects in the same process.  (Of course, there are\r\nworkarounds, such as multiprocessing or using C extensions.)\r\n\r\nIn contrast, there's no GIL in Jython. Jython instead embraces\r\nthreads, provides extensive support for managing their execution and\r\ncoordination through standard Java platform functionality\r\n(//java.util.concurrent//), and threaded code works well with Jython's\r\nimplementation of standard mutable collection types. Lastly, the\r\nunderlying JVM provides extensive instrumentation as well as the\r\nability to set a variety of parameters, including choice of GC. There\r\nare also the inevitable pitfalls that might be seen in complex\r\narchitectures, such as around the use of //ClassLoader//s.\r\n\r\nThis talk will go into a detailed discussion of some of the\r\ninteresting ramifications of these design points and how they can be\r\neffectively applied to write concurrent code, as illustrated through a\r\nvariety of short examples.", 
            "title": "Jython Concurrency", 
            "plenary": false, 
            "abstract_html": "<p>Jython implements the Python language, but we leverage the underlying\r Java platform to provide an opionated alternative to CPython in our\r support of concurrency.\r</p>\n<p>Because of the GIL and related infrastructure, CPython cannot use a\r model in which threads perform concurrent computation defined in\r Python on shared objects in the same process.  (Of course, there are\r workarounds, such as multiprocessing or using C extensions.)\r</p>\n<p>In contrast, there's no GIL in Jython. Jython instead embraces\r threads, provides extensive support for managing their execution and\r coordination through standard Java platform functionality\r (<i>java.util.concurrent</i>), and threaded code works well with Jython's\r implementation of standard mutable collection types. Lastly, the\r underlying JVM provides extensive instrumentation as well as the\r ability to set a variety of parameters, including choice of GC. There\r are also the inevitable pitfalls that might be seen in complex\r architectures, such as around the use of <i>ClassLoader</i>s.\r</p>\n<p>This talk will go into a detailed discussion of some of the\r interesting ramifications of these design points and how they can be\r effectively applied to write concurrent code, as illustrated through a\r variety of short examples.</p>\n", 
            "speaker": 149, 
            "submitted": "2010-11-02 01:56:45", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 235, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The #pylons IRC channel is the most common way of giving support to users of the Pyramid framework. In this talk we take away some of the most often discussed topics in the channel and give detailed answers to them.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Every development project has a few questions and doubts that seem to come up on its support channels every now and then. The Pyramid framework is no exception. \r\n\r\nIn this talk, we introduce Pyramid related FAQs using the chat logs and proceed to discuss them in detail. Showing the logs allows us to give the talk a lighter side and makes for an introduction to each topic based on real user questions.\r\n\r\nTopics covered here include:\r\n\r\n* Configuration objects.\r\n* Object traversal versus URL dispatch.\r\n* Context and views.\r\n* Authentication and authorization.\r\n* How much 'Zope stuff' is there in Pyramid and can we take it away?\r\n* Examples of how Pyramid enables the Pylons philosophy of integrating best of breed or preferred components.\r\n* The future of Pyramid and Pylons.", 
            "title": "The Pyramid FAQ", 
            "plenary": false, 
            "abstract_html": "<p>Every development project has a few questions and doubts that seem to come up on its support channels every now and then. The Pyramid framework is no exception. \r</p>\n<p>In this talk, we introduce Pyramid related FAQs using the chat logs and proceed to discuss them in detail. Showing the logs allows us to give the talk a lighter side and makes for an introduction to each topic based on real user questions.\r</p>\n<p>Topics covered here include:\r</p>\n<ul>\n<li>Configuration objects.\r</li>\n<li>Object traversal versus URL dispatch.\r</li>\n<li>Context and views.\r</li>\n<li>Authentication and authorization.\r</li>\n<li>How much 'Zope stuff' is there in Pyramid and can we take it away?\r</li>\n<li>Examples of how Pyramid enables the Pylons philosophy of integrating best of breed or preferred components.\r</li>\n<li>The future of Pyramid and Pylons.</li>\n</ul>\n", 
            "speaker": 85, 
            "submitted": "2010-11-02 02:43:10", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 237, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "In the past, Django users couldn't run apps unmodified on Google App Engine. Some tools helped with integration but required you to change your data models. Django-nonrel removes this requirement letting you run native Django apps on App Engine with only config changes if you bear in mind its restrictions like no JOINs. In this talk, we'll discuss Django-nonrel & porting App Engine apps to Django.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Previously, Django users could not get their apps to run unmodified on Google App Engine, the cloud application-hosting platform. Older tools like \"the Helper\" and \"the Patch\" required a change to the data models as well as perhaps integrating additional tools into the application source tree. The creators of the Patch realized how cumbersome this is and created a replacement for all of these older tools.\r\n\r\nDjango-nonrel allows users to run pure Django apps on App Engine with only minor configuration changes. It basically enables Django's ORM to operate on top of non-relational databases (in addition to preserving its ability to support standard relational DBs), one of which is Google App Engine's Datastore. (MongoDB is another.)\r\n\r\nWhat this means that current Django users can now use their existing knowledge to write apps for App Engine as long as they keep App Engine restrictions in mind, e.g., no JOINs. Projects written in this manner will work without any modifications other than changing the configuration settings. On the other side, App Engine developers now have an alternative to the '\"webapp\" framework that comes with its SDK. You can now leverage the power of a full web framework like Django and still enjoy the flexibility and scalability of App Engine. In this talk, we'll discuss Django-nonrel, and how to port App Engine apps from webapp to pure Django to run on App Engine using Django-nonrel.", 
            "title": "Running Django Apps on Google App Engine", 
            "plenary": false, 
            "abstract_html": "<p>Previously, Django users could not get their apps to run unmodified on Google App Engine, the cloud application-hosting platform. Older tools like \"the Helper\" and \"the Patch\" required a change to the data models as well as perhaps integrating additional tools into the application source tree. The creators of the Patch realized how cumbersome this is and created a replacement for all of these older tools.\r</p>\n<p>Django-nonrel allows users to run pure Django apps on App Engine with only minor configuration changes. It basically enables Django's ORM to operate on top of non-relational databases (in addition to preserving its ability to support standard relational DBs), one of which is Google App Engine's Datastore. (MongoDB is another.)\r</p>\n<p>What this means that current Django users can now use their existing knowledge to write apps for App Engine as long as they keep App Engine restrictions in mind, e.g., no JOINs. Projects written in this manner will work without any modifications other than changing the configuration settings. On the other side, App Engine developers now have an alternative to the '\"webapp\" framework that comes with its SDK. You can now leverage the power of a full web framework like Django and still enjoy the flexibility and scalability of App Engine. In this talk, we'll discuss Django-nonrel, and how to port App Engine apps from webapp to pure Django to run on App Engine using Django-nonrel.</p>\n", 
            "speaker": 151, 
            "submitted": "2010-11-02 03:46:05", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 238, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This talk is about the evolution of Python. We will discuss Python 2 and Python 3: what the compatibility issues are, what the main differences are, and also talk about migration, Python 2.6/2.7, and other transition tools.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Python is currently at a crossroads: Python 2 has taken it from a quiet word-of-mouth language to primetime, with many companies around the world using it and an ever-increasing global marketshare of the programming world. But now comes Python 3, the first version of the language that is not backwards compatible with previous releases.\r\n\r\nWhat does this mean? Are all my Python programs going to break? Will I have to rewrite everything? How much time do I have? When is Python 2 going to be EOL'd? Is the language undergoing a complete rewrite and will I even recognize it? What are the changes between Python 2 and 3 anyway? Also, the next generation is already here, as Python 3 is over two years old now. What has been ported so far, and what is its current status? Are migration plans or transition tools available? If I want to start learning Python, should I do Python 2 or Python 3? Are all Python 2 books obsolete?\r\n\r\nWe will attempt to answer all of these questions and more. Join us!\r\n\r\nOUTLINE/TOPICS\r\n    * Python 2 vs. Python 3\r\n    * Introduction to Python 3\r\n    * Backwards Compatibility\r\n    * Generational Changes\r\n    * Key Differences\r\n    * Role of Remaining Python 2.x releases\r\n    * Transition & Migration Plans & Tools\r\n    * Futures\r\n", 
            "title": "Python 3: the next generation is here already", 
            "plenary": false, 
            "abstract_html": "<p>Python is currently at a crossroads: Python 2 has taken it from a quiet word-of-mouth language to primetime, with many companies around the world using it and an ever-increasing global marketshare of the programming world. But now comes Python 3, the first version of the language that is not backwards compatible with previous releases.\r</p>\n<p>What does this mean? Are all my Python programs going to break? Will I have to rewrite everything? How much time do I have? When is Python 2 going to be EOL'd? Is the language undergoing a complete rewrite and will I even recognize it? What are the changes between Python 2 and 3 anyway? Also, the next generation is already here, as Python 3 is over two years old now. What has been ported so far, and what is its current status? Are migration plans or transition tools available? If I want to start learning Python, should I do Python 2 or Python 3? Are all Python 2 books obsolete?\r</p>\n<p>We will attempt to answer all of these questions and more. Join us!\r</p>\n<p>OUTLINE/TOPICS\r</p>\n<ul>\n<li>Python 2 vs. Python 3\r</li>\n<li>Introduction to Python 3\r</li>\n<li>Backwards Compatibility\r</li>\n<li>Generational Changes\r</li>\n<li>Key Differences\r</li>\n<li>Role of Remaining Python 2.x releases\r</li>\n<li>Transition &amp; Migration Plans &amp; Tools\r</li>\n<li>Futures\r</li>\n</ul>\n", 
            "speaker": 151, 
            "submitted": "2010-11-02 03:49:38", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 242, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "Google App Engine is an application development and cloud-hosting platform that lets users create apps to run Google's datacenters. In this 3-part tutorial, we'll give a 1-hour intro talk on cloud computing and App Engine, a 90-100 minute introductory codelab to get your feet wet with App Engine development, and finally conclude with about a half-hour intro to some of App Engine's newest features!", 
            "additional_speakers": [
                67
            ], 
            "session_type": 3, 
            "track": null, 
            "abstract": "Google App Engine is a unique hosting platform that lets you build applications and run them in Google's datacenters using the massive global infrastructure built to run the Internet's giant. App Engine offers a development environment that uses familiar technologies (Java and Python) and provides a powerful and robust set of services and APIs to users while maintaining security and independence from other apps running in the cloud. Its SDK includes a development server to test your apps before uploading to Google. App Engine is always free to get started so you can try it out with no risk, and if you need additional computing resources, you can purchase additional computing resources beyond the free quota limits. (If you enable billing and trust us with your credit card, we will extend your free quotas even further; you won't get charged until you exceed those *extended* quotas.) Scale your application to millions of users and pay only for what you use at competitive market pricing.\r\n\r\nIn this tutorial, we'll give you a comprehensive introduction to the platform in three components:\r\n\r\n* Cloud computing and App Engine seminar\r\n* Introductory App Engine codelab\r\n* New features found in recent releases\r\n\r\nIn the first hour, we review Cloud Computing as an industry and where Google App Engine fits into the picture. Specifically, we discuss App Engine as a PaaS solution because of the inherent challenges of building web and other applications. We'll outline the architecture of App Engine, what it's major components are, introduce its features and APIs, discuss the service and how it works (including information on the free quotas), present some information about current users and usage, including integration with Google Apps, and finally, give an overview of its enterprise edition called Google App Engine for Business.\r\n\r\nAfter the approximately one-hour lecture, we'll show you how to create applications that run on App Engine by building a simple but real web application from the ground up via a hands-on coding laboratory. Although based on the online tutorial, this codelab goes up and beyond what's in the documentation: you will get a more detailed step-by-step instructions to replicate that example as well as have the opportunity to extend your application with some of the newer APIs that come with App Engine. The codelab will cover the Users service, non-relational Datastore, and Memcache APIs.\r\n\r\nIn the final 20-30 minutes, we'll discuss some of the newest features found in recent App Engine releases and show you how to use them in your apps by giving a demonstration of each.\r\n", 
            "title": "Google App Engine workshop", 
            "plenary": false, 
            "abstract_html": "<p>Google App Engine is a unique hosting platform that lets you build applications and run them in Google's datacenters using the massive global infrastructure built to run the Internet's giant. App Engine offers a development environment that uses familiar technologies (Java and Python) and provides a powerful and robust set of services and APIs to users while maintaining security and independence from other apps running in the cloud. Its SDK includes a development server to test your apps before uploading to Google. App Engine is always free to get started so you can try it out with no risk, and if you need additional computing resources, you can purchase additional computing resources beyond the free quota limits. (If you enable billing and trust us with your credit card, we will extend your free quotas even further; you won't get charged until you exceed those *extended* quotas.) Scale your application to millions of users and pay only for what you use at competitive market pricing.\r</p>\n<p>In this tutorial, we'll give you a comprehensive introduction to the platform in three components:\r</p>\n<ul>\n<li>Cloud computing and App Engine seminar\r</li>\n<li>Introductory App Engine codelab\r</li>\n<li>New features found in recent releases\r</li>\n</ul>\n<p>In the first hour, we review Cloud Computing as an industry and where Google App Engine fits into the picture. Specifically, we discuss App Engine as a PaaS solution because of the inherent challenges of building web and other applications. We'll outline the architecture of App Engine, what it's major components are, introduce its features and APIs, discuss the service and how it works (including information on the free quotas), present some information about current users and usage, including integration with Google Apps, and finally, give an overview of its enterprise edition called Google App Engine for Business.\r</p>\n<p>After the approximately one-hour lecture, we'll show you how to create applications that run on App Engine by building a simple but real web application from the ground up via a hands-on coding laboratory. Although based on the online tutorial, this codelab goes up and beyond what's in the documentation: you will get a more detailed step-by-step instructions to replicate that example as well as have the opportunity to extend your application with some of the newer APIs that come with App Engine. The codelab will cover the Users service, non-relational Datastore, and Memcache APIs.\r</p>\n<p>In the final 20-30 minutes, we'll discuss some of the newest features found in recent App Engine releases and show you how to use them in your apps by giving a demonstration of each.\r</p>\n", 
            "speaker": 151, 
            "submitted": "2010-11-02 04:41:03", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 249, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Learn how to supercharge your python web applications (Django, Pylons, TG, GAE, Werkzeug, WSGI, etc) with real-time features! Presenceful and moderated chat? About 10 minutes, seriously. A real-time graph to monitor the CPU? Less than five. If you pay attention for at least half of this talk, you'll leave confident and ready to take advantage of WebSocket, Comet, and the world, thanks to Hookbox.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Hookbox (http://hookbox.org) is a Python and Eventlet-based Comet-server/message-queue which tightly integrates with existing web application infrastructure via web hooks and a REST interface; Hookbox\u2019s purpose is to ease the development of real-time web applications, with an emphasis on tight integration with existing web technology. Put simply, Hookbox is a web-enabled message queue. \r\n\r\nBrowers may directly connect to Hookbox, subscribe to named channels, and publish and receive messages on those channels in real-time. An external application (typically the web application itself) may also publish messages to channels by means of the Hookbox REST interface. All authentication and authorization is performed by an external web application via designated \u201cwebhook\u201d callbacks.\r\n\r\nIn this talk we cover the broad principles of Hookbox, then examine a few short examples in depth, including presenceful and moderated chat, real-time graphing, and, of course, a game. The code examples are very purposefully brief; the important parts of the talk deal with the interaction model between browser, web framework, and Hookbox -- everything else follows naturally and easily into place.\r\n\r\nThe audience need not be familiar with a particular web framework over another, but they must be proficient with at least one. \r\n\r\nThough this talk is aimed at a novice level, we'll also spend some time talking about the more advanced features that Hookbox provides.", 
            "title": "Hookbox: All Python web-frameworks, now real-time. Batteries Included.", 
            "plenary": false, 
            "abstract_html": "<p>Hookbox (<a href=\"http://hookbox.org\">http://hookbox.org</a>) is a Python and Eventlet-based Comet-server/message-queue which tightly integrates with existing web application infrastructure via web hooks and a REST interface; Hookbox\u2019s purpose is to ease the development of real-time web applications, with an emphasis on tight integration with existing web technology. Put simply, Hookbox is a web-enabled message queue. \r</p>\n<p>Browers may directly connect to Hookbox, subscribe to named channels, and publish and receive messages on those channels in real-time. An external application (typically the web application itself) may also publish messages to channels by means of the Hookbox REST interface. All authentication and authorization is performed by an external web application via designated \u201cwebhook\u201d callbacks.\r</p>\n<p>In this talk we cover the broad principles of Hookbox, then examine a few short examples in depth, including presenceful and moderated chat, real-time graphing, and, of course, a game. The code examples are very purposefully brief; the important parts of the talk deal with the interaction model between browser, web framework, and Hookbox -- everything else follows naturally and easily into place.\r</p>\n<p>The audience need not be familiar with a particular web framework over another, but they must be proficient with at least one. \r</p>\n<p>Though this talk is aimed at a novice level, we'll also spend some time talking about the more advanced features that Hookbox provides.</p>\n", 
            "speaker": 216, 
            "submitted": "2010-11-02 07:25:51", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 250, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Follow my 10 year adventure working with various Python technologies to create PinMachine - an electronic, programmable version of the classic 'pin art' desk toy. I'll show how I first used Visual Python to create my 3D software prototypes, and how I later used Arduino with Python serial interfaces to create my hardware protoypes. I'll have lots of prototypes on-hand for people to play with.\r\n", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "Covered topics:\r\n* Prototyping with Visual Python (VPython)\r\n* Arduino\r\n* Interfacing Arduino with Python\r\n* PinMachine and Pin Art - What, How, and Why\r\n* Prototyping with Lego\r\n", 
            "title": "Hardware Hacking with PinMachine", 
            "plenary": false, 
            "abstract_html": "<p>Covered topics:\r</p>\n<ul>\n<li>Prototyping with Visual Python (VPython)\r</li>\n<li>Arduino\r</li>\n<li>Interfacing Arduino with Python\r</li>\n<li>PinMachine and Pin Art - What, How, and Why\r</li>\n<li>Prototyping with Lego\r</li>\n</ul>\n", 
            "speaker": 215, 
            "submitted": "2010-11-02 07:34:51", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 251, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This presentation covers features of the standard library not widely known or used. Each feature is presented with a short demonstration program and explanation.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The standard library contains many hidden gems that are not widely used, either because they are not publicized enough or because they are deep in a module that programmers haven't had cause to study or use.  This presentation covers 8-10 selected topics of this nature in about 25 minutes (leaving time for a couple of questions).  Demonstration code is included for every item.\r\n\r\nPossible tips include, in no particular order:\r\n\r\n* Using hmac to verify pickled data before unpacking it.\r\n* Using uuid4 to generate session tokens.\r\n* Regular expression look-ahead/behind matches.\r\n* pdb startup files\r\n* Reading files with mmap\r\n* Using csv dialects\r\n* The robotparser module\r\n* The rlcompleter module\r\n* Using locale to format numbers and currency\r\n* The cgitb module\r\n* pkgutil.getdata\r\n* contextlib.contextmanager\r\n* The cmd module\r\n* The fileinput module\r\n", 
            "title": "Hidden Treasures in the Standard Library", 
            "plenary": false, 
            "abstract_html": "<p>The standard library contains many hidden gems that are not widely used, either because they are not publicized enough or because they are deep in a module that programmers haven't had cause to study or use.  This presentation covers 8-10 selected topics of this nature in about 25 minutes (leaving time for a couple of questions).  Demonstration code is included for every item.\r</p>\n<p>Possible tips include, in no particular order:\r</p>\n<ul>\n<li>Using hmac to verify pickled data before unpacking it.\r</li>\n<li>Using uuid4 to generate session tokens.\r</li>\n<li>Regular expression look-ahead/behind matches.\r</li>\n<li>pdb startup files\r</li>\n<li>Reading files with mmap\r</li>\n<li>Using csv dialects\r</li>\n<li>The robotparser module\r</li>\n<li>The rlcompleter module\r</li>\n<li>Using locale to format numbers and currency\r</li>\n<li>The cgitb module\r</li>\n<li>pkgutil.getdata\r</li>\n<li>contextlib.contextmanager\r</li>\n<li>The cmd module\r</li>\n<li>The fileinput module\r</li>\n</ul>\n", 
            "speaker": 217, 
            "submitted": "2010-11-02 07:50:24", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 255, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "The control of the Mars Exploration Rovers (MER) requires a complex set of coordinated activites by a team. Early in the MER mission the author automated in Python much of the task of one of the operation positions, the Payload Uplink Lead, for 7 of the 9 cameras on each rover.  This talk describes the MER rovers, the operation tasks and that implemented system.  ", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The Mars Exploration Rovers (MER), Spirit and Opportunity, have been\r\nroaming the surface of Mars since January of 2004 leading to many\r\ndiscoveries about the nature and history of our sister planet.  Each\r\nactivity requires a complex set of coordinated activites by a team.\r\nEarly in the MER mission the author automated much of the task of one\r\nof the positions, the Payload Uplink Lead, for 7 of the 9 cameras on\r\neach rover.  The system, called AutoPUL, is written in Python and that\r\nhas proven to be the excellent choice for the development and\r\nmaintenance.  In the talk I'll describe the Mars Rover mission and the\r\noperational activities and how AutoPUL and Python fullfilled those\r\nneeds.", 
            "title": "Greasing the Wheels of Exploration with Python", 
            "plenary": false, 
            "abstract_html": "<p>The Mars Exploration Rovers (MER), Spirit and Opportunity, have been\r roaming the surface of Mars since January of 2004 leading to many\r discoveries about the nature and history of our sister planet.  Each\r activity requires a complex set of coordinated activites by a team.\r Early in the MER mission the author automated much of the task of one\r of the positions, the Payload Uplink Lead, for 7 of the 9 cameras on\r each rover.  The system, called AutoPUL, is written in Python and that\r has proven to be the excellent choice for the development and\r maintenance.  In the talk I'll describe the Mars Rover mission and the\r operational activities and how AutoPUL and Python fullfilled those\r needs.</p>\n", 
            "speaker": 222, 
            "submitted": "2010-11-03 01:37:44", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 258, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Learn how cool it is to write command-line tools using IronPython and Visual Studios.  In this talk we cover why command-lines tools are important for .NET shops, how to write one, and finally, how to distribute it as a standalone .exe.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Learn how cool it is to write command-line tools using IronPython and Visual Studios.  In this talk we cover why command-lines tools are important for .NET shops, how to write one, and finally, how to distribute it as a standalone .exe.", 
            "title": "Writing Command-Line Tools using IronPython and Visual Studios", 
            "plenary": false, 
            "abstract_html": "<p>Learn how cool it is to write command-line tools using IronPython and Visual Studios.  In this talk we cover why command-lines tools are important for .NET shops, how to write one, and finally, how to distribute it as a standalone .exe.</p>\n", 
            "speaker": 26, 
            "submitted": "2010-11-04 01:18:31", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 261, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Spend ten minutes each learning to work with Counters, named tuples, new string formatting, and the LRU cache.\r\n\r\nLearn the basic API, see how it works under the hood, enjoy a simple example, and then have fun pushing it to the limit in interesting ways.\r\n\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Look at how a Counter is implemented.  See a simple word count example.  Use a counter for unittests.  Implement a sparse matrix.\r\n\r\nShow how named tuples are created, combined, subclassed, and extended.  See how to implement an Enum class and how to create default values.\r\n\r\nLearn the basics of the new string formatting syntax.  See how to use it for templating.\r\n\r\nShow everyday uses for an LRU cache, look at the underlying implementation, and see how to use it to trivially solve a dynamic programming problem.", 
            "title": "Fun with Python's Newer Tools", 
            "plenary": false, 
            "abstract_html": "<p>Look at how a Counter is implemented.  See a simple word count example.  Use a counter for unittests.  Implement a sparse matrix.\r</p>\n<p>Show how named tuples are created, combined, subclassed, and extended.  See how to implement an Enum class and how to create default values.\r</p>\n<p>Learn the basics of the new string formatting syntax.  See how to use it for templating.\r</p>\n<p>Show everyday uses for an LRU cache, look at the underlying implementation, and see how to use it to trivially solve a dynamic programming problem.</p>\n", 
            "speaker": 131, 
            "submitted": "2010-11-04 03:27:28", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 263, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Share the lessons learned from a decade of core Python development, what worked and what didn't.  \r\n\r\nLook at the development process and thinking behind some of Python's successful APIs and ones that leave something to be desired. \r\n\r\nLearn general principles for designing a good API for public consumption.\r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Hear the story and principles behind the design of Python's \"in\" operator, the development of deques, and the evolution of the set API.  \r\n\r\nExamine the principles and story behind the development of the named tuple API. Learn about unforeseen use cases and a bug that made it to production.\r\n\r\nDiscuss the decimal module's API challenge -- adhering to a published standard. Talk about the Queue module's framework style and how the API was refactored.\r\n\r\nDiscuss what we've learned about naming functions and methods.  Look at the i-naming convention in itertools, camelcase oddities, the proposed Italian name for enumerate, and vaguely named methods like assertItemsEqual.\r\n\r\nLearn about Guido's ideas on when to add flags to method signatures.  Recap his thoughts on the problems with the percent formatting operator.  Then hear Raymond's advice on packaging, hierarchies, and nested name spaces.\r\n\r\nSee how to use documentation to mitigate API problems using examples from regular expressions, decimal, tokenize, sorting.\r\n\r\n", 
            "title": "API Design:  Lessons Learned", 
            "plenary": false, 
            "abstract_html": "<p>Hear the story and principles behind the design of Python's \"in\" operator, the development of deques, and the evolution of the set API.  \r</p>\n<p>Examine the principles and story behind the development of the named tuple API. Learn about unforeseen use cases and a bug that made it to production.\r</p>\n<p>Discuss the decimal module's API challenge -- adhering to a published standard. Talk about the Queue module's framework style and how the API was refactored.\r</p>\n<p>Discuss what we've learned about naming functions and methods.  Look at the i-naming convention in itertools, camelcase oddities, the proposed Italian name for enumerate, and vaguely named methods like assertItemsEqual.\r</p>\n<p>Learn about Guido's ideas on when to add flags to method signatures.  Recap his thoughts on the problems with the percent formatting operator.  Then hear Raymond's advice on packaging, hierarchies, and nested name spaces.\r</p>\n<p>See how to use documentation to mitigate API problems using examples from regular expressions, decimal, tokenize, sorting.\r</p>\n", 
            "speaker": 131, 
            "submitted": "2010-11-04 04:09:02", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": true, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 264, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "HTSQL is a URI-based high-level query language for relational databases; it is written in the Python language.  HTSQL is a wonderful complement existing WSGI-based applications, making it trivial to create interactive dashboards, complex reports.  We use HTSQL as a REST query interface for data integration and ad-hoc reporting by technical users or ``accidental programmers``. \r\n", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The HTSQL processor is a high-level URI-based query language for relational databases such as SQLite, PostgreSQL or MySQL. Since it's written in Python, it is easy to integrate and generates immediate value as the core of your application's custom reporting engine.  HTSQL is like the Django or SQLAlchemy ORMs in that it generates SQL, but unlike an ORM in that its design center is completely different -- it was created for hard core reporting and not object to relational mapping.  Hence, it is a wonderful complement to existing WSGI-based applications to easily create dashboards, complex reports.  We use HTSQL as a REST reporting interface for data integration and ad-hoc queries. \r\n\r\nThis talk will have two parts.  In the first part we'll give a brief overview of the rationale and design of the query language.  In the second part, we'll show how to hook the HTSQL processor into your WSGI application and how to make custom commands, such as a simple calendar output from a table containing a date column.\r\n\r\nThe talk will be presented by Clark Evans, HTSQL was developed by Kyrylo Simonov. The main HTSQL site is http://htsql.org and the code is at http://bitbucket.org/prometheus/htsql.   It'll be similar to previous talks, such as http://htsql.org/talks/20101103.html\r\n", 
            "title": "HTSQL - an insanely good WSGI / REST interface to your favorite database", 
            "plenary": false, 
            "abstract_html": "<p>The HTSQL processor is a high-level URI-based query language for relational databases such as SQLite, PostgreSQL or MySQL. Since it's written in Python, it is easy to integrate and generates immediate value as the core of your application's custom reporting engine.  HTSQL is like the Django or SQLAlchemy ORMs in that it generates SQL, but unlike an ORM in that its design center is completely different -- it was created for hard core reporting and not object to relational mapping.  Hence, it is a wonderful complement to existing WSGI-based applications to easily create dashboards, complex reports.  We use HTSQL as a REST reporting interface for data integration and ad-hoc queries. \r</p>\n<p>This talk will have two parts.  In the first part we'll give a brief overview of the rationale and design of the query language.  In the second part, we'll show how to hook the HTSQL processor into your WSGI application and how to make custom commands, such as a simple calendar output from a table containing a date column.\r</p>\n<p>The talk will be presented by Clark Evans, HTSQL was developed by Kyrylo Simonov. The main HTSQL site is <a href=\"http://htsql.org\">http://htsql.org</a> and the code is at <a href=\"http://bitbucket.org/prometheus/htsql\">http://bitbucket.org/prometheus/htsql</a>.   It'll be similar to previous talks, such as <a href=\"http://htsql.org/talks/20101103.html\">http://htsql.org/talks/20101103.html</a>\r</p>\n", 
            "speaker": 226, 
            "submitted": "2010-11-04 10:33:08", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 266, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Introduced in Python 2.0, unicode became the default string type in Python 3.0. It took 8 years to switch to unicode, and since Python 3.0, a lot of bugs has been fixed. The switch to unicode opened many questions. Should Python support both bytes and characters for filenames? What to do with undecodable bytes? etc.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "The talk will focus on the recent issues fixed in Python 3.1 and 3.2:\r\n\r\n * Use the PEP 383 (error handler to store undecodable bytes) everywhere\r\n * Encoding of the command line arguments: utf-8 on Mac OS X, locale encoding on UNIX/BSD, unicode on Windows\r\n * Environment variables: creation of os.environb\r\n * Filenames: huge work to support the PEP 383 everywhere, creation of os.fsencode() and os.fsdecode()\r\n * Python source code encoding: use tokenize.detect_encoding() instead of the locale encoding\r\n * some library examples: email, ftp, ...\r\n * etc.\r\n\r\nThe talk will present not only the changes in Python, but also in the C API.", 
            "title": "Status of Unicode in Python 3", 
            "plenary": false, 
            "abstract_html": "<p>The talk will focus on the recent issues fixed in Python 3.1 and 3.2:\r</p>\n<ul>\n<li>Use the PEP 383 (error handler to store undecodable bytes) everywhere\r</li>\n<li>Encoding of the command line arguments: utf-8 on Mac OS X, locale encoding on UNIX/BSD, unicode on Windows\r</li>\n<li>Environment variables: creation of os.environb\r</li>\n<li>Filenames: huge work to support the PEP 383 everywhere, creation of os.fsencode() and os.fsdecode()\r</li>\n<li>Python source code encoding: use tokenize.detect_encoding() instead of the locale encoding\r</li>\n<li>some library examples: email, ftp, ...\r</li>\n<li>etc.\r</li>\n</ul>\n<p>The talk will present not only the changes in Python, but also in the C API.</p>\n", 
            "speaker": 231, 
            "submitted": "2010-11-07 17:33:39", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": true, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 267, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Dialectical changes in America are influencing expression online. This talk will discuss a current project which is using the Natural Language Toolkit to develop up to date reference materials to measure and monitor online natural language.", 
            "additional_speakers": [], 
            "session_type": 1, 
            "track": null, 
            "abstract": "Contrary to expectations, the prevalence of television did not cause every American to speak in a common standard dialect. Rather, smaller sub-regional dialects are merging into stronger regional dialects with the largest change in spoken English since the 1750's taking place in the Northern Cities Vowel Shift.\r\n\r\nSocial Media is widely considered a conversational media, users often leaning on their dialect which to express themselves.\r\n\r\nTaking a recent tweet for example:\r\n\r\n'_andBeautyKills: \u2013 after tonight, don\u2019t leave your boy roun\u2019 me, umma #true playa fareal.'\r\n\r\nThis tweet presents a problem for traditional natural language processing paradigm:\r\n\r\n * Do they build out an extensive reg ex to solve this?\r\n * Even Worse, do they reject it because of non-Standard English?\r\n * How do they respond such that communication is effective?\r\n\r\nCurrently under development with Python using the Natural Language Toolkit are the tools and methodologies to process, understand and respond to communication that falls outside Standard American English. This talk will focus on the status of existing tools, where development stands, challenges for traditional tools and potential opportunities for exploration.\r\n\r\nWhile limited to American English, any participant who is studying natural language processing of any language is welcome and sure to learn. The techniques could be applied to languages around the world for which the motivated programmer is knowledgeable about.", 
            "title": "Linguistics of Twitter", 
            "plenary": false, 
            "abstract_html": "<p>Contrary to expectations, the prevalence of television did not cause every American to speak in a common standard dialect. Rather, smaller sub-regional dialects are merging into stronger regional dialects with the largest change in spoken English since the 1750's taking place in the Northern Cities Vowel Shift.\r</p>\n<p>Social Media is widely considered a conversational media, users often leaning on their dialect which to express themselves.\r</p>\n<p>Taking a recent tweet for example:\r</p>\n<p>'_andBeautyKills: \u2013 after tonight, don\u2019t leave your boy roun\u2019 me, umma #true playa fareal.'\r</p>\n<p>This tweet presents a problem for traditional natural language processing paradigm:\r</p>\n<ul>\n<li>Do they build out an extensive reg ex to solve this?\r</li>\n<li>Even Worse, do they reject it because of non-Standard English?\r</li>\n<li>How do they respond such that communication is effective?\r</li>\n</ul>\n<p>Currently under development with Python using the Natural Language Toolkit are the tools and methodologies to process, understand and respond to communication that falls outside Standard American English. This talk will focus on the status of existing tools, where development stands, challenges for traditional tools and potential opportunities for exploration.\r</p>\n<p>While limited to American English, any participant who is studying natural language processing of any language is welcome and sure to learn. The techniques could be applied to languages around the world for which the motivated programmer is knowledgeable about.</p>\n", 
            "speaker": 233, 
            "submitted": "2010-11-09 13:09:46", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 268, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "This poster illustrates a Python application for simulating satellite geolocation called SatSim. Using all open-source components, SatSim allows the user to explore different satellite constellations and digital filter designs for determining position estimates. Visual outputs show satellite and observer geometry animated on user-customized maps for a high degree of user interaction.", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "It is hard to imagine daily life without having some sort of electronic indication of one's current location. Whether the purpose is for business or personal use, using in-vehicle systems or smart cell phones, we depend on the Global Positioning System (GPS) to tell us where we are. Yet the availability of the GPS should not be taken for granted. Both environmental (terrain, weather) and intentional interference (jamming) can reduce or deny satellite use. In order to investigate these and other issues as well as to explore possible alternative systems, a Python application called the Satellite Simulation Toolkit (SatSim) was created.\r\n\r\nSatSim is a toolkit that integrates a number of functional elements that allow the user to explore different satellite constellations and digital filter designs for determining a position fix for an observer. The simple graphical user interface is broken down into four sections dealing with tasks, applications, resources, and sites using tabs and buttons. Tasks are Python scripts written in the form of wizards that guide a user through a series of steps to perform some sort of analysis, such as plotting the orbits of a satellite constellation or simulating the operation of a Kalman Filter to estimate an observer's position. Applications include standalone codes that perform some useful function like GPS Babel that can be used to interface a GPS receiver. Some applications have open APIs that allow mash-ups to be constructed as part of the task wizards. Resources gather together both web and local reference material, such as satellite ephemeris or data packet descriptions, in one convenient location. Finally, sites are user-customized maps that are used by the task wizards for visualizing simulations like satellite orbits and observer position estimate convergence. The intent is to put in one place all of the functionality needed by the user to investigate this topic.\r\n\r\nThis project uses the more general Geospatial Integrated Problem Solving Environment (GIPSE, pronounced gypsy) software framework created by the author. GIPSE allows custom applications having a geospatial basis to be developed quickly. It brings together an intuitive graphical user interface, a database, an automatic report generator, and a simple map viewer with markup tools. The GIPSE core is constructed with open-source tools, including Python, wxPython, and PostgreSQL, and uses non-copyrighted map data from NASA, USGS, and OpenStreetMap. Reports may utilize templates in either OpenOffice ODF or Microsoft OOXML.\r\n", 
            "title": "Creating a Python Framework for Simulating Satellite Geolocation", 
            "plenary": false, 
            "abstract_html": "<p>It is hard to imagine daily life without having some sort of electronic indication of one's current location. Whether the purpose is for business or personal use, using in-vehicle systems or smart cell phones, we depend on the Global Positioning System (GPS) to tell us where we are. Yet the availability of the GPS should not be taken for granted. Both environmental (terrain, weather) and intentional interference (jamming) can reduce or deny satellite use. In order to investigate these and other issues as well as to explore possible alternative systems, a Python application called the Satellite Simulation Toolkit (SatSim) was created.\r</p>\n<p>SatSim is a toolkit that integrates a number of functional elements that allow the user to explore different satellite constellations and digital filter designs for determining a position fix for an observer. The simple graphical user interface is broken down into four sections dealing with tasks, applications, resources, and sites using tabs and buttons. Tasks are Python scripts written in the form of wizards that guide a user through a series of steps to perform some sort of analysis, such as plotting the orbits of a satellite constellation or simulating the operation of a Kalman Filter to estimate an observer's position. Applications include standalone codes that perform some useful function like GPS Babel that can be used to interface a GPS receiver. Some applications have open APIs that allow mash-ups to be constructed as part of the task wizards. Resources gather together both web and local reference material, such as satellite ephemeris or data packet descriptions, in one convenient location. Finally, sites are user-customized maps that are used by the task wizards for visualizing simulations like satellite orbits and observer position estimate convergence. The intent is to put in one place all of the functionality needed by the user to investigate this topic.\r</p>\n<p>This project uses the more general Geospatial Integrated Problem Solving Environment (GIPSE, pronounced gypsy) software framework created by the author. GIPSE allows custom applications having a geospatial basis to be developed quickly. It brings together an intuitive graphical user interface, a database, an automatic report generator, and a simple map viewer with markup tools. The GIPSE core is constructed with open-source tools, including Python, wxPython, and PostgreSQL, and uses non-copyrighted map data from NASA, USGS, and OpenStreetMap. Reports may utilize templates in either OpenOffice ODF or Microsoft OOXML.\r</p>\n", 
            "speaker": 235, 
            "submitted": "2010-11-19 10:17:44", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 269, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "At this poster you will learn about a set of open source tools for GPU computing using python based on ctypes.  These tools provide lots of glue, combining elements of\r\n\r\npython <=> pyglet <=> CUDA <=> C# <=> Django.\r\n\r\nYou will see how we use these tools in our Next Generation Air Transportation work.\r\n\r\n", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "[[http://www.NextAero.com/|NextGen AeroSciences, LLC]] NextGen AeroSciences, LLC, is working with colleagues at NASA, NIA, and other US Government and related organizations in support of national efforts to transform the US air transportation system.  The Company builds on its founders' contributions in applied research in complexity and network sciences, computationally efficient combinatorial mathematics, and in air transportation system strategies, technologies, and innovation management.  The founders bring a heritage from the Santa Fe Institute, NASA, Los Alamos National Laboratory, Bios Group, and DayJet Corporation.\r\n\r\n[[http://www.nextsciences.com/Assets/job_panel_screen.jpg|{{http://www.nextsciences.com/Assets/job_panel_screen_small.jpg|job control panel}}]] [[http://www.nextsciences.com/Assets/aerodisplay_screen.jpg|{{http://www.nextsciences.com/Assets/aerodisplay_screen_small.png|200 aircraft}}]]\r\n\r\n\r\n== The following tools (and possibly others) will be described:\r\n\r\n* ct_cuda provides a ctypes interface to CUDA.  This approach offers a lightweight alternative to pycuda.  ct_cuda does not require a build; a relief for those who consider ctypes a preferable alternative to python extension wrapper libraries.  Another difference is that kernels are built in the standard CUDA-C manner and exposed to python as kernel libraries via ctypes.\r\n\r\n* boaracuda consists of glue to make CUDA accessible to a pyglet app. Among other benefits, this allows a CUDA kernel to operate on pyglet based vertex lists.  This approach enables fast-time animation tens of thousands of sprites in pyglet with trajectories calculated in a CUDA kernel. (Etymology hint: boar=pyglet)\r\n\r\n* ct_sharp makes a python shell available to C#, suitable for launching a pyglet control thread.\r\n\r\n* cuda_sharp makes CUDA available to C# and provides interoperability between C# and python (e.g. passing CUDA buffers between C# and python)\r\n\r\n* A system for launching remote CUDA jobs from a Django application will also be described.\r\n\r\nThe implementation of this software architecture provides the means for understanding, designing, and ultimately operating complex adaptive systems such as in air transportation.", 
            "title": "GPU computing and the Next Generation Air Transportation System", 
            "plenary": false, 
            "abstract_html": "<p><a href=\"http://www.NextAero.com/\">NextGen AeroSciences, LLC</a> NextGen AeroSciences, LLC, is working with colleagues at NASA, NIA, and other US Government and related organizations in support of national efforts to transform the US air transportation system.  The Company builds on its founders' contributions in applied research in complexity and network sciences, computationally efficient combinatorial mathematics, and in air transportation system strategies, technologies, and innovation management.  The founders bring a heritage from the Santa Fe Institute, NASA, Los Alamos National Laboratory, Bios Group, and DayJet Corporation.\r</p>\n<p><a href=\"http://www.nextsciences.com/Assets/job_panel_screen.jpg\"><img src=\"http://www.nextsciences.com/Assets/job_panel_screen_small.jpg\" alt=\"job control panel\"></a> <a href=\"http://www.nextsciences.com/Assets/aerodisplay_screen.jpg\"><img src=\"http://www.nextsciences.com/Assets/aerodisplay_screen_small.png\" alt=\"200 aircraft\"></a>\r</p>\n<h2>The following tools (and possibly others) will be described:</h2>\n<ul>\n<li>ct_cuda provides a ctypes interface to CUDA.  This approach offers a lightweight alternative to pycuda.  ct_cuda does not require a build; a relief for those who consider ctypes a preferable alternative to python extension wrapper libraries.  Another difference is that kernels are built in the standard CUDA-C manner and exposed to python as kernel libraries via ctypes.\r</li>\n</ul>\n<ul>\n<li>boaracuda consists of glue to make CUDA accessible to a pyglet app. Among other benefits, this allows a CUDA kernel to operate on pyglet based vertex lists.  This approach enables fast-time animation tens of thousands of sprites in pyglet with trajectories calculated in a CUDA kernel. (Etymology hint: boar=pyglet)\r</li>\n</ul>\n<ul>\n<li>ct_sharp makes a python shell available to C#, suitable for launching a pyglet control thread.\r</li>\n</ul>\n<ul>\n<li>cuda_sharp makes CUDA available to C# and provides interoperability between C# and python (e.g. passing CUDA buffers between C# and python)\r</li>\n</ul>\n<ul>\n<li>A system for launching remote CUDA jobs from a Django application will also be described.\r</li>\n</ul>\n<p>The implementation of this software architecture provides the means for understanding, designing, and ultimately operating complex adaptive systems such as in air transportation.</p>\n", 
            "speaker": 236, 
            "submitted": "2010-11-29 04:38:10", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 270, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "As Python becomes more popular, more users are wanting IDEs that provide code completion, integrated source code control, project management, and other developer tools. This panel includes representatives from a number of Python-specific or Python-supporting IDE vendors, showing the ways that IDEs can speed up development on any platform.", 
            "additional_speakers": [], 
            "session_type": 2, 
            "track": null, 
            "abstract": "For many developers, IDEs are an essential tool-just as essential as source code control. The growth of Python in recent years has led to a number of projects and vendors developing Python-specific or Python-supporting IDEs. This panel will allow attendees to compare and contrast the different IDEs available.", 
            "title": "Python IDEs Panel", 
            "plenary": false, 
            "abstract_html": "<p>For many developers, IDEs are an essential tool-just as essential as source code control. The growth of Python in recent years has led to a number of projects and vendors developing Python-specific or Python-supporting IDEs. This panel will allow attendees to compare and contrast the different IDEs available.</p>\n", 
            "speaker": 31, 
            "submitted": "2010-12-09 15:55:35", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 271, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "pyBookBuilder is a web application for collaborative book making through the web.  It combines web2py, sphinx, bzr, and mathjax.", 
            "additional_speakers": [
                242, 
                241
            ], 
            "session_type": 4, 
            "track": null, 
            "abstract": "The [[http://openbookproject.net|Open Book Project]] has been using sphinx for several of its project for the last few years.  The goal of pyBookBuilder is to enable through the web collaboration on these projects.\r\n\r\nThis project is being developed collaboratively with a teacher/author acting as customer, a young web developer as programmer, and an experienced web developer acting as mentor.", 
            "title": "Collaborative Book Making", 
            "plenary": false, 
            "abstract_html": "<p>The <a href=\"http://openbookproject.net\">Open Book Project</a> has been using sphinx for several of its project for the last few years.  The goal of pyBookBuilder is to enable through the web collaboration on these projects.\r</p>\n<p>This project is being developed collaboratively with a teacher/author acting as customer, a young web developer as programmer, and an experienced web developer acting as mentor.</p>\n", 
            "speaker": 240, 
            "submitted": "2010-12-10 10:02:59", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 272, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "PyDas is a set of Python modules that are used to integrate various components of the Spallation Neutron Source Data Acquisition System at Oak Ridge National Laboratory, Tennessee. It is equipped with IPython command line interface as well as graphical user interface using wxPython.  ", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "The Spallation Neutron Source (SNS) at Oak Ridge National Laboratory currently holds the Guinness World Record as the world most powerful pulsed spallation neutron source. Neutrons scattered off atomic nuclei in samples yield important information about the position, motions, and magnetic properties of atoms in materials.\r\n \r\nA typical neutron scattering experiment usually involves sample environment control (temperature, pressure, etc.), mechanical alignment magnetic field controllers, and neutron velocity selection and detectors. The SNS Data Acquisition System (DAS) consists of real time subsystem (detector read-out using custom electronics), data preprocessing and a cluster of control and ancillary PCs that communicate with each other via TCP/IP. \r\n\r\nPyDas is a set of Python modules that are used to integrate various components of the SNS DAS system. It enables customized automation of neutron scattering experiments in a rapid and flexible manner. It provides IPython command line interface as well as graphical user interface using wxPython. Matplotlib and NumPy are used for data presentation and simple analysis. \r\n\r\nWe will present an overview of PyDas architecture and implementation along with the examples of use. We will also discuss plans for future development as well as the challenges that have to be met while maintaining PyDas for 20+ different scientific instruments. \r\n", 
            "title": "Running Neutron Scattering Experiments with Python", 
            "plenary": false, 
            "abstract_html": "<p>The Spallation Neutron Source (SNS) at Oak Ridge National Laboratory currently holds the Guinness World Record as the world most powerful pulsed spallation neutron source. Neutrons scattered off atomic nuclei in samples yield important information about the position, motions, and magnetic properties of atoms in materials.\r</p>\n<p>A typical neutron scattering experiment usually involves sample environment control (temperature, pressure, etc.), mechanical alignment magnetic field controllers, and neutron velocity selection and detectors. The SNS Data Acquisition System (DAS) consists of real time subsystem (detector read-out using custom electronics), data preprocessing and a cluster of control and ancillary PCs that communicate with each other via TCP/IP. \r</p>\n<p>PyDas is a set of Python modules that are used to integrate various components of the SNS DAS system. It enables customized automation of neutron scattering experiments in a rapid and flexible manner. It provides IPython command line interface as well as graphical user interface using wxPython. Matplotlib and NumPy are used for data presentation and simple analysis. \r</p>\n<p>We will present an overview of PyDas architecture and implementation along with the examples of use. We will also discuss plans for future development as well as the challenges that have to be met while maintaining PyDas for 20+ different scientific instruments. \r</p>\n", 
            "speaker": 244, 
            "submitted": "2010-12-15 10:20:20", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 273, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Python and the scientific ecosystem provide plenty of tools to ease the computation life of atmospheric scientists.  Open-source and the free nature of this ecosystem greatly facilitate reproducibility and openness in research. In this poster, the use of Python / Cython languages, NumPy, SciPy, and Matplotlib libraries, and other related tools will be demonstrated in a cloud modeling application.", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "This poster demonstrates key components of scientific data analysis  and visualization ideas that are used in a Python implementation of a cloud parcel model. We first start with dataset handling (e.g. NetCDF file reading) and fundamental array processing features of [[http://numpy.scipy.org/ | NumPy]] library (e.g. indexing, slicing, masking of arrays). Later in the analysis we demonstrate basic techniques to perform regression analysis and optimization procedures (e.g. least squares curve-fitting and numerical root solving) and statistical analysis of 1/2D data by using NumPy and [[http://scipy.org | SciPy]] libraries. Visualization examples illustrate time-series and uncertainty analysis plots (e.g. box-and-whisker and errorbar) and probability density function histograms in assessing the cloud model initialization and resulting data through [[http://matplotlib.sourceforge.net | Matplotlib]] plotting library. Code profiling and basic optimization techniques are demonstrated using [[http://cython.org/ | Cython]] compiled functions to boost code execution speed. The cloud model has a great use of [[http://ipython.scipy.org | IPython]] interactive interpreter throughout the past and on-going development, and [[http://pydev.org/ | Eclipse + PyDev]] extension have been helpful in managing the complexity of the project. Although the focus of this presentation is on a specific research area in atmospheric sciences, the analysis and visualization techniques demonstrated within the poster could easily be applied to any of the observational data driven science disciplines.", 
            "title": "Python in Atmospheric Sciences", 
            "plenary": false, 
            "abstract_html": "<p>This poster demonstrates key components of scientific data analysis  and visualization ideas that are used in a Python implementation of a cloud parcel model. We first start with dataset handling (e.g. NetCDF file reading) and fundamental array processing features of <a href=\"http://numpy.scipy.org/\">NumPy</a> library (e.g. indexing, slicing, masking of arrays). Later in the analysis we demonstrate basic techniques to perform regression analysis and optimization procedures (e.g. least squares curve-fitting and numerical root solving) and statistical analysis of 1/2D data by using NumPy and <a href=\"http://scipy.org\">SciPy</a> libraries. Visualization examples illustrate time-series and uncertainty analysis plots (e.g. box-and-whisker and errorbar) and probability density function histograms in assessing the cloud model initialization and resulting data through <a href=\"http://matplotlib.sourceforge.net\">Matplotlib</a> plotting library. Code profiling and basic optimization techniques are demonstrated using <a href=\"http://cython.org/\">Cython</a> compiled functions to boost code execution speed. The cloud model has a great use of <a href=\"http://ipython.scipy.org\">IPython</a> interactive interpreter throughout the past and on-going development, and <a href=\"http://pydev.org/\">Eclipse + PyDev</a> extension have been helpful in managing the complexity of the project. Although the focus of this presentation is on a specific research area in atmospheric sciences, the analysis and visualization techniques demonstrated within the poster could easily be applied to any of the observational data driven science disciplines.</p>\n", 
            "speaker": 245, 
            "submitted": "2010-12-15 14:50:19", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 244, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "This tutorial will teach various ways to distribute python-based computation across a cloud or cluster.  Tools covered include Pyro, Sun GridEngine. Google AppEngine, PiCloud, and Hadoop.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "**Detailed description**:\r\n\r\nDo you have computational problems that take hours, if not days, to solve? You can often distribute your work over a cluster or cloud of computers to solve the problem in only minutes.\r\n\r\nThis tutorial will teach various ways to distribute python-based computation.  Tools covered include Hadoop, Google AppEngine, Sun GridEngine, PiCloud, Hadoop, and Elastic MapReduce.\r\n\r\nAttendees should bring a laptop with Python 2.x (x>=6) installed as the tutorial is example based.\r\n\r\n**Format**: //Class//\r\n\r\n**Audience**:\r\n\r\nIntermediate level Python programmers.  While no familiarity with distributed computing is assumed, programmers should be very comfortable reading Python code.  Familiarity with scientific programming (e.g. numpy, scipy) helps but is not a must.\r\n\r\n**Class Size**: //Ideal, 20.  Up to 30//\r\n\r\n**Outline**:\r\n* Introduction to distributed computing\r\n** Types of parallelizable problems\r\n* Low-level primitives\r\n** Pyro\r\n* Job processing on own cluster\r\n** Oracle (Sun) Grid Engine\r\n* Cloud Computing Solutions\r\n** Google AppEngine\r\n** PiCloud\r\n* MapReduce for large data\r\n** Hadoop (using dumbo for python)\r\n** Elastic MapReduce (overview only)\r\n* Benchmarks showing how different problems perform on each system\r\n* Conclusion\r\n\r\n**Examples used in presentation include:**\r\n* Parallelizing Support Vector Machine training (Python's libsvm wrapper) across a hundred nodes\r\n* Determining features in brain waves using NumPy and distributed computing\r\n* Using NumPy, SciPy, and lots of computers for analyzing data from human cells.\r\n* The classic MapReduce distributed grep.\r\n", 
            "title": "Distributed and Cloud computing with Python", 
            "plenary": false, 
            "abstract_html": "<p><b>Detailed description</b>:\r</p>\n<p>Do you have computational problems that take hours, if not days, to solve? You can often distribute your work over a cluster or cloud of computers to solve the problem in only minutes.\r</p>\n<p>This tutorial will teach various ways to distribute python-based computation.  Tools covered include Hadoop, Google AppEngine, Sun GridEngine, PiCloud, Hadoop, and Elastic MapReduce.\r</p>\n<p>Attendees should bring a laptop with Python 2.x (x&gt;=6) installed as the tutorial is example based.\r</p>\n<p><b>Format</b>: <i>Class</i>\r</p>\n<p><b>Audience</b>:\r</p>\n<p>Intermediate level Python programmers.  While no familiarity with distributed computing is assumed, programmers should be very comfortable reading Python code.  Familiarity with scientific programming (e.g. numpy, scipy) helps but is not a must.\r</p>\n<p><b>Class Size</b>: <i>Ideal, 20.  Up to 30</i>\r</p>\n<p><b>Outline</b>:\r</p>\n<ul>\n<li>Introduction to distributed computing\r<ul>\n<li>Types of parallelizable problems\r</li>\n</ul>\n</li>\n<li>Low-level primitives\r<ul>\n<li>Pyro\r</li>\n</ul>\n</li>\n<li>Job processing on own cluster\r<ul>\n<li>Oracle (Sun) Grid Engine\r</li>\n</ul>\n</li>\n<li>Cloud Computing Solutions\r<ul>\n<li>Google AppEngine\r</li>\n<li>PiCloud\r</li>\n</ul>\n</li>\n<li>MapReduce for large data\r<ul>\n<li>Hadoop (using dumbo for python)\r</li>\n<li>Elastic MapReduce (overview only)\r</li>\n</ul>\n</li>\n<li>Benchmarks showing how different problems perform on each system\r</li>\n<li>Conclusion\r</li>\n</ul>\n<p><b>Examples used in presentation include:</b>\r</p>\n<ul>\n<li>Parallelizing Support Vector Machine training (Python's libsvm wrapper) across a hundred nodes\r</li>\n<li>Determining features in brain waves using NumPy and distributed computing\r</li>\n<li>Using NumPy, SciPy, and lots of computers for analyzing data from human cells.\r</li>\n<li>The classic MapReduce distributed grep.\r</li>\n</ul>\n", 
            "speaker": 202, 
            "submitted": "2010-11-02 05:08:09", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 274, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "Come join David Beazley and Brian Jones, editors of the new all-Python-3 edition of the Python Cookbook, for a fun and interactive tour through what's new in Python 3. David and Brian will walk you through the features, differences, and porting challenges that they have encountered updating the examples in the Python Cookbook to use Python 3. Got a challenge? Bring it to the tutorial, as David and Brian take on all sorts of examples through a lively mix of interactive demos, examples, and discussion. Participants should install Python 3 on their computer and plan to play along.\r\n", 
            "additional_speakers": [
                249
            ], 
            "session_type": 3, 
            "track": null, 
            "abstract": "This tutorial will start with a guided tour through the \"what's new in Python 3?\" document, with more examples motivated by our experiences working on the Python 3 Cookbook. Attendees should plan on bringing challenges for us to address - we will demonstrate the use of Python 3 to solve all manner of practical problems as suggested by the audience.", 
            "title": "Cooking with Python 3", 
            "plenary": false, 
            "abstract_html": "<p>This tutorial will start with a guided tour through the \"what's new in Python 3?\" document, with more examples motivated by our experiences working on the Python 3 Cookbook. Attendees should plan on bringing challenges for us to address - we will demonstrate the use of Python 3 to solve all manner of practical problems as suggested by the audience.</p>\n", 
            "speaker": 128, 
            "submitted": "2010-12-17 10:33:41", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 275, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "Sandia National Labs analyzes high-performance computing environments to optimize application performance, analyze system architectures, and provide design guidance for future systems. We discuss the process of using our open source GUI Python software tools, Pylot and Co-Pylot, to capture, store, analyze, and compare performance data through direct access and display of MySQL database tables.", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "As a leading entity in supercomputer development and application, Sandia National Laboratories has developed a performance analysis suite for capturing, storing, analyzing, and comparing supercomputer performance metrics. This suite consists of two Python software tools, Pylot and Co-Pylot.\r\n\r\nCo-Pylot is a relatively simple interface that enables easy batch transfer of performance data and other relevant metrics as they are generated to a remote MySQL database server for persistent storage. Once captured, the performance data can be extracted, organized, filtered, and analyzed using Pylot, a more functionally complex interface. Pylot allows the user to directly access the MySQL database table, to display the table using an intuitive GUI interface, and to present user-selected MySQL fields in a variety of views. These views include statistical data, bar and pie charts, Cartesian or log-log or semi-log plots, reference curves for comparisons, and Kiviat diagrams (also called radar charts) for multivariate datasets.\r\n\r\nIn addition, Pylot's built-in storage buffer provides the ability to store, compare, and analyze data from multiple databases, again using an intuitive GUI. This capability is critical for studying performance variations of a code running on a particular architecture, comparing application performance across architectures, or comparing multiple applications on one or more architectures, all difficult feats when using MySQL alone. Values in up to four database fields at a time can be mathematically combined to generate a new set of data for plotting and analysis while leaving the original database table intact.\r\n\r\nFurther, Pylot provides the ability to easily move MySQL databases and tables between computers/servers, including the analyst\u2019s laptop. This coherency of databases across multiple analysis platforms can be used, for example, to provide local access to databases, thus avoiding network latency issues associated with accessing remote servers. This has the additional benefit of serving as a distributed backup system for databases. ", 
            "title": "Capture, Store, Analyze, and Compare Supercomputer Performance Metrics with Python and MySQL", 
            "plenary": false, 
            "abstract_html": "<p>As a leading entity in supercomputer development and application, Sandia National Laboratories has developed a performance analysis suite for capturing, storing, analyzing, and comparing supercomputer performance metrics. This suite consists of two Python software tools, Pylot and Co-Pylot.\r</p>\n<p>Co-Pylot is a relatively simple interface that enables easy batch transfer of performance data and other relevant metrics as they are generated to a remote MySQL database server for persistent storage. Once captured, the performance data can be extracted, organized, filtered, and analyzed using Pylot, a more functionally complex interface. Pylot allows the user to directly access the MySQL database table, to display the table using an intuitive GUI interface, and to present user-selected MySQL fields in a variety of views. These views include statistical data, bar and pie charts, Cartesian or log-log or semi-log plots, reference curves for comparisons, and Kiviat diagrams (also called radar charts) for multivariate datasets.\r</p>\n<p>In addition, Pylot's built-in storage buffer provides the ability to store, compare, and analyze data from multiple databases, again using an intuitive GUI. This capability is critical for studying performance variations of a code running on a particular architecture, comparing application performance across architectures, or comparing multiple applications on one or more architectures, all difficult feats when using MySQL alone. Values in up to four database fields at a time can be mathematically combined to generate a new set of data for plotting and analysis while leaving the original database table intact.\r</p>\n<p>Further, Pylot provides the ability to easily move MySQL databases and tables between computers/servers, including the analyst\u2019s laptop. This coherency of databases across multiple analysis platforms can be used, for example, to provide local access to databases, thus avoiding network latency issues associated with accessing remote servers. This has the additional benefit of serving as a distributed backup system for databases. </p>\n", 
            "speaker": 4, 
            "submitted": "2011-01-10 00:51:33", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 276, 
        "model": "schedule.session", 
        "fields": {
            "slot": null, 
            "description": "In late 2009 SourceForge embarked on a plan to rebuild our developer tools on top of an open platform including Python, MongoDB, RabbitMQ, and Solr. The resulting platform \"Allura\" was recently released as open source software. This poster describes what you get 'out of the box' with Allura and how to extend it with your own plugin applications.", 
            "additional_speakers": [], 
            "session_type": 4, 
            "track": null, 
            "abstract": "The poster includes an overview of the Allura platform architecture. Particularly, it covers the overall project-based URL structure of an Allura installation, the offline servers required for the data model (MongoDB), messaging (RabbitMQ), search (Solr), and SCM (Git, Subversion, and Mercurial). \r\n\r\nIt will also describe the Allura plugin Application base class and the minimal fields you must override to write your plugin application. It will show how to build your MongoDB models, how to enable search, and how to set up asynchronous processing over RabbitMQ.  This will be illustrated with the built-in Allura IRC chat application to show just how easy it can be to write your own plugin.\r\n", 
            "title": "Using the Allura Platform to Create Your Own Forge  ", 
            "plenary": false, 
            "abstract_html": "<p>The poster includes an overview of the Allura platform architecture. Particularly, it covers the overall project-based URL structure of an Allura installation, the offline servers required for the data model (MongoDB), messaging (RabbitMQ), search (Solr), and SCM (Git, Subversion, and Mercurial). \r</p>\n<p>It will also describe the Allura plugin Application base class and the minimal fields you must override to write your plugin application. It will show how to build your MongoDB models, how to enable search, and how to set up asynchronous processing over RabbitMQ.  This will be illustrated with the built-in Allura IRC chat application to show just how easy it can be to write your own plugin.\r</p>\n", 
            "speaker": 141, 
            "submitted": "2011-01-12 14:28:56", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 108, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "This teaches the basics of Python for beginning and intermediate software developers.  It is best paired with Python 102.  Most of the material is presented with the interactive interpreter shell instead of starting with a \"Hello, world!\" program.  Each 10-15 minute section is a demonstration followed by hands-on exercises, some of which are meaty enough to keep advanced participants interested.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "==== Intended Audience\r\n\r\nSoftware developers with experience in other languages who want a fast\r\nhands-on introduction to basic features of Python.  Part 1 of the\r\n//Python 101, 102// full-day tutorial.  This tutorial can be taken\r\nwithout //Python 102//.\r\n\r\n==== Tutorial Format\r\n\r\nHands-on with frequently alternating presentation of concepts and\r\nexercise sets.  Each pair of concepts and exercises ranges in length\r\nfrom 5 to 15 minutes.\r\n\r\nThe tutorial will target Python 2.7, including features back-ported\r\nfrom Python 3, with explanations of differences from Python 3.\r\n\r\n==== Attendee Requirements\r\n\r\nBring a laptop computer with Python 2.7 installed.\r\n\r\n==== Prerequisites\r\n\r\nAt least beginning to intermediate ability in any programming\r\nlanguage.  Self-study before the tutorial will increase your learning,\r\nfor example the Python website's tutorial at\r\n[[http://docs.python.org/tut/tut.html]].\r\n\r\n=== Course Outline\r\n\r\n* Numbers and Operators\r\n* Strings\r\n* Introspection/Discovery\r\n* Tuples and Lists\r\n* Sets\r\n* Dictionaries\r\n* List Comprehensions\r\n* Objects and Names\r\n* Loops and Blocks\r\n* Iterators\r\n* Generator Expressions\r\n* Functions\r\n* Generators\r\n* Namespaces\r\n* Simple Classes\r\n* Exceptions\r\n\r\n==== Preview\r\n\r\nI gave a similar tutorial at PyCon 2010 for which the video is\r\navailable -- see\r\nhttp://us.pycon.org/2010/tutorials/williams_python101/\r\n\r\nIf you're not sure about signing up for this tutorial, take a look at\r\nthe video to help you decide, or grab the handouts and watch that\r\nvideo instead of taking this tutorial.\r\n", 
            "title": "Python 101", 
            "plenary": false, 
            "abstract_html": "<h4>Intended Audience</h4>\n<p>Software developers with experience in other languages who want a fast\r hands-on introduction to basic features of Python.  Part 1 of the\r <i>Python 101, 102</i> full-day tutorial.  This tutorial can be taken\r without <i>Python 102</i>.\r</p>\n<h4>Tutorial Format</h4>\n<p>Hands-on with frequently alternating presentation of concepts and\r exercise sets.  Each pair of concepts and exercises ranges in length\r from 5 to 15 minutes.\r</p>\n<p>The tutorial will target Python 2.7, including features back-ported\r from Python 3, with explanations of differences from Python 3.\r</p>\n<h4>Attendee Requirements</h4>\n<p>Bring a laptop computer with Python 2.7 installed.\r</p>\n<h4>Prerequisites</h4>\n<p>At least beginning to intermediate ability in any programming\r language.  Self-study before the tutorial will increase your learning,\r for example the Python website's tutorial at\r <a href=\"http://docs.python.org/tut/tut.html\">http://docs.python.org/tut/tut.html</a>.\r</p>\n<h3>Course Outline</h3>\n<ul>\n<li>Numbers and Operators\r</li>\n<li>Strings\r</li>\n<li>Introspection/Discovery\r</li>\n<li>Tuples and Lists\r</li>\n<li>Sets\r</li>\n<li>Dictionaries\r</li>\n<li>List Comprehensions\r</li>\n<li>Objects and Names\r</li>\n<li>Loops and Blocks\r</li>\n<li>Iterators\r</li>\n<li>Generator Expressions\r</li>\n<li>Functions\r</li>\n<li>Generators\r</li>\n<li>Namespaces\r</li>\n<li>Simple Classes\r</li>\n<li>Exceptions\r</li>\n</ul>\n<h4>Preview</h4>\n<p>I gave a similar tutorial at PyCon 2010 for which the video is\r available -- see\r <a href=\"http://us.pycon.org/2010/tutorials/williams_python101/\">http://us.pycon.org/2010/tutorials/williams_python101/</a>\r</p>\n<p>If you're not sure about signing up for this tutorial, take a look at\r the video to help you decide, or grab the handouts and watch that\r video instead of taking this tutorial.\r</p>\n", 
            "speaker": 137, 
            "submitted": "2010-10-30 17:08:01", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 26, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "We will provide an introduction to web2py with particular focus on its design objectives, its differences when compared to other web frameworks, and some of the most recently added features (components, plugins, openid/oauth integration).", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "Web2py is a framework for rapid web application development of secure database-driven web applications. In this tutorial we will provide a brief introduction to web2py, the web based IDE, its internal design, and its internal file organization. We will explain the motivations behind some of its most controversial design goals. We will also discuss in some detail its Ajax capabilities by using web2py components and plugins for modular design of rich web interfaces.\r\n\r\nThis will be a very concentrated version (10%) of a course (CSC438) on web frameworks the author teaches at DePaul University. The course has been taught 3 times and the last time counted more than 30 students.", 
            "title": "web2py secrets", 
            "plenary": false, 
            "abstract_html": "<p>Web2py is a framework for rapid web application development of secure database-driven web applications. In this tutorial we will provide a brief introduction to web2py, the web based IDE, its internal design, and its internal file organization. We will explain the motivations behind some of its most controversial design goals. We will also discuss in some detail its Ajax capabilities by using web2py components and plugins for modular design of rich web interfaces.\r</p>\n<p>This will be a very concentrated version (10%) of a course (CSC438) on web frameworks the author teaches at DePaul University. The course has been taught 3 times and the last time counted more than 30 students.</p>\n", 
            "speaker": 53, 
            "submitted": "2010-10-15 16:29:40", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 164, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "Python provides numerous tools for scientific and engineering applications. \r\nThis is an overview of the most widely used libraries including NumPy,\r\nmatplotlib and tools for interfacing with C/FORTRAN. They are not only useful\r\nfor scientists and engineers but also for programmers who need to do number\r\ncrunching, simple yet powerful plotting of diagrams or interfacing with\r\ncompiled languages.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "= Intended Audience =\r\n\r\nPython programmers with intermediate knowledge. Scientists and engineers with a good working knowledge of Python.\r\n\r\n= Tutorial Format =\r\n\r\n**Lecture/Class**\r\n\r\nThis tutorial is a mixture of lecture and class. Since it is designed as an overview and therefore covers a great many different tools, we cannot go too much into details. Students can work along but there is not enough time to do in-class excerices. They have to be done as homework.\r\n\r\nAll source codes are provided on CD before the course. There is a comprehensive handout detailing all presented topics including in-depth discussions of all code examples. This should enable the students to complete the exerceise on their own.\r\n\r\n= Class Size =\r\n\r\nThis is in a combined lecture/class format and will work with a larger crowd. Parts of t were presented at EuroSciPy 2010 in Paris to about 50+ people without problems.\r\n\r\n\r\n= Requirements =\r\n\r\nAll participants should bring laptops with Linux, Windows, or Mac OS. Python 2.6 or 2.5 (2.7 might work in March) as well as an editor or IDE will need to be installed .\r\n\r\nThe following third-party packages are needed:\r\n\r\n* [[http://numpy.scipy.org|NumPy]] (version 1.3 or higher)\r\n* [[http://matplotlib.sourceforge.net|matplotlib]] (version 1.0 or higher)\r\n* [[http://ipython.scipy.org/moin|IPython]] (version 0.10 or higher)\r\n* [[http://www.cython.org|Cython]] (version 0.13 or higher)\r\n* C and FORTRAN compiler (e.g. GCC and gfortran)\r\n\r\n\r\n== Windows users ==\r\n\r\nThe [[http://www.pythonxy.com|Python(x,y)]] distribution contains all packages listed above including the compilers and makes installation very simple.\r\n\r\nIf you have the Entough Python Distribution ([[http://www.enthought.com/products/epd.php|EPD]]) installed you should also be all set.\r\n\r\n== Testscript ==\r\n\r\nA test script will be provided by the instructor. If it runs through without complaining all necessary packages are installed. Otherwise it will prompt to install the missing package(s).\r\n\r\n= Notes for Reviewers =\r\n\r\nThis tutorial is based on my three-day course \"Python for Scientists and Engineers\". I've been teaching this course since 2008 several times a year both as an open course as well as major parts of it incorporated in on-site courses for companies and research institutes.\r\n\r\nUnlike the course that goes quite into detail and has exercise for all major topics, the tutorial focuses on the main concepts teaching the students what each library is good for with some typical examples.\r\n\r\nParts of this tutorial have been given at EuroSciPy 2010 in Paris, France.\r\n\r\n\r\n= Outline for Review =\r\n\r\n* Science and Python (15 min)\r\n** Short history of scientific tools in Python + Scientific Python + Numeric\r\n** Examples for scientfic users\r\n** Overview of some current tools\r\n* NumPy (45 min)\r\n** **The** array processing package\r\n** Array construction\r\n** Indexing and slicing\r\n** Broadcasting\r\n** Universal functions\r\n* SciPy (15 min)\r\n** Overview of packages\r\n* matplotlib (30 min)\r\n** pylab and IPython\r\n** Simple plots\r\n** Properties\r\n** Text and ticks\r\n** Figures, subplots and axes\r\n** Types of plots\r\n* Working with external processes (20 min)\r\n** Generating input\r\n** Starting processes\r\n** Reading output\r\n* Extending Python with C and FORTRAN (55 min)\r\n** ctypes\r\n** Cython\r\n** f2py\r\n*** F90 module data\r\n*** Callbacks\r\n*** Modules\r\n\r\n\r\n= Outline for Website =\r\n\r\n* Science and Python\r\n** Short history of scientific tools in Python\r\n*** Scientific Python\r\n*** Numeric\r\n** Examples for scientfic users\r\n** Overview of some current tools\r\n* NumPy\r\n** **The** array processing package\r\n** Array construction\r\n** Indexing and slicing\r\n** Broadcasting\r\n** Universal functions\r\n* SciPy\r\n** Overview of packages\r\n* matplotlib\r\n** pylab and IPython\r\n** Simple plots\r\n** Properties\r\n** Text and ticks\r\n** Figures, subplots and axes\r\n** Types of plots\r\n* Working with external processes\r\n** Generating input\r\n** Starting processes\r\n** Reading output\r\n* Extending Python with C and FORTRAN\r\n** ctypes\r\n** Cython\r\n** f2py\r\n*** F90 module data\r\n*** Callbacks\r\n*** Modules", 
            "title": "Scientific Python Tools not only for Scientists and Engineers", 
            "plenary": false, 
            "abstract_html": "<h1>Intended Audience</h1>\n<p>Python programmers with intermediate knowledge. Scientists and engineers with a good working knowledge of Python.\r</p>\n<h1>Tutorial Format</h1>\n<p><b>Lecture/Class</b>\r</p>\n<p>This tutorial is a mixture of lecture and class. Since it is designed as an overview and therefore covers a great many different tools, we cannot go too much into details. Students can work along but there is not enough time to do in-class excerices. They have to be done as homework.\r</p>\n<p>All source codes are provided on CD before the course. There is a comprehensive handout detailing all presented topics including in-depth discussions of all code examples. This should enable the students to complete the exerceise on their own.\r</p>\n<h1>Class Size</h1>\n<p>This is in a combined lecture/class format and will work with a larger crowd. Parts of t were presented at EuroSciPy 2010 in Paris to about 50+ people without problems.\r</p>\n<h1>Requirements</h1>\n<p>All participants should bring laptops with Linux, Windows, or Mac OS. Python 2.6 or 2.5 (2.7 might work in March) as well as an editor or IDE will need to be installed .\r</p>\n<p>The following third-party packages are needed:\r</p>\n<ul>\n<li><a href=\"http://numpy.scipy.org\">NumPy</a> (version 1.3 or higher)\r</li>\n<li><a href=\"http://matplotlib.sourceforge.net\">matplotlib</a> (version 1.0 or higher)\r</li>\n<li><a href=\"http://ipython.scipy.org/moin\">IPython</a> (version 0.10 or higher)\r</li>\n<li><a href=\"http://www.cython.org\">Cython</a> (version 0.13 or higher)\r</li>\n<li>C and FORTRAN compiler (e.g. GCC and gfortran)\r</li>\n</ul>\n<h2>Windows users</h2>\n<p>The <a href=\"http://www.pythonxy.com\">Python(x,y)</a> distribution contains all packages listed above including the compilers and makes installation very simple.\r</p>\n<p>If you have the Entough Python Distribution (<a href=\"http://www.enthought.com/products/epd.php\">EPD</a>) installed you should also be all set.\r</p>\n<h2>Testscript</h2>\n<p>A test script will be provided by the instructor. If it runs through without complaining all necessary packages are installed. Otherwise it will prompt to install the missing package(s).\r</p>\n<h1>Notes for Reviewers</h1>\n<p>This tutorial is based on my three-day course \"Python for Scientists and Engineers\". I've been teaching this course since 2008 several times a year both as an open course as well as major parts of it incorporated in on-site courses for companies and research institutes.\r</p>\n<p>Unlike the course that goes quite into detail and has exercise for all major topics, the tutorial focuses on the main concepts teaching the students what each library is good for with some typical examples.\r</p>\n<p>Parts of this tutorial have been given at EuroSciPy 2010 in Paris, France.\r</p>\n<h1>Outline for Review</h1>\n<ul>\n<li>Science and Python (15 min)\r<ul>\n<li>Short history of scientific tools in Python + Scientific Python + Numeric\r</li>\n<li>Examples for scientfic users\r</li>\n<li>Overview of some current tools\r</li>\n</ul>\n</li>\n<li>NumPy (45 min)\r<ul>\n<li><b>The</b> array processing package\r</li>\n<li>Array construction\r</li>\n<li>Indexing and slicing\r</li>\n<li>Broadcasting\r</li>\n<li>Universal functions\r</li>\n</ul>\n</li>\n<li>SciPy (15 min)\r<ul>\n<li>Overview of packages\r</li>\n</ul>\n</li>\n<li>matplotlib (30 min)\r<ul>\n<li>pylab and IPython\r</li>\n<li>Simple plots\r</li>\n<li>Properties\r</li>\n<li>Text and ticks\r</li>\n<li>Figures, subplots and axes\r</li>\n<li>Types of plots\r</li>\n</ul>\n</li>\n<li>Working with external processes (20 min)\r<ul>\n<li>Generating input\r</li>\n<li>Starting processes\r</li>\n<li>Reading output\r</li>\n</ul>\n</li>\n<li>Extending Python with C and FORTRAN (55 min)\r<ul>\n<li>ctypes\r</li>\n<li>Cython\r</li>\n<li>f2py\r<ul>\n<li>F90 module data\r</li>\n<li>Callbacks\r</li>\n<li>Modules\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h1>Outline for Website</h1>\n<ul>\n<li>Science and Python\r<ul>\n<li>Short history of scientific tools in Python\r<ul>\n<li>Scientific Python\r</li>\n<li>Numeric\r</li>\n</ul>\n</li>\n<li>Examples for scientfic users\r</li>\n<li>Overview of some current tools\r</li>\n</ul>\n</li>\n<li>NumPy\r<ul>\n<li><b>The</b> array processing package\r</li>\n<li>Array construction\r</li>\n<li>Indexing and slicing\r</li>\n<li>Broadcasting\r</li>\n<li>Universal functions\r</li>\n</ul>\n</li>\n<li>SciPy\r<ul>\n<li>Overview of packages\r</li>\n</ul>\n</li>\n<li>matplotlib\r<ul>\n<li>pylab and IPython\r</li>\n<li>Simple plots\r</li>\n<li>Properties\r</li>\n<li>Text and ticks\r</li>\n<li>Figures, subplots and axes\r</li>\n<li>Types of plots\r</li>\n</ul>\n</li>\n<li>Working with external processes\r<ul>\n<li>Generating input\r</li>\n<li>Starting processes\r</li>\n<li>Reading output\r</li>\n</ul>\n</li>\n<li>Extending Python with C and FORTRAN\r<ul>\n<li>ctypes\r</li>\n<li>Cython\r</li>\n<li>f2py\r<ul>\n<li>F90 module data\r</li>\n<li>Callbacks\r</li>\n<li>Modules</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n", 
            "speaker": 135, 
            "submitted": "2010-11-01 06:12:13", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 64, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "This tutorial covers subjects of how the vector data becomes a set of raster tiles you actually see when using web map providers (such as Google Maps, Bing Maps, Mapquest and others), what is map projection and how it changes the look of the map, why WMS is hard and why one should probably not try to implement it.\r\nIn general, this tutorial will try to explain how the map is created.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "* Explain what OpenStreetMap is and how to use data produced by OSM\r\n* Explain basics of map rendering -- layers, basic map projections, data organization, data type, etc\r\n* Import OpenStreetMap data using Python\r\n* Prepare data for GIS usage\r\n* Create basic Mapnik style with Python\r\n* Render map with Mapnik\r\n* Explain why most web map services organize raster data in tiles\r\n* Short reference to WMS and why is it not widely used in most popular web map providers (Google, Bing, Mapquest)\r\n* Render tiled map\r\n* Create basic web service with simple tile access scheme\r\n* Create staticmaps service based on tiles service", 
            "title": "Building your own tile server using OpenStreetMap", 
            "plenary": false, 
            "abstract_html": "<ul>\n<li>Explain what OpenStreetMap is and how to use data produced by OSM\r</li>\n<li>Explain basics of map rendering -- layers, basic map projections, data organization, data type, etc\r</li>\n<li>Import OpenStreetMap data using Python\r</li>\n<li>Prepare data for GIS usage\r</li>\n<li>Create basic Mapnik style with Python\r</li>\n<li>Render map with Mapnik\r</li>\n<li>Explain why most web map services organize raster data in tiles\r</li>\n<li>Short reference to WMS and why is it not widely used in most popular web map providers (Google, Bing, Mapquest)\r</li>\n<li>Render tiled map\r</li>\n<li>Create basic web service with simple tile access scheme\r</li>\n<li>Create staticmaps service based on tiles service</li>\n</ul>\n", 
            "speaker": 98, 
            "submitted": "2010-10-27 16:12:37", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 259, 
        "model": "schedule.session", 
        "fields": {
            "slot": 1, 
            "description": "Have your Python skills have hit a plateau? Come learn from Python core \r\ndeveloper and consultant Raymond Hettinger about the tips and tricks \r\nneeded to move up to the next level. ", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "This tutorial will work through a series of real-world examples, showing how an understanding of the tools built \r\ninto the Python interpreter or included in the standard library can be combined to solve difficult problems clearly and Pythonically. We will also discuss when and how to reach beyond the standard library when needed to address difficult algorithmic and optimization problems. This can be taken as a stand-alone session or in conjunction with the second session; the two sessions will be complementary.", 
            "title": "Advanced Python I", 
            "plenary": false, 
            "abstract_html": "<p>This tutorial will work through a series of real-world examples, showing how an understanding of the tools built \r into the Python interpreter or included in the standard library can be combined to solve difficult problems clearly and Pythonically. We will also discuss when and how to reach beyond the standard library when needed to address difficult algorithmic and optimization problems. This can be taken as a stand-alone session or in conjunction with the second session; the two sessions will be complementary.</p>\n", 
            "speaker": 131, 
            "submitted": "2010-11-04 02:58:16", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 99, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "I will teach a group of complete Python and/or programming beginners using material from my book \"Learn Python The Hard Way\".  The class will be lab style with direct guidance from me.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "I will take a group of total beginners to Python and/or programming and teach them using my book \"Learn Python The Hard Way\" found at http://learnpythonthehardway.org/.  This will be a guided lab style of class where you go through the exercises in the book and I help you with each one.  The goal is to get through as much of the book as possible by the end of the class.", 
            "title": "Python For Total Beginners Using \"Learn Python The Hard Way\"", 
            "plenary": false, 
            "abstract_html": "<p>I will take a group of total beginners to Python and/or programming and teach them using my book \"Learn Python The Hard Way\" found at <a href=\"http://learnpythonthehardway.org/\">http://learnpythonthehardway.org/</a>.  This will be a guided lab style of class where you go through the exercises in the book and I help you with each one.  The goal is to get through as much of the book as possible by the end of the class.</p>\n", 
            "speaker": 138, 
            "submitted": "2010-10-30 13:06:52", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 260, 
        "model": "schedule.session", 
        "fields": {
            "slot": 2, 
            "description": "Have your Python skills have hit a plateau? Come learn from Python core \r\ndeveloper and consultant Raymond Hettinger about the tips and tricks \r\nneeded to move up to the next level. ", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "This tutorial will work through a series of real-world examples, showing how an understanding of the tools built \r\ninto the Python interpreter or included in the standard library can be combined to solve difficult problems clearly and Pythonically. We will also discuss when and how to reach beyond the standard library when needed to address difficult algorithmic and optimization problems. This can be taken as a stand-alone session or in conjunction with the second session; the two sessions will be complementary.", 
            "title": "Advanced Python II", 
            "plenary": false, 
            "abstract_html": "<p>This tutorial will work through a series of real-world examples, showing how an understanding of the tools built \r into the Python interpreter or included in the standard library can be combined to solve difficult problems clearly and Pythonically. We will also discuss when and how to reach beyond the standard library when needed to address difficult algorithmic and optimization problems. This can be taken as a stand-alone session or in conjunction with the second session; the two sessions will be complementary.</p>\n", 
            "speaker": 131, 
            "submitted": "2010-11-04 03:11:51", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 117, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "We're going to mesh TDD, a desire to learn Python and Brazilian BBQ. Bring your laptop (having Python 2.x installed (will note 3.x differences)). This is hands on! You will program!  It is assumed that you know how to program but perhaps not in Python.  You start hungry and leave stuffed. We assume you know nothing and will stuff you with enough Python to be dangerous.\r\n\r\n", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "The tutorial works like this: There's a short presentation. A short testcase for you to complete.  Rinse/repeat until we run out of time. Hopefully you'll walk away from this tutorial knowing how to write Python programs.\r\n\r\nCourse will cover:\r\n\r\n* REPL\r\n* Types\r\n* Mutable/Immutable\r\n* Getting help\r\n* Lists\r\n* Dictionaries\r\n* Functions\r\n* Whitespace\r\n* Conditionals & booleans\r\n* Iteration\r\n* Slicing\r\n* I/O\r\n* Classes\r\n* Exceptions\r\n* Packaging and layout\r\n\r\nThere are short testcases to allow participants to practice concepts.\r\n\r\nIncluded are slides, code for assignments a handout and prizes for completion of assignments.", 
            "title": "Hands on Beginning Python", 
            "plenary": false, 
            "abstract_html": "<p>The tutorial works like this: There's a short presentation. A short testcase for you to complete.  Rinse/repeat until we run out of time. Hopefully you'll walk away from this tutorial knowing how to write Python programs.\r</p>\n<p>Course will cover:\r</p>\n<ul>\n<li>REPL\r</li>\n<li>Types\r</li>\n<li>Mutable/Immutable\r</li>\n<li>Getting help\r</li>\n<li>Lists\r</li>\n<li>Dictionaries\r</li>\n<li>Functions\r</li>\n<li>Whitespace\r</li>\n<li>Conditionals &amp; booleans\r</li>\n<li>Iteration\r</li>\n<li>Slicing\r</li>\n<li>I/O\r</li>\n<li>Classes\r</li>\n<li>Exceptions\r</li>\n<li>Packaging and layout\r</li>\n</ul>\n<p>There are short testcases to allow participants to practice concepts.\r</p>\n<p>Included are slides, code for assignments a handout and prizes for completion of assignments.</p>\n", 
            "speaker": 150, 
            "submitted": "2010-10-31 00:09:15", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 187, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "The goal of this tutorial is to give the attendee a first experience of machine learning tools applied to practical software engineering tasks such as language detection of tweets, topic classification of web pages, sentiment analysis of customer products reviews and facial recognition in pictures from the web or from your own webcam.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "The demand for software engineers with Data Analytics and Machine Learning skills is [[ http://www.indeed.com/jobtrends?q=machine+learning%2C+data+analytics&relative=1|rapidly growing]] and python / numpy is one of the best environment for quickly prototyping scalable data-centric applications. \r\n\r\n[[http://scikit-learn.sourceforge.net|scikit-learn]] is a very active open source project that implements a variety of state-of-the art machine learning algorithms. The goal of this project and tutorial is to take the algorithms out of the academic papers and make them work on a selection of real world tasks to unleash the value of your data.\r\n\r\nWe will focus providing hints to perform the right data preprocessing steps and how select the right algorithm and parameters. We will also introduce tools and methodologies to measure the performance of the trained models as objectively as possible.\r\n\r\nPrior experience with standard file processing in python (parsing HTML, json, ...) and numerical computation with numpy is highly recommended. An undergrad level in maths will help gain some theoretical insights but is not required to go through the exercises.", 
            "title": "Applied machine learning in python with scikit-learn", 
            "plenary": false, 
            "abstract_html": "<p>The demand for software engineers with Data Analytics and Machine Learning skills is <a href=\" http://www.indeed.com/jobtrends?q=machine+learning%2C+data+analytics&amp;relative=1\">rapidly growing</a> and python / numpy is one of the best environment for quickly prototyping scalable data-centric applications. \r</p>\n<p><a href=\"http://scikit-learn.sourceforge.net\">scikit-learn</a> is a very active open source project that implements a variety of state-of-the art machine learning algorithms. The goal of this project and tutorial is to take the algorithms out of the academic papers and make them work on a selection of real world tasks to unleash the value of your data.\r</p>\n<p>We will focus providing hints to perform the right data preprocessing steps and how select the right algorithm and parameters. We will also introduce tools and methodologies to measure the performance of the trained models as objectively as possible.\r</p>\n<p>Prior experience with standard file processing in python (parsing HTML, json, ...) and numerical computation with numpy is highly recommended. An undergrad level in maths will help gain some theoretical insights but is not required to go through the exercises.</p>\n", 
            "speaker": 189, 
            "submitted": "2010-11-01 16:43:55", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 47, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "Although Python offers a wide variety of Data Structures not normally found in other programming languages, it lacks several that the user may need. This tutorial will cover the stack, the queue, binary search trees, and the priority queue -- how to build them, navigate them, the operations that can be performed using them, and when to use them.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "This tutorial will cover the stack (actually built-in), the standard queue, linked-lists, binary search trees (two ways), and the priority queue -- how to build them, navigate them, and operations that can be performed using them. The tutorial will also discuss pro's and con's of these structures including complexity theory which is a measure of how fast an operation will run with millions of items.\r\n\r\nThe tutorial will have some lecture with small examples of various Data Structures focusing on the structures that use the list (array) and then continue into the ones requiring the dynamic memory elements common to current languages. Participants will be designing classes to implement these Data Structures.\r\n\r\nAudience: Individuals interested in learning about some common Data Structures (and some not so common) in Python. The tutorial will be in Python version 2.7. Students should be familiar with creating a class and know about recursion. No prior math level required, the complexity theory necessary for the pro's and con's part will be taught during the tutorial. Note: Complexity Theory sounds like a difficult topic, it is not.  It is easy to use and understand. Everything should be usable in Python 3.x.", 
            "title": "Tutorial -- Doing Data Structures in Python", 
            "plenary": false, 
            "abstract_html": "<p>This tutorial will cover the stack (actually built-in), the standard queue, linked-lists, binary search trees (two ways), and the priority queue -- how to build them, navigate them, and operations that can be performed using them. The tutorial will also discuss pro's and con's of these structures including complexity theory which is a measure of how fast an operation will run with millions of items.\r</p>\n<p>The tutorial will have some lecture with small examples of various Data Structures focusing on the structures that use the list (array) and then continue into the ones requiring the dynamic memory elements common to current languages. Participants will be designing classes to implement these Data Structures.\r</p>\n<p>Audience: Individuals interested in learning about some common Data Structures (and some not so common) in Python. The tutorial will be in Python version 2.7. Students should be familiar with creating a class and know about recursion. No prior math level required, the complexity theory necessary for the pro's and con's part will be taught during the tutorial. Note: Complexity Theory sounds like a difficult topic, it is not.  It is easy to use and understand. Everything should be usable in Python 3.x.</p>\n", 
            "speaker": 73, 
            "submitted": "2010-10-25 19:34:41", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 141, 
        "model": "schedule.session", 
        "fields": {
            "slot": 3, 
            "description": "While Python is great for many things, C is still the lingua franca of the programming world. Whether you need to rewrite that critical loop or you want to get involved in CPython development, knowing the basics of C is an important skill for even the most hardened of Python coders. Over the course of this tutorial we will go over the basics of C and where Python programmers may get tripped up.", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "* Introduction (10 minutes)\r\n* Environment setup (10 minutes)\r\n** gcc basics\r\n** Check for make\r\n* Types (10 minutes)\r\n** int, char, float\r\n** unsigned keyword\r\n** pointers\r\n*** void*\r\n** arrays\r\n** strings\r\n*** char*\r\n*** char[]\r\n** structs\r\n*** unions\r\n** enums\r\n* Writing a function (10 minutes)\r\n** Function signatures\r\n*** void\r\n** Semicolon, semicolon, semicolon\r\n** Declare variables at the top\r\n** return()\r\n** ints all the way down\r\n** int main(int argc, char {{{**}}}argv)\r\n* Exercise 1 (10 minutes)\r\n** Quick overview of printf\r\n** gcc -o\r\n** Start with hello world\r\n** Extend to ./ex1 name --> \"Hello name\"\r\n* Blocks (10 minutes)\r\n** if, while (same as Python, just mention for syntax)\r\n** for\r\n** do/while\r\n** \"simple\" blocks \r\n* Exercise 2 (10 minutes)\r\n** ./ex2 hello --> \"Hello world\"\r\n** ./ex2 list a b c --> \"a\\nb\\nc\\n\"\r\n** Use both if and for\r\n*** Confirm understanding of C-style for loops\r\n* Preprocessor (5 minutes)\r\n** #include\r\n*** \"\" vs. <>\r\n*** <stdio> vs. <stdio.h>\r\n** #define\r\n*** #ifdef, #if\r\n** #pragma once\r\n* Headers (5 minute)\r\n** How to declare a function\r\n** Forward definitions\r\n*** Enums\r\n* Exercise 3 (10 minutes)\r\n** Must use multiple files\r\n** ./ex3 10 --> \"2 3 5 7\"\r\n** ./ex3 5 13 --> \"5 7 11\"\r\n* Break (15 minutes)\r\n* The compiler process (10 minutes)\r\n** Preprocess\r\n*** gcc -D\r\n*** gcc -I\r\n** Compile\r\n*** Assemble\r\n*** gcc -c\r\n** Link\r\n*** gcc -l\r\n*** gcc -L\r\n* make basics (15 minutes)\r\n** Basic targets\r\n** Dependencies\r\n** Macros\r\n** Suffix targets\r\n* Exercise 4 (10 minutes)\r\n** Create a makefile for ex3\r\n* Useful functions (20 minutes)\r\n** printf()\r\n*** %s, %i, %d, %f\r\n** string.h\r\n*** strlen()\r\n*** strcpy() vs. strncpy()\r\n*** strncmp()\r\n** malloc()/free()\r\n*** sizeof()\r\n*** calloc()\r\n*** realloc()\r\n** memcpy(), memmove()\r\n** stdio.h\r\n*** fopen()\r\n*** FILE*\r\n*** fread()\r\n*** fwrite()\r\n*** fgets()\r\n*** fclose()\r\n*** snprintf()\r\n*** fprintf()\r\n** stdint.h\r\n*** int32_t\r\n*** uint64_t\r\n** math.h\r\n*** import math\r\n*** M_PI, M_E\r\n** stdlib.h\r\n*** atoi(), atof(), strtol()\r\n*** random()\r\n*** exit()\r\n*** system()\r\n*** qsort()\r\n**** Comparator functions\r\n*** abs() (not in math.h)\r\n*** NULL\r\n*** size_t\r\n* Runtimes (5 minutes)\r\n** GLib\r\n** Python\r\n*** C extensions, give some links\r\n** C++\r\n*** STL\r\n*** Boost\r\n*** QtCore\r\n*** wxBase\r\n", 
            "title": "(Re-)Introduction to C for Pythonistas", 
            "plenary": false, 
            "abstract_html": "<ul>\n<li>Introduction (10 minutes)\r</li>\n<li>Environment setup (10 minutes)\r<ul>\n<li>gcc basics\r</li>\n<li>Check for make\r</li>\n</ul>\n</li>\n<li>Types (10 minutes)\r<ul>\n<li>int, char, float\r</li>\n<li>unsigned keyword\r</li>\n<li>pointers\r<ul>\n<li>void*\r</li>\n</ul>\n</li>\n<li>arrays\r</li>\n<li>strings\r<ul>\n<li>char*\r</li>\n<li>char[]\r</li>\n</ul>\n</li>\n<li>structs\r<ul>\n<li>unions\r</li>\n</ul>\n</li>\n<li>enums\r</li>\n</ul>\n</li>\n<li>Writing a function (10 minutes)\r<ul>\n<li>Function signatures\r<ul>\n<li>void\r</li>\n</ul>\n</li>\n<li>Semicolon, semicolon, semicolon\r</li>\n<li>Declare variables at the top\r</li>\n<li>return()\r</li>\n<li>ints all the way down\r</li>\n<li>int main(int argc, char <tt>**</tt>argv)\r</li>\n</ul>\n</li>\n<li>Exercise 1 (10 minutes)\r<ul>\n<li>Quick overview of printf\r</li>\n<li>gcc -o\r</li>\n<li>Start with hello world\r</li>\n<li>Extend to ./ex1 name --&gt; \"Hello name\"\r</li>\n</ul>\n</li>\n<li>Blocks (10 minutes)\r<ul>\n<li>if, while (same as Python, just mention for syntax)\r</li>\n<li>for\r</li>\n<li>do/while\r</li>\n<li>\"simple\" blocks \r</li>\n</ul>\n</li>\n<li>Exercise 2 (10 minutes)\r<ul>\n<li>./ex2 hello --&gt; \"Hello world\"\r</li>\n<li>./ex2 list a b c --&gt; \"a\\nb\\nc\\n\"\r</li>\n<li>Use both if and for\r<ul>\n<li>Confirm understanding of C-style for loops\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Preprocessor (5 minutes)\r<ul>\n<li>#include\r<ul>\n<li>\"\" vs. &lt;&gt;\r</li>\n<li>&lt;stdio&gt; vs. &lt;stdio.h&gt;\r</li>\n</ul>\n</li>\n<li>#define\r<ul>\n<li>#ifdef, #if\r</li>\n</ul>\n</li>\n<li>#pragma once\r</li>\n</ul>\n</li>\n<li>Headers (5 minute)\r<ul>\n<li>How to declare a function\r</li>\n<li>Forward definitions\r<ul>\n<li>Enums\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Exercise 3 (10 minutes)\r<ul>\n<li>Must use multiple files\r</li>\n<li>./ex3 10 --&gt; \"2 3 5 7\"\r</li>\n<li>./ex3 5 13 --&gt; \"5 7 11\"\r</li>\n</ul>\n</li>\n<li>Break (15 minutes)\r</li>\n<li>The compiler process (10 minutes)\r<ul>\n<li>Preprocess\r<ul>\n<li>gcc -D\r</li>\n<li>gcc -I\r</li>\n</ul>\n</li>\n<li>Compile\r<ul>\n<li>Assemble\r</li>\n<li>gcc -c\r</li>\n</ul>\n</li>\n<li>Link\r<ul>\n<li>gcc -l\r</li>\n<li>gcc -L\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>make basics (15 minutes)\r<ul>\n<li>Basic targets\r</li>\n<li>Dependencies\r</li>\n<li>Macros\r</li>\n<li>Suffix targets\r</li>\n</ul>\n</li>\n<li>Exercise 4 (10 minutes)\r<ul>\n<li>Create a makefile for ex3\r</li>\n</ul>\n</li>\n<li>Useful functions (20 minutes)\r<ul>\n<li>printf()\r<ul>\n<li>%s, %i, %d, %f\r</li>\n</ul>\n</li>\n<li>string.h\r<ul>\n<li>strlen()\r</li>\n<li>strcpy() vs. strncpy()\r</li>\n<li>strncmp()\r</li>\n</ul>\n</li>\n<li>malloc()/free()\r<ul>\n<li>sizeof()\r</li>\n<li>calloc()\r</li>\n<li>realloc()\r</li>\n</ul>\n</li>\n<li>memcpy(), memmove()\r</li>\n<li>stdio.h\r<ul>\n<li>fopen()\r</li>\n<li>FILE*\r</li>\n<li>fread()\r</li>\n<li>fwrite()\r</li>\n<li>fgets()\r</li>\n<li>fclose()\r</li>\n<li>snprintf()\r</li>\n<li>fprintf()\r</li>\n</ul>\n</li>\n<li>stdint.h\r<ul>\n<li>int32_t\r</li>\n<li>uint64_t\r</li>\n</ul>\n</li>\n<li>math.h\r<ul>\n<li>import math\r</li>\n<li>M_PI, M_E\r</li>\n</ul>\n</li>\n<li>stdlib.h\r<ul>\n<li>atoi(), atof(), strtol()\r</li>\n<li>random()\r</li>\n<li>exit()\r</li>\n<li>system()\r</li>\n<li>qsort()\r<ul>\n<li>Comparator functions\r</li>\n</ul>\n</li>\n<li>abs() (not in math.h)\r</li>\n<li>NULL\r</li>\n<li>size_t\r</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Runtimes (5 minutes)\r<ul>\n<li>GLib\r</li>\n<li>Python\r<ul>\n<li>C extensions, give some links\r</li>\n</ul>\n</li>\n<li>C++\r<ul>\n<li>STL\r</li>\n<li>Boost\r</li>\n<li>QtCore\r</li>\n<li>wxBase\r</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n", 
            "speaker": 166, 
            "submitted": "2010-10-31 20:53:09", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 2
        }
    }, 
    {
        "pk": 149, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "Python makes it easy to develop great web applications. Amazon Web Services (AWS) makes it easy to deploy scalable, fault tolerant applications. In this tutorial we will focus on taking a provided Django web application and deploying it to AWS through a series of hands on exercises using Amazon's load balancing, auto scaling, content delivery and relational database services.\r\n", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "In this tutorial we will start with a demo Django application that we will use for the rest of the exercises. No previous experience with Django will be required.\r\n\r\nExercise 1: deploy the demo Django application to a single EC2 node using MySQL backed by an EBS (Elastic Bloc Storage) volume.\r\n\r\nExercise 2: move the database to RDS (Relational Database Service) and scale out reads using RDS read replicas.\r\n\r\nExercise 3: add a second node for the web application and place them into ELB (Elastic Load Balancer).  \r\n\r\nExercise 4: move the static content into S3 and CloudFront. \r\n\r\nExercise 5: create an Auto Scaling group to automatically adjust the fleet of web servers based on load.\r\n\r\nAfter these exercises the student will be left with a set of automated recipes for provisioning and deploying standard Django applications to AWS in a scalable, fault tolerant manner.\r\n\r\nStudents will be need to bring their own laptop and have a current AWS account including signing up for the following services: EC2, S3, CloudFront and RDS. Usage of AWS will be billed to the student by Amazon, but it should only be a few dollars for the 3 hour exercise. Students using Windows will need to have Putty installed for SSH access.", 
            "title": "Deploying web applications to the cloud", 
            "plenary": false, 
            "abstract_html": "<p>In this tutorial we will start with a demo Django application that we will use for the rest of the exercises. No previous experience with Django will be required.\r</p>\n<p>Exercise 1: deploy the demo Django application to a single EC2 node using MySQL backed by an EBS (Elastic Bloc Storage) volume.\r</p>\n<p>Exercise 2: move the database to RDS (Relational Database Service) and scale out reads using RDS read replicas.\r</p>\n<p>Exercise 3: add a second node for the web application and place them into ELB (Elastic Load Balancer).  \r</p>\n<p>Exercise 4: move the static content into S3 and CloudFront. \r</p>\n<p>Exercise 5: create an Auto Scaling group to automatically adjust the fleet of web servers based on load.\r</p>\n<p>After these exercises the student will be left with a set of automated recipes for provisioning and deploying standard Django applications to AWS in a scalable, fault tolerant manner.\r</p>\n<p>Students will be need to bring their own laptop and have a current AWS account including signing up for the following services: EC2, S3, CloudFront and RDS. Usage of AWS will be billed to the student by Amazon, but it should only be a few dollars for the 3 hour exercise. Students using Windows will need to have Putty installed for SSH access.</p>\n", 
            "speaker": 168, 
            "submitted": "2010-10-31 22:00:41", 
            "extreme_pycon": true, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }, 
    {
        "pk": 219, 
        "model": "schedule.session", 
        "fields": {
            "slot": 4, 
            "description": "Python projects can succeed or fail based on their documentation.\r\nThanks to Sphinx, Python now has a \u201cdocumentation framework\u201d with indexing and syntax highlighting that can integrate your\r\ndocumentation with your code.\r\nStudents will be given a small undocumented Python package,\r\nand during the exercises they will give the package\r\na tutorial and reference manual.\r\nPlus: deployment and theming!", 
            "additional_speakers": [], 
            "session_type": 3, 
            "track": null, 
            "abstract": "//This is the same Sphinx tutorial that students enjoyed at PyCon 2010 (with some improvements), offered again after receiving positive responses last year, in the hope that it will benefit another round of students.//\r\n\r\nPython projects can succeed or fail based on their documentation.\r\nThanks to Sphinx, Python now has a \"documentation framework\" that\r\nprovides convenient indexing and automatic syntax highlighting, and can\r\nalso integrate your documentation with your code (your documentation can\r\nbe run as a test, and your class and function docstrings can become your\r\nreference documentation).  Students will be given an undocumented sample\r\nPython package, and be lead through exercises that result, by the end of\r\nthe tutorial, in their giving the package a full tutorial and reference\r\nmanual.  Deployment and theming will also be taught.\r\n\r\nBesides a 15-minute introduction\r\nand 15 minutes for questions and discussion at the end,\r\nthe tutorial will be organized in six 25-minute sessions\r\nwhich are each split between 10 minutes of lecture\r\nand a 15-minute exercise that asks the students\r\nto apply what they have just learned.\r\nHere are the major topics covered by each of the six sessions:\r\n\r\n# The reStructuredText markup language and its syntax; the standard doctools; and the two different conventions that Sphinx can support for laying projects out as directories and files.\r\n# The Sphinx documentation build process on both Unix and Windows; how to arrange your project documentation in a way that will make sense to novice, experienced, and expert users alike; and how Sphinx supports connections between different pages of documentation.\r\n# Running code examples in the documentation as doctests; the pros and cons of pulling docstrings from the code as API documentation (and how to do it if it proves necessary); and including non-doctest full code listings in the documentation.\r\n# Referencing headings in the same document; cross-referencing between documents; making class and method names automatically link to their entry in the API documentation; and how to make code objects appear in the index.\r\n# Theming with custom HTML and CSS, for students who happen to know web design; plugging in pre-made Sphinx themes; and how to integrate Sphinx into an entire web site for their product.\r\n# Shipping documentation with your package on PyPI; making sure documentation gets included with a binary install; using a version control source browser to view documentation directly in their project trunk; and deploying Sphinx to a web site.\r\n\r\nThe Sphinx approach will be linked to other successful documentation systems in our computing heritage, most notably in the practices it shares in common with the Unix Documenter's Workbench (DWB) of the 1970s.", 
            "title": "Documenting Your Project With Sphinx", 
            "plenary": false, 
            "abstract_html": "<p><i>This is the same Sphinx tutorial that students enjoyed at PyCon 2010 (with some improvements), offered again after receiving positive responses last year, in the hope that it will benefit another round of students.</i>\r</p>\n<p>Python projects can succeed or fail based on their documentation.\r Thanks to Sphinx, Python now has a \"documentation framework\" that\r provides convenient indexing and automatic syntax highlighting, and can\r also integrate your documentation with your code (your documentation can\r be run as a test, and your class and function docstrings can become your\r reference documentation).  Students will be given an undocumented sample\r Python package, and be lead through exercises that result, by the end of\r the tutorial, in their giving the package a full tutorial and reference\r manual.  Deployment and theming will also be taught.\r</p>\n<p>Besides a 15-minute introduction\r and 15 minutes for questions and discussion at the end,\r the tutorial will be organized in six 25-minute sessions\r which are each split between 10 minutes of lecture\r and a 15-minute exercise that asks the students\r to apply what they have just learned.\r Here are the major topics covered by each of the six sessions:\r</p>\n<ol>\n<li>The reStructuredText markup language and its syntax; the standard doctools; and the two different conventions that Sphinx can support for laying projects out as directories and files.\r</li>\n<li>The Sphinx documentation build process on both Unix and Windows; how to arrange your project documentation in a way that will make sense to novice, experienced, and expert users alike; and how Sphinx supports connections between different pages of documentation.\r</li>\n<li>Running code examples in the documentation as doctests; the pros and cons of pulling docstrings from the code as API documentation (and how to do it if it proves necessary); and including non-doctest full code listings in the documentation.\r</li>\n<li>Referencing headings in the same document; cross-referencing between documents; making class and method names automatically link to their entry in the API documentation; and how to make code objects appear in the index.\r</li>\n<li>Theming with custom HTML and CSS, for students who happen to know web design; plugging in pre-made Sphinx themes; and how to integrate Sphinx into an entire web site for their product.\r</li>\n<li>Shipping documentation with your package on PyPI; making sure documentation gets included with a binary install; using a version control source browser to view documentation directly in their project trunk; and deploying Sphinx to a web site.\r</li>\n</ol>\n<p>The Sphinx approach will be linked to other successful documentation systems in our computing heritage, most notably in the practices it shares in common with the Unix Documenter's Workbench (DWB) of the 1970s.</p>\n", 
            "speaker": 209, 
            "submitted": "2010-11-01 22:27:05", 
            "extreme_pycon": false, 
            "cancelled": false, 
            "invited": false, 
            "audience_level": 1
        }
    }
]